{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[PlantVillage Disease Classification Challenge](https://www.crowdai.org/challenges/plantvillage-disease-classification-challenge)**\n",
    "\n",
    "PlantVillage is built on the premise that all knowledge that helps people grow food should be openly accessible to anyone on the planet.\n",
    "\n",
    "**Overview**\n",
    "\n",
    "We depend on edible plants just as we depend on oxygen. Without crops, there is no food, and without food, there is no life. It's no accident that human civilization began to thrive with the invention of agriculture.\n",
    "\n",
    "Today, modern technology allows us to grow crops in quantities necessary for a steady food supply for billions of people. But diseases remain a major threat to this supply, and a large fraction of crops are lost each year to diseases. The situation is particularly dire for the 500 million smallholder farmers around the globe, whose livelihoods depend on their crops doing well. In Africa alone, 80% of the agricultural output comes from smallholder farmers.\n",
    "\n",
    "With billions of smartphones around the globe, wouldn't it be great if the smartphone could be turned into a disease diagnostics tool, recognizing diseases from images it captures with its camera? This challenge is the first of many steps turning this vision into a reality. PlantVillage is a not-for-profit project by Penn State University in the US and EPFL in Switzerland. We have collected - and continue to collect - tens of thousands of images of diseased and healthy crops. ***The goal of this challenge is to develop algorithms than can accurately diagnose a disease based on an image.***\n",
    "\n",
    "Here are the 38 classes of crop disease pairs that the dataset is offering.  To learn more about the background of the dataset, please refer to the following paper: https://arxiv.org/abs/1511.08060v2. You must cite this paper if you use the dataset. \n",
    "\n",
    "\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "Submissions will be evaluated using a Multi Class Log Loss evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import pathlib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import SVG\n",
    "import IPython.display as display\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next will be show few images samples from the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAFtAQADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDrQvPNSDgUwHnr1qTPuMVJYyafyY93foKzpr2YMGZ2CnuOKgne7kf/AEnyyVY7Qn8Iz0Pqcd8Cpo5FYjDBeOh6/wCf8a8urV55uz0MZt3siFri3AXczh25Hpipops434LD5ee9Ub2FCVkIzsbOAO3f/PtVyJIi6HeQuMY/lUxavYzdx8Q3OwK45IHNN1G5eC0jYE43YIIzimSmMXOY2ZSvBPb/AD0q43lz2DwMEZmHBJ4z/StEraCKcVxviWRWO7HODxT4gJGEx25P3tvf3qG2jQMSjbOMYHApSsUUcrcsQMqB2NWrC1LJupCNsbyKcckYGakiuZDgN86Dgjoc1lqkXkwvtk59eBV2KylkkHy4Gc7iwNJSlsUa0MhfKt1X1qYHFZYhW2J3O7qDwwYU+yv2mk8t3UoO+Ofat4VuW0ZmsZdGaQII6ilyKZgZo6V1mhKGyPekLUwECnMRjNADGPfPWmqSDyc0127DAzSxjrSAmBpAuT6ikxx1oH14oAfnPtRk4xikOMCl7CmAp/yKUHjANNA7mjPNADiM9DQTg4JoUihj6UCA/U0zkcdqUE+nFJ3xmgA6mjOMg80hyOcmmEnGKAKinH0p0s0cMZd2xgdPWkTg9unrVC/lWZBEmCM8lTXNiKypRv1CTshkMpud8jqBnnb7VWZVimyVbyj0OaYVmtIwVyVY4B9aWMOQZGKlWONpHf0/lXkxTd7mDY7iQsQ3yj1PWooW3gxqMYYjk++OtLhIwMIUQdD1Hc80sbQ75GZCmTkELkE5BOOa3jZuxJetcSQ7RhSRt3Mcg/1/KnvIqHGwhgQSo6kVR8xWlJiJRj0A6HiiZjNBvLkyg8j1+taqVhNg+15mki+VWPzjt9aiuMeYEEjZHUBep+tSxtA9uHUlJE6//XFQNh5ftBkXccfIpz78VKSYI1bUbYQZ1+8MDgVVe+2XTeWudo7MCG/SoB9rkJfeojZsYLjH5dqvQaXYxxAOC7k5zuOMfpxWqTatEe5WM88p8yMZQDJUt1/rTIwgQ7fkYfeA6CnzzSq6QxErGeMKMD8f/wBdTiSPYquqICu04X7x9zWbXNo2NGxaSCW0jYMDxg1MD61m6YSN8XbqK0wvHUV24efNTR0Rd0Iwx0NHbOelLtHWhgCOBzW4yFupyKWPpTSfXNKvTjpSAfmnDHY1DnApckDIoAm74pR16VDuJA7mjfg9KAJywyfSg4xzUKyD0pS/OP1piJhjsfxpM4+lQ7j607fz3oAkz6UnAOcU3dg9aXJx1oAaTjvxSZOac2KYcUAcPZ6vdS4Mkm5A23cV9v8A9VaGAylsk/7IPINY2ngRQ29uuMscs2ccn3PTitSRhA6qpRwVALr0Y57V4k6aXvSdzBlq6KS2i+S0nmA8Buvp/jVSIyFTukKonIUnr/8AX4oe4YRgP8qhcEHoO1NWHcqmKR92M4bsD/nNLS7sS9SQtJHAsrAAAjkDJPv/AJ9ahkuGknC9lXdweKeJpJE8qUFVB5YjpzTb2GNLi3KOp3ofmPHTHH05q1K9iWh1swlBBVl8rHfnH5+lSsdhXZIWyOM96hhh2L5kbHr8wyBUzgfIq/Mg5GD+n1q9EIbcTSRxKkMZLseflGQB2P49PxqFGe4nw77D3IFPa+WON3G0q3ye5GffkUlpF9rZrhcdcnc4OaSfNsXboWZovsxXO2Td1G45q0HxaPiKMDqSex7f5+tVYpv3O6WSMsDgbutMuJVm2DG1QADjoatTSAEckxllPzcll9v8ipis12W+UrEDxtH9aiIA2lCY4ySNucmrLf6HGoaXcrKG6Hpntn8alKSfkVbQfE08dyr+XIJEGcFcZFbMF3HcOVUFXAztasS6uI5ELecu6P5FCkkk4HPT8eoqx4fZpYJ5JGzKZTz7dq0puUaihF7lwfQ2+D/hSOaUCmv6dq9E1IWILE5/CnjIXpxTCO/X605etAACMH1oBHtSA8880pYDqPyoATqeOKQ9evelI6HFMweTzQAjbg3HNPz/AHjTRkA+1Hvn8aYDs8dcml/T3phPuKM5/CgCYNjrijcPWoiSafjIFAAW5HPFKW460w5B9qT1zgemaBHm/mrcOsUZ2jco+909f8/WtM+XEyxmQuCCM+2O/vWcfLt9rLz1+VONpOe/r/jV/EUxUnAfJ3IEC4Pp6/r2rx5WcNTneppboTAQ7NvCghQOM55/IA1XF95TAjJJG3ODwOen+e9UxNIjPHHK204DbeMjtx9D/nNSXI224eI45ABYdwR+tQ3poK5cW6Xc4MCygrxu/hNRXJhWKOQoWQvhgG+6P8KjjvUKGHaAwGM5+v50kqGbTptuDtCsc88DHb8KOlxXL0MySxsqbVYDg9M8ZqJ7h10+QFdrMdvAz9cVDbKnkhejdVfPX2qO7VmnaNPmMYwVx1PfHt0pyTewk+pGYjIpC5GDgbm6VZtrl4A8OQyP224x/wDWpIbWWOIMyBVJ2gE8nkVHNHIrjZjy5Onb8KT5oj8y1BJDFcqmwSSMu1SMk546VHeRyNdtEsUqgnhApH1/KqqyTeaDCVPbPcVqvcvCoE7qM5HGeeoGM89aqNprcr1F055T5tuVKeWSCoPJHXr6dM1YuYZGkEck8cabsKpPTpg89qoLeSRyq0chWRySW9B/jzVVxJcTljKqnJ2gHGKftY8tguXZrL7Pdqnnozs3y7WBz+VbWm6Y1jI0kkzZK7TGDlfr9eT/AJxWVpdgz3y3EqGXyuQR6446966cNnitcHTUm6j6bG8FZDgeOKM7h0zTSCP6U3J9a9Ioa6lTmkPAzTi/OCaQk5xjrQA0HnnpTsg9KTgdRSDbkgUAKSKZnB56UvfqKY2c57UAOOPU0m4dMjNJndzgYpD04xnNACkgcYoHB4PFNDcYxTS3OCPypgSliaTcR+dRhhn2p28EAZoAkzxz17UFgMUzcNvJ69KYQCMZoEcJdQ+XBuwAx6g02whZpcEjLjbwefw/H86tH9+jIwBJP3T6UsNqILWGc/P2b0BU/wD6vzFeFGDk79DnJhBhS6RyEYwSAAPxpx3zRojRADuehJ7c/nVsaojlXAj3Mm18N1DA9Mg4449qhk1JEWTMY65XOfl75GP88n3rWSpxd7iKUSvGQ27A5HfjIyM1ct8tIyEEgkg85HNQtulGNyBME7QCfpmpFddoCBt69cZ/WpcronYnhto4YSJnKrE2Dhdx46e3cfnTbRrUM4VJGYDLuVB3fQfke/H6x6rcI3kxMSC4DsU6GorcxWjhkUAKeVkOSeO/+ehpxqIdrbFq5vnkzEYm284yOAeeg6CqM6u4xA6OMZcN/IZq2LxQslvHAXL9QRyv1/Mf5zU9vDEtqzFNrbgQMdOO3P4/hSknJ7lJFK1tJRcf6kJI44TIHpVi9ihjZlEZZicEDkgenHXjHNVZ7p/tESoNpQg7xxuPXp9ana6VYd4jM8rPjzHUN/n6048vwoNyIQEbYokkDkZCN1z71r6fpV0JFe7IWL+6Dzmizukt53a5MjT5xvY52gjJHtzntV86nCARhye4A9s1pClT3my4qO7ZfWJUXaihR2AFPBK+tY8usMibhHgYHU5P/wCqj+1yYXlVIztH3ckZPpmulYqktEaKSexsjk9PxpD93gVkabrRubUSXlsbNyfuGQPx65H+FaS3CTHEbBj2681uq1N7MrrYQue/8qXdkcDFIWDZ5UlTg4PQ+9ArQBd31pCSRnH40pGQMAU3Bbtj2NACZJ+lJu9TSEEdf0ppA54P40AKCR1+vFNY+xpDyucjPuKNwP1+tMA3DHf60wkjv+lOzjgZ/GmEHb+NADgfemhyc0xjgEj0pm70FAEwk47U3zBjDCoSdvWmmTrjPvQBzdw8lveBBGGLqGVsYBBwePTtVKG5kuZWVhiIMAVHqOPzwccmr4nKRAyAOrjnPOPf+fSs64LC7dUVSpbjHqcHGP8APevF62OO/UuMuXQD5scl8nHv+H6/yp01wUj5UMePm4OO/T/PpT9MjSUqkhK8gh9w2gHGfr9BzTbiBIpcrIJTj72T6dPbHXmo5WlzFMYksiQ5C5jaTOTyPpmtKxja2lDOpw4yCOnNZ1uplbyWBjQnK4Hf/P8AkVYu2NlbASL87jYCD1HPIz/nmk2lESve5BeKslzJcblYE8ZbAA7f54/pUDuoYu8pOCPlC4x2x+dRonmNEP3j7iGwXGOfwp7lIJggUMAcbWwfwqU2lqgfcv2cyWirOx3f3Sygj05B4NWpr5LkDY4jUKF8sYG4cjkADnn8cms+J4IY1Yl92CWQEL9ceh4BzTEMcsJkb6467sd8f56mq5rKzY79iyqeZdDYJNrAAqcnPHGO/rVwTQRF/LhAYIFG8bueMkZ6YPTjp+ueDLaxhSGG4hWXcSTj1waljhZozKc+b/CC+cgcH/P0qo1FTXmUi09wrSNMypn/AGs5b37/AOc1OsMvliY7ljwSo25z/nH6VVEUkcKzrESD8u/khuQSP1Hp1qzJfwvafZ124XkZPU7VB5znt9KrdNyEQHzyfubhnnHQipflcbAD8y5yowN34fyqKO5W1BVtrhwVBbv3wPxH+c0hUxOt0rmNn+ZSrYPTGeOn/wBc0oRTQupHHBOR5m4EFc4A6H39KsIWjRwXJJbJUZJH9Ke0tzJFFEqbSWyWwAMD/P4URW7m5ZVLsSx+YnNOolFaFR3LPh23fT1ks5pvOaUmdWY4YdFxg9QBtA//AFVucDOKhitkiw5KtJjaWA7enrTz/nNepQ5vZrm3Oi99x4b2px9QBUe8bRwaN2RkVqA7IJOaYcZOBS59cYpGYL1GaAGFcngimnqc44pxb0OPY0gIODn9KYDCcc+lNJxz2qQqCabjHagCE4Oc1GyHrnip29cdKbjnPr2oArkMO/41EwYYxVlup9j6Uxl4zxQBgSrCLSE/atzAkmMKVK44HtzjPr0rNLK1+JE5G0fL128d/wAqdGVwyyLl9vAPQH+vA/8A100BluHAQbic885GO3PtXizl1OM1beYBgZM7QcnHXnnjsDx1FM1C7FxMsfygK+doI2jnsoAAz/T8oYvJiBkcbwwxgkgj3471Xcss4Ko2zHG485/yaXO+Ww29C/FBIJkYkNlAwIHqMj9P8Kz9YvTNciPAcJ8uDnr/AC6/yq+bhooGm8vGwdeRu7DrWdb3geVmHDHJOW4z61hVnroioq63IIRcYRWhK7uAcY49j+NaVrbrK23dCCFAYyHBH59+cf1HNU2ka5mY7tq44x/KmrMHlLb8MSckgYP45/H8BSi03qLYsTo0csgMeGX5cHscfyrQ09IzKrzKCvUjdgEDnGfXjA+tZMplkk8wSE5BZmdsBvQcUqXcjYj2EuD+nOByemapS5ZXiCdjavJUuZx5AVQxzuz1/LOOe3btnnNW8ilgmRSG2gE7x3UnGP0pIy0RicEhRhgMcg9SD7f5+unfanZNiNY2VUC4weuBxkcjJrVuM05yHa5nxTSTmOBsCMjBLt1z/n/PNTwWqealtaAyTlsszAHaP5Dnp05IqOGWCFo2VSwByTKQV46/Udv0q6t9liyI5jAZj1zkg4+bpxgfr+FU+WS1YWEmEyv5TTI2xcgZ/Tp69qpSSNvjaSEOMfKrLwffmrNxEs0g2swlb1OTgnv706LBgFoibWZskg9Sfp9TU1HFXuxqNy1akSXK2qhlk2nIBwAvORx7k8e5rTtNMS1bzPNLNjGD+NR6dp/2EMzOHcjn2/GrxfI4NduHocy56iszZRSDnH40mAT1zil7CkIGM967ihODwBTQMcY607n2z7UmfypgNI7j9aTryQRTycjimEEdT9aAAZx0pGX5uAM0F9xx/WkyWP0oARgcnHWmkk8Upx19fWkJHagBpBC0z86k3cc9aYzEdBx7UAMbdj19e1NPUelL25BpvB9B9DQBy7WggdXJMisu7K9QM/5GPrUV2YnvYxb7gFCgo7Y7ZqaS5LHE+AevUkfj/wDWqrPEPtDTIf3ZVce3AxzXhysrrocj02L0jLhUUAOGIxjv14/lUNvZSTKXCsVQ5Y9BgnA/z/kCF0XoCc7cYPAOTUlv5iKxLeWCBuPqvHWs00tWFrjNTCxp5XBL9Md+ePp3/OsqCHMMo8wYQrjkc5/PinvcyXN00hVgf4V6Y9PrgUzh5sthBnLFec+v1x/nNQmm2N26EkrfJhScdMA9u/B7flSMQ0CmNdoA5yQ3PXp29Oc9atT20MSQyQqjb+GUnGPlBPXtkkfhUIV2biTAYg5AA5P06f8A16px5NxO9xQJGV2QdFyyv7YY4x37U2Dc0u5ztOMqNnJ46+n41LNts3Rw2x+Rgt0wP1P+eafDKkyecVILAnHc9v58U077D5e4+3nSa7fzTlUVm+/gAj09elWrwR3bAxShVHGNw9DyOT+I+nPPGRcs+8hY/LAznjBPb8eamSGYTYUBjtBV+OQOP85GelDlyx5UF7luCJ3TcGkyvXHRu386sNcHyiIf9WcByfQeg7d/z7VJa3EsS+SkcakDcw+Xk/8A1u3p+NVLpJGXYpfI5YhRg8fnjGfzqk7RtFlGnblFt1bDHzOeTxwTkHuPp/8AWrVsLMI5uZR+8YcZ4IFY+lEs8UEj/JknGOfz79B16V0e7Pf8MV0YWmqk+Z7L8zSC6koOQQTmnjkZ4FQbz0zjHenhsg816poSZwexpevQdaYACvJp4JA6/SgBpXOeKaFIzS5JYcAmnDLd+aYDNo6/nRwR0608jntTAccdCKAI2AXvk/SkBzk4p7DPzUzoc9qAEBGTnkfWmkc0pPPFNyc+lAA4AGSabnjgUhZu+MU3dxQAufSoT3z396k3L9M0xsUAcJIWSM71IY8fLg579Ov41aLMsgd1GSiZBwOwp4gSQ8uNrDGOev8AjUF1b7LkRu5woUL06Yx0rwN9ehxvQkW58+QDHToQ3T0rQvmktLDc5U+YMAcE4+n+etZ5iUOjIRuBGAe4o1i5ExVVdU8sD5SPlyeWH9BUS5XEqN1qxlsscjRyFkUFScnIAPYZAPt+mavpFafbZ1uG3Ap+7l3beh6kYPtkfrWCpaLaC2cdMdMev5+35VYkdprlSjB5c5Yhv1zx2H+elVTlGG6G2W7+1b7cwifzAjsq5UjcM+gHBxj9ah+1eS0a7izkY3DnHsP8aA0sMZdY8A5XcRxkc8fp+YqrwqBtiMpGAwBH4cfjSk+aTdg2LLTTvL8ksm4+mQfpVuSSFrOEBmGQCcsCwOc9z/8AqzWYyiTlFX7xOM/NjqP5e/fPap4oV81iVzGTwTxhfX86ItJNCu2aEVqk0cmBvCAYwDk/xH36d/1oYSfvJIo8AHIx0AH8vxp9q8kIVX3bdoC7juOCeBj3H8jWw0ykKrEDv8qjrjv/AIVrKnzq0UWo9jHMGQjngYOQP55/KrtvHK4Z8EgKBx0OD/8AWq41tFNIriVRnqmMZP8AKpY5PLTanyewop4arUbuuUtUwsYGjZZXxxyvHX8KvhieSB+HFVvMZ8HrgVIsmGwRXpYegqMfM0SsWR+hpwPPYnsajDE4PWpAevOK6QHqwwcjmgH0Jpm7qR/hS5zjPWgCQN8v3qAfam8ZFNOf1pgTHnGKackn0poJC9eKQP1BX86AFbngH8DTT0wOT9KUEsx6YPf0pCGHp1oAawPGQCfam4B6cU4nPbrTCvPXpQA1wMnBOPWo8HGR09al+U8H8MU19oXAxQBAY+/akYA+3vUhAJGDUbdxyKAOYO3cGVSueinuB3qpevHHLFgtnaYsrkdDxn65qzayKrrIEYgg4zyOnTtVa/CvgIvA+fbjrj/6xNeE3aJyPUW0LwsZ5fnQLnB6MB2P44qJIZb6eRizIgGWbsQD+dJdyiHT/Lxncp5PXAqHS5AsIiCOWYHGO5Pr/n/6002nfmKtZJA6yQz+XHvdWAwV+8Rn9KSYNCuxfvkgSOx6cdM9Mf4U5737OxtsrlvvOO2ewOM4/wA/WLe27Z5gP8Rz0/z/AI1l5j0NJ7pLm0iHlkKigLzkkZPYn1NVZwd5VJFEKDHXr0HHt9asW9nNdRDBVQAGbgIvbHPA/iHPvUlzA0ZWKRTkZVSp+8MnoR2P9a2lzPWwmrlKMnLoQzIcZOMYPfj2/lmtJIkmiaJSVREJZRnLH09jyfTioIrNY4DI6ghmwGIznIq4jRfKGZ2ROgx932HJ9zRCE2rqNyowZHHZGOZV3fJxnPUfjWjuLM2SDk4yO9UzIxYlWIQkjJGM/X9PpUsXABPHXgV6FCk4Xbe5tGNi1Gx4BBH4VbQgqOPzqmg+XJbAHGTxUUupLGFSD95Ie/TH51tKpGC1Y20tzVRV25P3fU9qmQBQWMibfXIxzWPDckPlHBb1Y5/Idepq3Z+XLKJbneNvQqAMds/n61h9Zk9kZ+1NFSPlCuDu9OtSBtpKkEfWq08q+aDFDJ0HHU9OD9Krz3bh1cJMqE42MxOPQetNYpr4l9we07mnuBHp/SjcAVXIGeADTftMM1kUdSkmAQxJLHn/AD+VUY7W0F6booqXOMGcemO/r2/StHiUnsNVEainoO/qTShh7fnVVZ0bILjK/wARGOKVbqHOzzFyfrWsK0JLcakmWC/OAOeppW55IqPzYyThwWGB0NSFTtyOgOCRj+dWpxezKuKvBOOPTNK3t+dRjsfWjcSTnv0qgFK44P8AKmlQD160uSAP60pbb+PagCFhhsEYNNIJ+tSHBPA60whh7UARliBjBBHSmZJ+nrT+e4HHrRtxx1oA40TtDbGUFmUjueh9D/Oq8N0XnjU4kU8DPU1Gt2yDaCQG7E0+AIsjTquSF3AAcZr57mfLqciV3ZEV1btqGpGCNcooCc5AX6/rT0RLeUwREsG+8/fJ+vb/AD2qst5N9o3k4GGyM4GO9NS7c3IdwSCSSCM8/wCRSS0SZd1e49XiS6cMFI6Bm5wc/Xtz+dTWlu97vJGXxgZPXt+mP894Ll4nKrEx3McN3wOMHnrxmtO0LW9i96N+UUBM9jwBz7en/wBetoRcnYSV3YY90bePakztKhIJIyoz1xn8c8fyqssjswLSFvqScf5/rVffkDPapUVnZUjDNIeiqOtehCKirI6VFJFoMAvGevapYyDUcduwjDSsI+cFSfm/EVZgmtrcBiiSN1XzDxxzyB1/Hik60IuzYnOKHRru+ZQMdzngVYk3QRqxCnK5BzkVD5omlDS7B6BOAB9KaQXl81G2qOAcdB+NYTxN9ImUqrexKGJCzOBzjC55Hfp6f59atWdoTMLmWNhGDtVl4wf/AK2RUkUlhaxgm33sAckjg9wT+vpUt5qisqxhUTABCqMEYGKzUEtWyL9yysUdvLHLDAEKZ3shxzk9z+H+RRq0w8oJC0ZDgFjtwevTjrWNJqckWBgEsec9M9elQSXjtMpUMGI5xyPYVUqitZC5kai+ZEqOSTwB83UfgafMPLSOYYUE/MRjp64qkmZkG9dr+/SlG1vl3fKpySxx+tYxuxNlt53lceXjB4B44qxHAyALKflIxkEHB/pVCJSUYjrxwDU8k+xljJ/1hyOemPelew0aNtEDcNEgifBx85/rTLhLW3iBKkOTyST1/rVQzqrKV3BlxznHelkJSbzJ2MisBgZzj862Ula1hXLHmqz7ipVc45BGR61dinClXGNhHzYUDGKqecLi1EeVBIz+H+f8803zlgjWQscDG07snP8A+qnazug5jRFwrbigyME/d6c9B/n/AOs0Tx7S5+VQcc/1rPGo5jVYDtC8bWwSfbpUgR/lmQEoSQzAkDp0+nStI1akXoy1UsaJO07uD2JBppAPUce1V0uIYYi3OT/DnOfT/ParCzwOMoSh6YcjBrrhXUtJaM1U0xu4fh9aTdkjHBp7JhcEHNRgYPIArcsaxwAM7s+1JwRySKcQBg0jgjHPFAHm7E3LEKAAewqdj5drhFKl224554qpCWKqCAg9ecmpZ5jHLGgJIQAtnnHr9a+dabaRzR01IQ+yForhSiluGHTvwfxFMWFPL3ebgHHO3jA7n8RT75murpmVcqOWwOFqKa2aIMMYKqCowR/9fuK0cRMsmzKwKZJd5I+QjJ2qO3OP8/jV2BoChtJFyrkFmH/LPn16enPSq9i0pJKIytuwnsMd/fnr9avW/wAgMc4w7qW+9nkkYzyfUcDnn0rWno9BrQUWunR3e2Mu0YjDfvXwCxH+6Djr+VQzTBFRo9sajAby0wD/AI1TvZRvco4AB7HHbjH59KY9z5ojidAh2/3ecYyP0x/niipVcrobk3uPW4kcnrknB+Uj9O/5dqntwkkbnaXAyFxxk/8A68VWSFmZSm4kndhT0xzn29ama3uBMwEWFCjb/COeep+prHbclIPMdpiVfnHUc4NXbfz3hAZAVB3fUetVbaBlkaeaZDnoOp4rY8+2EWQFTdkFBkgf/X61KlFjUe5AJ2itQqllLk5z2xjikt1lQoRl/MOM47ds/XinrdRfZQFijJU/UnNSxTiWMrG/lyICeTxihSa0QWQtyuJfKVH4yWcjgjHIzUMcDbY1Ckjdub5gDj8f50wG4uN0SqeOoI5P1p9ssltMBIcgenetLtLmJ0bNRPlnV1JKbTu5A4z9fYVE1u9xbs0fy5bJz3HOMfpTFkSCZWTlV4571qR3KvBKYXELOc7Vzz06/wCe/ftpTSnrJj02M9StuRGxVSudw5x7VXnZZL4mMg/KAowf8PU0uGlunEqGIKOcDj8K11t7eO2jkZF65yGBIHHaiFLmu7k6makE6iORlJBY/dB6gev5094rq55C7UUEYY4FaDzb0MGEVGAHB6n1z/X9aW1ubeECGcIEBALEH15q/ZpNajsrWM0x/ZpcsykOMgA+1TGQz4RGXB6EnGKuG3FziNVVoH5GeucVntp8ttNtJLoe6NyOeh4qeV3E1bYl8uJW3fwqAHz7irUKxoMGTgjOc5I4+tV7awk3O7q7BG24yMEY46H27U4xfu/3RJVM/L6H1FNvleoJFx43dAojBLEgcfe+lPFsiyRlY+cchhjHXjr7e1Zou5fLKTjkdAetXDeqUDB3Ma8hHOcE1pdWGtyaKeX5w/3OcMeMdMY9sfzqXjI56jkis17hZ8ZBQZz7KasLPHCiRSSBcHG/cMegGexyeK1w9dt8jN6b6FnA6gYoC5zkjijPy7ug7Z60uRjORkV3mh5cscvmjBBBIzinXa7pSykkt26ZGKlQ/NJIGG0DPynjOO/r/wDXqFzGDbMWwQMnHU14ThZnN0HWrGNiF5Jwd3oev9KddxESqhYOQvy/ge3cDGKtLAsd3EyQ7DjcCD098/T/ADzRe2k99qQSGJw4Yhj12j6ce9NxsrBbQNNuuuCqt0YnnI7/AMu1Vr24eW5nKjgKFB9cMAOPoK0X0eOz4llBdeSq88fXpT1mFvM5jVFkY4G3rj157VDk/htsNrQhtdHku1/eYiU/Nlzjk47Hmm3GnWlpI0ziSVckEBcBfr3FPk1Gbztu4hiefTPNW5rkQwIAfnZe4wRkD/6/5UNRavewaGfFdJBGghjRFPUqMn86v2ckYYyM4O7O0Njrg+3+f1qlBbRzOAv7sqckgfK34f4flVi4tSRiNcgAE7ex+lRCVncWtipL8kzSqCWLZ65q7ptmZ4pmmOAFzhm24B6Hn/8AXyKzxMRMyupyvboAa3bFraS1jiaPGDnI75wD1PTArSnFN6iRnzNCknlxZC5yGB6c06HbHcErtIzgjHT6j86tXtnHHtO8lpCcY+lMW2lw+VcKAOR9BiplFqQF0XqJdL5WVAHBJ/A/1qK6k8mci4T733NtWLWxilt2ZXw3GDweef64qN4pGQxSgSKcHJ7fSqlzW12ZRFD5cqLG7AZOfl5xVmKOOOUMFIHpUK2ckNyUh+bg9+mOfyqwZgrKrMHVuoXnH+eaXvWJsupft7baGxlkPJGOx69fXNVjK8krKnCJ8uwnt0FT2wPmMUYlCOp5A/z71QlSS3vJO4znIOM1o24pWG2XTPIs5hTKDqQerjoMfnU0kwjly0CkA8qwwT6/1qvDLK0mSgKHqGANW5LZ2ncxj5GAIDHnPt/n1q1NtXDdBcxxmCN4X2OvQdP0NFpP5coknyMEZOcEdKjQB2IYsr55TPGPf8hRc2ruqMDkY65ok5NqUUBLcXExkL2xBQj51Xj61SSd8neAVPALcEc1q6dZhIi8rIAAM45P+H50TWymQSJ1TJ7805XlrIVnuUo9stwC0W7jpjr9KfchAdioB/EMcYJ//VVgy8oY1CEchhnOfzqJo5JGyqkEc+xrKU0laJSTI0g3w5wN7deO1TQWhXaWUKFPep9ixptOQzcnHT6U3LFgck8dCa6qOGlNKbdjWMLai7QfqOtGwnocHtS4JXJzkn0oIGPWvSLPKIQ4s5WLfeqijTSShMHcxyPbGf8AGtPyZD5UCKT8pJYf5+tSx28NqVWMbpieCf4a8R6K5zNF+3tHD28kv3kPEec5GO/PHatMTm1t2bGxidh2jiq9kjBXkUhnPBLEccH1+o/KoYo3urGTBOMlmcDjHHOfw/Wmk1qMi3SzLI0cjMZDjJP+fUdKW1jaS5EQRpWK4IQ455/Xoal+yPDABIZIwoGd2MgHjGO3r+OfSktJfIV3iAY5OGU9D9fb/CoUGpe8BJcWYt5Fdx91cEA5GcdvXtVTzWmkWNj8oPQDg8cVKHlvrzzEZmO3JQKOw9Pw/D8KgkYfalVI2WRSAq55zUTkm7rYaJm/cRAJwcZzjHHXFNF423tkn8f89KjuIyRkgrg7gvt3/wA+1RtHtAEP3gc9axe7GWZGjuJB5yjZ0BPX8xU4tCqE28u5h91Mc/nVIMQ6lwyqCevuBitKGZTMqxRqgHBIPWtIpvYkpjUJlnRJVZccYIxW1b6kkkLLIck456Edehx7kflVOVYTC8UyhiHPPt7VXFu0IBhJdT/CeuPrRGco6oNS+kvlsZPMIP16U65nTO5XO4/eA5zx0/lVWNvMyrIUPfcKfEChLFVKBs1PtHazDUuWxl3rKw2oRwTzVeSykW5Kj5geVYnHB96leVmP3sqTwOOKupMYgp25VfU/571UXBuzHYqB5owED7QBnaOhq5H5ZQNIw34JAqs0ZkkDK2WzwB6elXzFDJt/hOO1VdS2FYZAGZiWHyD6VbmLx22Qy/iAc1V2sWw/Ef8AeFOlkJhCKcgNinzqCuCTJNizRK2/bIBk/Ngj6VEUkiYrJJmLPylehx04/H9TUkTNjJVQ3TPepkj8yRFIzgdMU3VXTcfKyxb3CG3AK/KPXjrSDy41LLJlumBVa7KLtSNg2Bzz0/xqMA7PTA5Nd1LDKcVKe5qoItKY933TxyeaUuzFsMcHoM1CAc+5PGBUhyc5AxjrXXTowh8KKsOHTHShmbnpgenehQdwBbt1pecn9M9/rWoCDcGORS5JPHQ4xSZLHaw9uKQHHAz1xTA5GVIbOyUkJnHTPesffsTKoC7Hr6D3P+cV0lxZQXiiCGMpsGGfcOD9O4/zmqU2hm0lRDIHZW3A5zn16V4VRTbutjn3C3uF+xCM/fLH5gSOgH/1uP8A9dJCrQ2zF2Y+ZLtCjGTj1Hb9etRbnjeREZSxOMEDAH1PrzTbtsQDaG+XOTuzweg9Mf4mmp6a7jHTM73JiURjj5gGHCjPUjpgCst7tThIfMzjIJIA6c1o2zpcxTiR1jZoyvmMeATk4PHrWLLbTQuUkUpnv1H51rSpwm3J6lQSe5ftdQgh/wCXf5s8knOf5VbmeG5BbAxjKt6HP+fyrEXnPHHQcVPC2x9wAA9MZzW0qEWrRLcF0NGSKXzGduQT+tQgCOLcCSCQAMcj8asLcSNa7QuULbs85U/571VJZXKHGw9sV5lX3ZWM7WFik3sFPOecVaguTamSIFcEEEkcVXjj24cOV9CwyBTiI1iCbcnHOaSvHURfuZDN5bsxLty3ercluUhVwcDG4ADkjmsq3BlOzo/8JFaguThQzA4yCRzk/wBa0ik7ykMcIPtUIRm2PjKv3X/HtUKK0DlJfmZehB4IqzFi5YBMIMcEZ4yf/wBX51K9utwgQqox0fPU+tHs1a6FcrmPcAyAgH/JqdGaNOF3gDJz1xRDMqgpMo3Y28D3p0kTSICjZXpkc8f5xSlTT1iGwQOMKVAyDzmtBUVpDJ2749aqxW4V1VR6Hr1q5ujtIy8nIJwEHU8VMIyk0ojSuPfasIRsAHoT3FRKoit3kkIeMcLg9T6VnXU/2i4kZUZUIA2seg6YpqO4XaHYDI+XPf6fnXoRwSaTkzRQsPWZ5Ij5oaOQk/dboM9j9KtLcSnygJCCoKscg7uO/FVUyU+VcHHUd6lVTnbsY59D/n/Jrqjh6UdkXcmRRtBwev4VOOnrj1qunTGMnrz3qxGTxzgD1HWtwHjryOnTNP8AkO0rg46+1NztUEL2z9KfnAIGDn0piJCQqHqPrSYyM7MA8k03K7RhcZPSl3Ag4IGTx6H3pgDMFHODjuOP89KY5BYnJAp7kA4GCB0Izimhc9SDjnGM4oAwpIXjm8tJCSvJ7demKflbabY0nmEjKllBI6ZGD0qnieFHfzDuI69j+f1qNnM0xdjuxgnpya8WVSK0RzFWed5pDKItkIJPP6D9Kc9tJNbhzwrD198En8amuyZ44yCu0N8wB6E9D7//AFjUE+oSLAsMRLIBnJOQT9Pw/U1gnG7bYymVaNPKXnPByP0qe2ujG/kusbg9Vflc9c1Xnd0VZtoIHP3cd/wpsKg5kDMCTn5jkD1xSjJ3uK5qC0s4oxLJbKdx+6pOPr79apPpmCDFOCPVgRio5pZ+jIQOoOeP0qSOZ2QNj7uAWNaxxE09GWptCPDNYmNnZPnPCA8n0OPrQQjxbuA4IwQeMVcjjF6hSRiecK3oPeqtxE+nsUkKsrjIIOePardsQrp+8i9JEhMJt41ZSCD1zyPb+dNkKSXPlocqOhxiphCHSM56jJx156VVG+G6IUE5Pp71ySm9mTYvp5YU/Llx6fSqhkY3g+YkEFTmprmAxRrJ0OORioraRTIrHnb1B71XOmkgsaBRhtUDHGCff6VYlZlgUYOMcc96eqiUKQ4IDE5xg/T3qeWImJO+09KuclHREWGFEFrucAkDg1XtX2SrtJZQckH0q5tztQDhuDTGjFikjNgleB71MW5SSiWotl1Ly2t3USq7E4ICjkCsudt1xLKMFCSwJxlgf8ikeaS5ZS43FQBggAgZ6ULGCoVUwByPUHpzn6ivYo0FTXmapWEEfGcZPQZFSrt3KvQkjGD1704LwuCcDj2POKdFHlvmBJ6nj/PatxiqgR8NjHPbjPSpVQEEZ3bcnP6UbRjJ4x/dpVIUYzzkcg8imA6M4O7IAzwCeg/zjip9u4DtgfhTCCowpOc9xyfb9adHkk8jg4IBznNMRJuIJyQcdM07JUFhkgdvTr6Ux1GA2OhGSAP61IHBJwNzZxjjmgAAyAp5yevpTh6gHJxnnvSMqsSHYYJGe/6U4HDA5IbPIPP60wGKP3gw3B5xmgDZ8xYn0GcU/Cc4O30INMXIOdo+XnOPxIHt/hTA5eU7i4c4TJAB7094C1sBEh5HJ29T9KdNGkBV2/eNj5Rj6UyO9KoxxgKOv+fwrwEkvjOUaqRxo8LgneCCR/Oslo2ik8ljnb1IHHTt+lacjyOD824vycdqjvLeX7LHJg5Xg5HOKykm7sfkVpIkMDZfqAMHsKSOPy7clQMjjHSkuM+SMqRz+JNPRdqKQCxxyD6UrWtcZNbrtiOdrADkdajVoB8uCEXJPOc/nUEbzmR8D5F6nGadICz4OFjGBhaOayuBpQRI0ZlRkQc8HINTS2Meo2m5GAmT7p3ABvbmqcW1oDtH3TnPY1chijkgZZziEjn8OeKSq8tROJpTTuYY3QyPsJDKSCpPTk8D1qZbneoCKBKDycZ9MY/WoZokM7PGQ0QICkpgsPXj8P1pWZWKjZtQD5sEgnn/AOv7fnXtulCdnJGxqFmubNpMD92drc8VlNMLRoy8ZO+UJtHXmrMJZI2AL46EE4z7++P8+yxrhcM2Fz0XBx6H/wDVXLPAxlK6YkkX2uo0jUwZEg6lhxj/ADmtNJYrmwe538xY3qBzn/69YCqojYMNygkcDqc5/wA+9WFZlDDeQrklsnGRn+laywdJpJIVkacepZiUJbr5gPXrxUc88k6OXjJJwUA/oD7VViXIbLFgD2X3/M9R+VTAjkhWwOg6DpW0aFOOsUNabDVwkYwML0A/z61INrRjhVyMAdgPwppwGGTgnueOOtToig5GAG4BPf8AzitgBPmGwncwXqF4HWpVjcAHO/PI9fekTIOSMf7SjGB/nFPSTLAIc4OTnjH5mmAKW2kYJ+hzipVBAyRtTPOB0pkRR5FOdpHJA5I6/wCfxqUtncTuwDwcdCP5UxCqdzBhu5BHGacisqMuGGRjkkc/ShAQqlchWPAU5P8AnGKlAK5A2BgeFH0pgNVsqwJwp6kcnOf/ANdLx94cgnrjGPrTQ5Jx0HJGBjJ9KeFbI69c4OaAEZ/L46juDxj1p3mhWAdT0I5P1pNquqsAWx36A59qdtTJyflADLnGMDtQAFicgAjPA49qdkFB1CtweeRQCCMjkYznBOBSx7mHA68ctwM0wMAvbNEEwdx+Xg4xWfepHuzDHlAO/U1asfK5aTk/y96dPJGFcpjPcf1rw5Pmjc5FqVLNcSlWI459hV3LFwduYwOQemPSskFyzSEECtMS+RCElIw3zH1zUwXcpMo6mm6WNFIPyjqegqjtnVmY7QD0G7tVu4O5lkJOTkD6f5NV7kszDblcjsayk3Ju+wDIZpIiw2sAeSSDUtxsRBjGe4HQ0W+DG7MfvHHsaGtldhsJzjPJ4qJLQaJrQBR8xJBFW54X+zsyIXVQScn7vHX3qrApBCsPz6GtC7u5rbTkS3fZJITk4/hAow8XKsrG1N2MEEqwJ7fdY8YP9acgXG1wDg4zyMZ/lR5aqAWcNzyD3qZYsHAxgAbeM8e1fQFiQo0nJbGD024xj/IqREIyrBiuCQF6j8e3P86AZNwD8hTycdc8e/GBUkahpAoUMXBOQenXP4UDHgKUG3BAHHPI/wA44/Gp0QKpOQFb7rMOMD3zjv3qHaDGyyDI4PP14/z/AEqbcSw+Y8KBwcdM8Drzk/r71QBGGXfhPlDcAnGPWpU+/tJ4LHjrjn9KQRMJFIJZWQYUDoATxx/n+dSxMyocBtw6ZGQf889u1AiWXrgg7uuWbjgZz1+tCFQpA4B+XLHrk0yM7Sdy45yR14Pf2qQ7CA4cAld2CMHpz269vx7UxEwXcu1F+UAYx1/yKcyncWiwM4wO31//AF1GHZDuADLjJZTnjt9QeamVgAwUnJOcAdDzjFMBAPlztUN2A9elKEwzBmICnauBjof8/WlTo5YlemAfb1x1pQTtLx4ZhkkHA/EUwJBtVl5OSMAcnB/PrSgIuAMnA4yPw6/lUaM8uA4HqBkdeP5/1pUOFLNglhk5PPXHNAExKO28AA5z1/P+tG/EO3JzkkgjnNCybxkDJzjn9PrTN2Cwwob0J4B+lAEgJC71YliPmx1FNViWAY5weOM5P+f507n5kiBy/I2k0xUdt2SNrHgEc5Hr+n4/owLG5AOAOecelH3wAd2A2fpj+lRiYRhhgkKPl5yR+BpWIeRVVflIG4n0oA5eY+bclosqhwM5wBTJI2x8oJ56+tTGBZXYREhc5wakcLCmMZ78V867vU5UjOUty7scp0yfyFMgUzy7nLHnjdSzyKsuGGByT9afbsd28Aipd2CsWpoxFbK+0EBvyrNIaQyPtPoADWi5LQuFXIHc1WVcKTwM9MmktHY03Q2CJFtwS2Cf4T0/zzUtsU8hxgMwOAKjCfMmCGI/GtFWWHGQAx/St4LuKxLYx5iKSgHd69veqOpTW1xFFsjcMmVw6/w+vX68VoWxbncORk896yZWBk2hmZCMA5AGBnsPTitsHGMqjl2NoKyIRH8hZijY5yHBwPfFPVgrEg43cHjBPX/69N3DkFl3KCPoOvT0xn1/xdH94sVVt64UZyAfcdRgetemUOHKj5dy9M44Pr/nNSR7QkfX5c4yDxnB79OtKAGZmUICRj5l4A7/AEODSiUs6yuQHPDYP5/ypgTPhRtyXO0kc8Y7fTJxT0ZnDyFSc4yv/wBb8KTyyADsLcgckY7c/XoaVYwrBgWZivXtg+nbp60wJVCHazA/KMIduTn/AOtz/no6NN2BswmcN8uOf6fhSqRhV2ZUHqfX8P8APP5Hlh12KfkGQQeuAcce3P5UAPUOQFwRjJJ/u+49fx61LnyzsIAUd+mQOppsUTYLrGisB90YIHP69aFbYxCx/KWBHyn5cZPrz3piJI8htqgZIJHOOR6+nb/JowQVMn3sYDYyBx2J/Gmj91ACMsDnknAzg9+3f1p6nKyIrPhCSfoPb36dv1FMBQSW5OBg/P8Ayxjv/n3oOV2qyoWIJ69iPr29PrQpLxM5BOThVPHfnvx0AFA3AYCDZjhs4P157dO/rQAMd6sT82eAyjGGI5H406IgKVdtrSdT0A7/ANTQygqGYlh3UMeOozjPPWlP91wpUHJLHIx7fXjv2oAA+Tg4ZT0z29P5U9iM8uMLwTjGDxzk8f5NIrEqN2CB2PBB4pflDbc5xnIxgZ9T/ntQA8BiqnB7jbnOafnaSQhAJwccHP8AKmopALbT0OCMnPbPpk01GJwH6YAYKfukdvz/AENMBCWbBUHPOFORj8+3+FSxkld3IwcEA9M+/wDnpUYKsWJG7PUjnnnsac+eCeoPDKc4oAwbhPLPmKML7Uwzbot4ySOufWrCwiVBEGy3v2qJ4HWby92UXrgda8Fwb2ORblSO0e7mLDjnnJ61ZaFLQddx6fWrCzxouEABAwaawWWNnJUHv61cYR5bLcopsySq2GI+U546VUIOMAkjqe1XECruCphsEHFUoy7sYwvXrXPNu6sVEt26IWVt2F7hqk+1JI/3eh44pskZiiVeRu/lTIkAPTI9aqpU5FyjRpx+bcyyFVPzIQPyrGl/dFWfaCMqcDGDkjr+dbE0jR2KBTtZmz1I4HuKz5MCDcYznBbcHxnPYH1GP5V3YCMvZub6myVkVRGxVQeVxyRnp9KkVQjMF5woPOevb8P8+lSsgddq7cAgbSvIwe1KA25Ylbfxgg8FT05HHHSu8YLl9hJ80jKnkncMn29BSq6vvKFlU5ClRuOPUZ9v5UkgEjMyrkDJyVzznt6c9vSljbEDqCqMeTvAOw9c8/TOO2PzAJnZizRbmLKRuA6t6ZA+p59PzqVVBOEXCg9T1HOefTnimJEqbRHuZUJGARgY4yDk+2fxNAXavA8xjjOWw3Trn0pgTRMu75o+dw4IyT0GMfXFO2squmPkZtrMCR3z35/KgqQx2OfMYZMoGMjP09se1PPyJtGwq2Oo/r2pgBkaQZwEAIzjjnqR7dabkTBX+9sbcrMOcgYx+vek83dlkXcOfmAyQQOef8PSpsGRjEG2EMGz7jqD9c0CERVGVIDNjup4/wA81YkXCl3/AIhtC7eR79McfX1qBio/eISxUfxEg+n/ANanoxJwowBjbk/l/kmmAbOflchmG088ntwPy60Z8sLuxuUg4bjvjP5dv8KYhkV8sT8w3dByvXr+v9KkBDlndctkHkg8/l1oAkyVhwzZPQkdc/jgnk0pCu5zhTnOW6L06574z+VMj2KHCALHgEcjBH9KUnaEYZCLyWfOCPrz+tAD8IZCCRv5CkH8/wDJp3ysRllBbjHr6frUQjUZOck9se5P+fpT06FypY4x1O0n9femA4DkEoN2T8uT1pvmcmYnJC89yTjp+X+etSAck8c4wBzzmo3VVwFUMTknHfnnPbv/ADoAk+VSRjC5wB+lKNiFOckfKDnAz6f4UjMSVUE53YVmOQPf8h/jQE8vaTgdPmI/z6/rQIzIbqOOXzWT5vTHWkkJfe3Az3qs84BVdg24zROxmQKvGa8GNX3bnMl0K8sLbiVOEJ45qWFMRszbieq1Bbvtl2vyQcGtLz4nLKBgkYUUoNPUEZm4ibknnr71XRt0jMrEHOAMVq/ZSB5pYDB4BHJFVbdFjnfIHzA4Poc1PI3JXKWhG8Vy0oJG9T6Vo20a4WMLznJJ7VKo3RsxP3jxgdKjvZFgMkYlVGVAMYyST2/Km6Ep1OWPXc1grjL26geFUUEGNvv89Seh/nVV/nDY2qqLyBkc/wCfaoRkjKuVYdSBgA1OmBHuiYqfu4GCMdyP/wBVezTgoRUY7I0CBBFFkHL4OOCpxz6H+Q9voo+UBWJYEDau38uO3TtjpzQGb7zOGLcEr3PTrx17fWliT5mQcDkZAU/N0x7D1rQBtuqlsgKpHB254PqcnjrUkeElAYnO7vkZ/lzj2pwQAqV4AQ55H5nHI64+tSeXuxESqFh3PHtz7fpimADa5MrMiBuAGUEDvx2I5p5QSsGiG49OSQQOhz7/AJHimgKhXG7ceODt78g9+MH9KcIX812dlXGBwvf6+nI/KgBEOEkyXGMEZYnnp0P1Ip4O18Ftuxc5Hb0P/wCr2+tBBYMyuoPHAYfgfpmm5Dsr7vkPBbOAQOh9+uKBD977SqAHJBGSfl6Hv+H5U4YhYN5nrtbOV6/y5/zmo0lRTuRQM/e3N7ZH1p5LRxtkAAZ2jO3bx+vv/M0wBdxK/KNzdyMHnsD26YqRHZRs++WGPmUD8f8AOD9RTAE3sGwOnHTPsfw/l0NIxxMVK/KB1PX8QPX+v40AS7ATljkk9Md89P5YpzK7PtVnWTgkY6Drn/8AVUayFQRsQMRtAwDgZ54+gNCztkIQ4OMqBhcE8DnPt/nNAEske/ChRkkHk9cHsfbrUgjUKyysQSDn+eB+VRb12oXYAg884wfr/n9acFKkhchu23PXufy96YEjbGbkZHGDjg+2P8PSiNm8vDnDAkccA/5/yKYhMijB5IOQDnPPt/npTwWWJcFhnG4dc/54oAQvvn3q33hnbtwfTilw24/Kcq3ryoB980AEnKkgsCdvUe3WpCAycBOASMDp/n+tAA7b3VkZdq5+YEHr/h0ppUMgYR5wcLjHJx+lNjjKgKqgMASfm7/TFOOQG5znqrY9KBGC4AA+XNLCu85LYUdqZZT/AGi3RduNowTUkkRjOVzg18u/3cuV6kThZ6DBbhbvcTkHmrixADcR93uaW3hVyGkOMVLMys4XO0d66ItcuhnylcxyOAS+ai8vYW3Aexqzu2sFGQKhuVBcZJINZzkltuWkTWzCPMjN8ijJqrdSJLIzqSVJPt19/wDP86lmiMVgxJABYH5j2qhuwRg8EdW+vT1HWvRwEXyc73ZolYchXyjGyZwM7zn5env+H40BGyCCAo6DPv8AypqgbSCV+YZ5OcAHpUpUSXDDehTPBGcY/EZPTn8a7ygLyMeVCjtxkNjvUn3M/MG45yOuQeSfTj60wfMuIgcYxk8dO/8AOlVmf5tqEZwcryQPx+tMCZk80ZC/KqgEHqRnrToijRsSvOez5AGP896YQcZUAHjaAD19T3x+VTM/loTg9MrnuPQ/57UxDVJjy7cEkjlcY/L+ooZnXadisDlWHUkHpx9e9MX7rcnB5A689+tPOxAwy2McZyQe/T+tMBJw3+pjzuydh25A/X6UBdiAngqcHdn0z169KfHkkyOigfxAHnjsacoR4gVfBPQoOBnn+eaLACyH52IBLMTweAc+3+c0iMZAzckPzkc9sd+v8qAuShXJyORt/Ef596kO3CupYnGRkDtjv25/GgBRvk+4nJ4VQM7sdunt/ns/cWTYxDEEADpu+g/z1pknLlsY4wQp/n9aJGLuOFPfBGCf/rc0wHZZ8YKquD8p64ODTkO05GR1AHTjv+n8/ao0Bf51VR6Z4pyIBlA+3d0wOR+HfpQAqyKcgIpPUj3FSqTuBJAQMScdcce3vUIL7sAN8wwOcZ60jPyFdi3UggjnPXI/z0oAkdjHKxZNozkHg4/X2/8A1U47SdrAEAAqWGMY6fr3piZJKjcVVeCOucelPVjHggdy3TIz6UAPD7kB3grkDH93HP8An/8AXT96iNmA68Y9R7fX/OajBBQbiAMcEdBRgxn5gCCOoPagBQpTGGKcc4I6f5/lRlnKjI5Jyf50kfPGAqDocn+tJ5hC5yNzKOcfpQBwsNxMAAruBnPWukuL2JYLY58yR1DFR2rlxlixJztXNSwDzHXsMYxmuGrh4VGuZDsdhBPaTkJHMN2BweKdPb7CXZgq+pNcjBuVgwbB68Vs3969xb2occhOeeD+FcksAudWegrGgAsmNrhge4PWpWtiyBsdDXPQytHOoUkELnOf8K2JL+U2ZXoxXlhSq4F/Zd0JRsyreSEXz7cAfdz6/X/PeoH3OF2ll7Z7Z4zUska7FcZBMeWOeTUSuc47DivUgrRSKtYZ8wbnBBG0du9Sx8xhnU5zkHHBpNu9S5JG07OvpQjEQbgT12cnr15/SrAmTkjcpYrjaCMdM1KU4G1VJ6hlBweaYM7S3G71I6D2prPycrkqM89/84pgTNjOSd55PXNAZwOV+78o4zj3/SmgqYQdudpxzycYz/jUm5mIJIyBngcfSmITcuSAcKM5OACCPcc+p5pSMocOoIJG3uff/PpTG3GXORycYx05Ip8qlH4IzuxnFAxw2nDqgBHXaOc+v61Ko8xsOAwIIH97b2/rUZxtBweWGMHpkZpWGCR74444/wAimIGZRnZgdwCccewojICZYsATu5PTvTUbcTkcg4yepzmnMuAzgn6f5+lADwGXI5BOMn1+tKSUOCSW6H396iyYy5BOFHTPtT48syhjnj9KAJNpcEnHykcg54P0oJGQAoHYhfT1/n+dI5KgYIy4yePWlZmbgnkgYOOnIoAAGC9mU9RjH8utSEESCRiArAjp0zkVEQryqGyckLkn1OPxqaMBmdOgXj+tACluATtLMeuOR+v0pSTgZBDA/Kc8UgTc8Z4Af+EDgc0nUjJOMDgds4/x/SgAY7Cwxj6nr2p+9jzjA9OeKbJLnjHPOD6YH/66dn96q+pC5oAaD06uRwAegpJCZHJxkk8EDpSNEgHAxg9umaQtmQJyOT3oA//Z\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c_25', '69165975-b7d8-4edd-8516-6218f2c6560b___UMD_Powd.M 9877.JPG']\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c_37', 'd88b90c0-2850-425d-af82-7bfb0f6a9dd4___GH_HL Leaf 361.JPG']\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c_11', '50911cb0-4fc0-4403-b42d-d21b60b76ed6___FAM_B.Rot 0422.JPG']\n"
     ]
    }
   ],
   "source": [
    "rootDir = 'crowdai'\n",
    "data_root = pathlib.Path(rootDir)\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "for i in range(0,3):\n",
    "    image_example = str(random.choice(all_image_paths))\n",
    "    display.display(display.Image(image_example))\n",
    "    print(image_example.split(\"/\")[-2:])\n",
    "# The first value correspond to folder name and it is its label, next values is the file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value correspond image folder name and it's its label, and next value is the file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and create labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create function to read the files in root, and get a list with labels and image names.\n",
    "\n",
    "After several attempts, and try different aproach, I  choose this way, because the way of dataframe was created keep the same read system order, because the classes or labels are in the same order that jupyter is reading the data, and the code is more clean than other approachs I did tested. I like this consistency, even though the data reading is more slow, but I'm keeping this approach for this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_labels(rootDir):\n",
    "    '''\n",
    "    From a given root, this function return a pandas dataframe with the classes and file names\n",
    "    The data read is slow but it garanties the order in pandas, as pc read the files.\n",
    "    inpu:\n",
    "        rootDir: Root dir which contains the files by classes folder names\n",
    "    return:\n",
    "        d: Is an empty dataframe, wich is populated by files names and ist respective classes.\n",
    "    '''\n",
    "    df = pd.DataFrame()   \n",
    "    idx = 0 \n",
    "    for lists in os.listdir(rootDir): \n",
    "        path = os.path.join(rootDir, lists)\n",
    "        aux_list = []\n",
    "        for path, dirs, files in os.walk(path):\n",
    "            key = path.split(\"/\")[-1:][0]\n",
    "            for file in files:\n",
    "                temp = pd.DataFrame({'label': key, 'img':file},index=[idx])\n",
    "                idx +=1\n",
    "                df = pd.concat([df, temp])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next are the function test, in order to get classes and files names from folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c_1</td>\n",
       "      <td>f2b57a5b-f46d-453a-bb33-21d01d8a10de___JR_FrgE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_1</td>\n",
       "      <td>73b7ad12-02d0-4775-8f51-c7d404177132___JR_FrgE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c_1</td>\n",
       "      <td>50afe8c7-d56e-4dd0-97b8-23a70ddca819___JR_FrgE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_1</td>\n",
       "      <td>1ce4ecdf-fe69-42df-a0dc-c90f5495e7a1___JR_FrgE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_1</td>\n",
       "      <td>464511a6-77d9-493f-bb3c-f151fb390f1b___JR_FrgE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                img\n",
       "0   c_1  f2b57a5b-f46d-453a-bb33-21d01d8a10de___JR_FrgE...\n",
       "1   c_1  73b7ad12-02d0-4775-8f51-c7d404177132___JR_FrgE...\n",
       "2   c_1  50afe8c7-d56e-4dd0-97b8-23a70ddca819___JR_FrgE...\n",
       "3   c_1  1ce4ecdf-fe69-42df-a0dc-c90f5495e7a1___JR_FrgE...\n",
       "4   c_1  464511a6-77d9-493f-bb3c-f151fb390f1b___JR_FrgE..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_labels(rootDir)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file function\n",
    "\n",
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (64, 64), cv2.INTER_LINEAR)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file read checking\n",
    "path = '../crowdai/c_1/f2b57a5b-f46d-453a-bb33-21d01d8a10de___JR_FrgE.S 3036.JPG'\n",
    "a = cv2.imread(path)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data vectors load function\n",
    "# source: https://www.kaggle.com/satian/keras-mobilenet-starter\n",
    "\n",
    "def load_img(df):\n",
    "    '''\n",
    "    '''    \n",
    "    m = df.shape[0]\n",
    "    X = np.zeros((m, 64, 64, 3))\n",
    "    count = 0\n",
    "    for i in range(0,m):\n",
    "        img = image.load_img(rootDir+\"/\"+df.ix[i][0]+\"/\"+df.ix[i][1], target_size=(64, 64, 3))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "        X[count] = x\n",
    "        if (count%1000 == 0):\n",
    "            print(\"Processing image: \", count+1, \", \", df['img'][i])\n",
    "        count += 1\n",
    "    label = list(df)[0]\n",
    "    values = np.array(df[label])\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    y = onehot_encoded    \n",
    "    \n",
    "    return X, y, label_encoder\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Data set construction\n",
    "X, y, label_encoder = load_img(df)\n",
    "\n",
    "# Data set normalization\n",
    "X/=255\n",
    "\n",
    "# Shape controls\n",
    "print('X matrix shape', X.shape)\n",
    "print('y vector shape', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data drop\n",
    "\n",
    "As experiment accuracy doesn't improve, this was 0.10 in average.  Maybe it must because data classes are imbalanced, as you can see in the next tables. In order to surpase this, I will try increasing the number of images repeating the numbers of images accord to proportion of the maximum images class.  First, I compute the number of times a class has with respect the maximum number image per class.  Then i will copy many times the class as it is in the minimum number of image in a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c_15</td>\n",
       "      <td>2321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>c_35</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c_24</td>\n",
       "      <td>1917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c_16</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>c_28</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>c_25</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>c_32</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>c_30</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>c_33</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>c_3</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>c_37</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>c_4</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c_19</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_12</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>c_34</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>c_8</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>c_5</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_11</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c_10</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c_18</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c_13</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c_20</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>c_29</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>c_26</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c_21</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>c_9</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>c_31</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>c_6</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_1</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c_0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>c_23</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>c_27</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>c_7</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c_14</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>c_36</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>c_2</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c_17</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>c_22</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   img\n",
       "7   c_15  2321\n",
       "29  c_35  2100\n",
       "17  c_24  1917\n",
       "8   c_16   962\n",
       "21  c_28   792\n",
       "18  c_25   749\n",
       "26  c_32   734\n",
       "24  c_30   726\n",
       "27  c_33   720\n",
       "23   c_3   713\n",
       "31  c_37   643\n",
       "32   c_4   586\n",
       "11  c_19   577\n",
       "4   c_12   552\n",
       "28  c_34   547\n",
       "36   c_8   519\n",
       "33   c_5   510\n",
       "3   c_11   476\n",
       "2   c_10   445\n",
       "10  c_18   428\n",
       "5   c_13   420\n",
       "13  c_20   412\n",
       "22  c_29   405\n",
       "19  c_26   390\n",
       "14  c_21   380\n",
       "37   c_9   374\n",
       "25  c_31   360\n",
       "34   c_6   358\n",
       "1    c_1   280\n",
       "0    c_0   270\n",
       "16  c_23   240\n",
       "20  c_27   214\n",
       "35   c_7   191\n",
       "6   c_14   171\n",
       "30  c_36   139\n",
       "12   c_2   124\n",
       "9   c_17   108\n",
       "15  c_22    64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = df.groupby(['label']).count().reset_index().copy().sort_values('img', ascending=False)\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f90584c6748>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_grouped.plot.bar(x ='label', figsize=(18,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>576.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>505.201027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>299.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>436.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>695.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2321.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               img\n",
       "count    38.000000\n",
       "mean    576.763158\n",
       "std     505.201027\n",
       "min      64.000000\n",
       "25%     299.500000\n",
       "50%     436.500000\n",
       "75%     695.500000\n",
       "max    2321.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is completely imbalanced, for that reason, must be find an approach to handle with this imbalances before the feed the Neural network. \n",
    "\n",
    "https://towardsdatascience.com/handling-imbalanced-datasets-in-deep-learning-f48407a0e758\n",
    "\n",
    "Oversampling with gans\n",
    "\n",
    "https://github.com/JeffersonLPLima/adversarial_oversampling\n",
    "\n",
    "\n",
    "https://medium.com/neuralspace/kaggle-1-winning-approach-for-image-classification-challenge-9c1188157a86\n",
    "\n",
    "\n",
    "https://github.com/kumar-shridhar/CNN_Architectures/blob/master/Resnet50/resnet50.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I make a copy of dataframe with file data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 695\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695, 2)\n",
      "(695, 2)\n",
      "(695, 2)\n",
      "(1390, 2)\n",
      "(695, 2)\n",
      "(2085, 2)\n",
      "(695, 2)\n",
      "(2780, 2)\n",
      "(695, 2)\n",
      "(3475, 2)\n",
      "(695, 2)\n",
      "(4170, 2)\n",
      "(695, 2)\n",
      "(4865, 2)\n",
      "(695, 2)\n",
      "(5560, 2)\n",
      "(695, 2)\n",
      "(6255, 2)\n",
      "(695, 2)\n",
      "(6950, 2)\n",
      "(643, 2)\n",
      "(7593, 2)\n",
      "(586, 2)\n",
      "(8179, 2)\n",
      "(577, 2)\n",
      "(8756, 2)\n",
      "(552, 2)\n",
      "(9308, 2)\n",
      "(547, 2)\n",
      "(9855, 2)\n",
      "(519, 2)\n",
      "(10374, 2)\n",
      "(510, 2)\n",
      "(10884, 2)\n",
      "(476, 2)\n",
      "(11360, 2)\n",
      "(445, 2)\n",
      "(11805, 2)\n",
      "(428, 2)\n",
      "(12233, 2)\n",
      "(420, 2)\n",
      "(12653, 2)\n",
      "(412, 2)\n",
      "(13065, 2)\n",
      "(405, 2)\n",
      "(13470, 2)\n",
      "(390, 2)\n",
      "(13860, 2)\n",
      "(380, 2)\n",
      "(14240, 2)\n",
      "(374, 2)\n",
      "(14614, 2)\n",
      "(360, 2)\n",
      "(14974, 2)\n",
      "(358, 2)\n",
      "(15332, 2)\n",
      "(280, 2)\n",
      "(15612, 2)\n",
      "(270, 2)\n",
      "(15882, 2)\n",
      "(240, 2)\n",
      "(16122, 2)\n",
      "(214, 2)\n",
      "(16336, 2)\n",
      "(191, 2)\n",
      "(16527, 2)\n",
      "(171, 2)\n",
      "(16698, 2)\n",
      "(139, 2)\n",
      "(16837, 2)\n",
      "(124, 2)\n",
      "(16961, 2)\n",
      "(108, 2)\n",
      "(17069, 2)\n",
      "(64, 2)\n",
      "(17133, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17133, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 =pd.DataFrame(columns=['label','img'])\n",
    "for index,row in df_grouped.iterrows():\n",
    "    df_aux = df[df.label == row['label']].copy()\n",
    "    if len(df_aux) > k:\n",
    "        df_sample = df_aux.sample(n=k).reset_index(drop=True)\n",
    "    else:\n",
    "        df_sample = df_aux\n",
    "    print(df_sample.shape)\n",
    "    df2 = df2.append(df_sample,ignore_index=True)\n",
    "    #df_n = pd.concat([df2, df_n_aux],ignore_index=True) \n",
    "    print(df2.shape)\n",
    "\n",
    "    \n",
    "df2.shape\n",
    "        #pd.concat([df]*3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17133, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>c_30</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>c_32</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>c_3</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>c_28</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>c_33</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>c_25</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c_24</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c_15</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c_16</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>c_35</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>c_37</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>c_4</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c_19</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_12</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>c_34</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>c_8</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>c_5</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_11</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c_10</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c_18</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c_13</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c_20</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>c_29</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>c_26</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c_21</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>c_9</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>c_31</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>c_6</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_1</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c_0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>c_23</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>c_27</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>c_7</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c_14</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>c_36</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>c_2</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c_17</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>c_22</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  img\n",
       "24  c_30  695\n",
       "26  c_32  695\n",
       "23   c_3  695\n",
       "21  c_28  695\n",
       "27  c_33  695\n",
       "18  c_25  695\n",
       "17  c_24  695\n",
       "7   c_15  695\n",
       "8   c_16  695\n",
       "29  c_35  695\n",
       "31  c_37  643\n",
       "32   c_4  586\n",
       "11  c_19  577\n",
       "4   c_12  552\n",
       "28  c_34  547\n",
       "36   c_8  519\n",
       "33   c_5  510\n",
       "3   c_11  476\n",
       "2   c_10  445\n",
       "10  c_18  428\n",
       "5   c_13  420\n",
       "13  c_20  412\n",
       "22  c_29  405\n",
       "19  c_26  390\n",
       "14  c_21  380\n",
       "37   c_9  374\n",
       "25  c_31  360\n",
       "34   c_6  358\n",
       "1    c_1  280\n",
       "0    c_0  270\n",
       "16  c_23  240\n",
       "20  c_27  214\n",
       "35   c_7  191\n",
       "6   c_14  171\n",
       "30  c_36  139\n",
       "12   c_2  124\n",
       "9   c_17  108\n",
       "15  c_22   64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped2 = df2.groupby(['label']).count().reset_index().copy().sort_values('img', ascending=False)\n",
    "df_grouped2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>450.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>202.126422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>299.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>436.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>682.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>695.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              img\n",
       "count   38.000000\n",
       "mean   450.868421\n",
       "std    202.126422\n",
       "min     64.000000\n",
       "25%    299.500000\n",
       "50%    436.500000\n",
       "75%    682.000000\n",
       "max    695.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped2.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://github.com/09rohanchopra/cifar10/blob/master/helper.py\n",
    "# https://www.kaggle.com/satian/keras-mobilenet-starter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(0,len(df)):\n",
    "    print(df.ix[i][0],df.ix[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image:  1 ,  926e099c-8d2a-4d4b-8cb5-a5be62e25f2e___UF.Citrus_HLB_Lab 1159.JPG\n",
      "Processing image:  1001 ,  2567dfac-4dbf-4ad8-a538-e239f15cefb0___YLCV_NREC 2337.JPG\n",
      "Processing image:  2001 ,  1b283b99-e33d-4b1d-baf3-aa3d06305d1c___RS_HL 4286.JPG\n",
      "Processing image:  3001 ,  53a586ef-8136-4f96-929e-f51c590a628c___UF.GRC_BS_Lab Leaf 0769.JPG\n",
      "Processing image:  4001 ,  b51d73d1-874c-497b-8a84-e7317e27c871___UMD_Powd.M 9801.JPG\n",
      "Processing image:  5001 ,  1f8743b6-f385-4464-9e41-48bd9fe85637___GHLB2 Leaf 8914.JPG\n",
      "Processing image:  6001 ,  6eb67c67-b362-4be2-8257-27c8aba346d6___Com.G_SpM_FL 8907.JPG\n",
      "Processing image:  7001 ,  30c8f7b8-e0cf-4cfb-b7fe-e2b75ce22789___GH_HL Leaf 333.1.JPG\n",
      "Processing image:  8001 ,  44429437-288d-44cf-9aee-cdc89b7dc1ec___RS_HL 5397.JPG\n",
      "Processing image:  9001 ,  3306483f-5feb-42e3-9c39-0a0b29ac1959___FAM_B.Msls 1767.JPG\n",
      "Processing image:  10001 ,  5d94d29c-5831-4b75-bf31-0598e61b9bd1___RS_Rust 2028.JPG\n",
      "Processing image:  11001 ,  9a668952-936a-4d6e-8cda-31f4dcd95a6b___FAM_B.Rot 0458.JPG\n",
      "Processing image:  12001 ,  e5781299-7fd6-4d80-aca1-d78910d9da1c___JR_B.Spot 3371.JPG\n",
      "Processing image:  13001 ,  d0221e13-4d76-45e5-9cd1-7cac63833f52___RS_Early.B 7191.JPG\n",
      "Processing image:  14001 ,  d648ee66-d38a-4df0-8696-c6fe5490a15b___RS_LB 4144.JPG\n",
      "Processing image:  15001 ,  69de380a-4fd8-4c50-bdff-a983495dcd8c___JR_HL 4175.JPG\n",
      "Processing image:  16001 ,  e3e3cd97-a57b-417b-b57d-e3934e2840e3___Mary_HL 6327.JPG\n",
      "Processing image:  17001 ,  3658d11f-3a09-43ce-bace-391510b30737___Rutg._HL 3569.JPG\n"
     ]
    }
   ],
   "source": [
    "X, y, label_encoder = load_img(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, NUM_CLASSES = y.shape\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Standarization\n",
    "\n",
    "data_generator = image.ImageDataGenerator(rescale=1./255,\n",
    "                                          rotation_range=75,\n",
    "                                          width_shift_range=0.2,\n",
    "                                          height_shift_range=0.2,\n",
    "                                          featurewise_center=True,\n",
    "                                          featurewise_std_normalization=True,\n",
    "                                          horizontal_flip=True,\n",
    "                                          zoom_range=0.3,\n",
    "                                          samplewise_std_normalization=True)\n",
    "\n",
    "data_generator.fit(X_train)\n",
    "\n",
    "# standardize the test set\n",
    "for i in range(len(X_test)):\n",
    "    X_test[i] = data_generator.standardize(X_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://github.com/kumar-shridhar/CNN_Architectures/blob/master/Resnet50/resnet50.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Mobilnet model\n",
    "model = MobileNet(input_shape=(100, 100, 3), alpha=1., weights=None, classes=38)\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first mode to train is a Resnet 50 with original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 70, 70, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 32, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 32, 32, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 34, 34, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 16, 16, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 16, 16, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 16, 16, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 16, 16, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16, 16, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 16, 16, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 16, 16, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 16, 16, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 16, 16, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 16, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 16, 16, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 16, 16, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 16, 16, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 16, 16, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 16, 16, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 16, 16, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 16, 16, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 16, 16, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 16, 16, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 16, 16, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 16, 16, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 16, 16, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 8, 8, 128)    32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 8, 8, 512)    131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 8, 8, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 4, 4, 256)    131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 4, 4, 1024)   525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 4, 4, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 4, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 4, 4, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 4, 4, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 4, 4, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 4, 4, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 4, 4, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 4, 4, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 4, 4, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 4, 4, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 1024)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 2, 2, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 2, 2, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 2, 2, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Resnet50 model\n",
    "base_model = ResNet50(input_shape=(64, 64, 3),include_top=False,weights= 'imagenet')\n",
    "\n",
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "history = model.fit(X_train, y_train, epochs=180, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/amadeus1996/fruits-360-transfer-learning-using-keras\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "# add a fully-connected layer\n",
    "#x = Dense(512, activation='relu')(x)\n",
    "# and a fully connected output/classification layer\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "# create the full network so we can train on it\n",
    "inception_transfer = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_transfer.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2500\n",
      "53/53 [==============================] - 22s 417ms/step - loss: 1.9091 - acc: 0.5369 - val_loss: 0.9820 - val_acc: 0.7193\n",
      "Epoch 2/2500\n",
      "53/53 [==============================] - 15s 279ms/step - loss: 0.8688 - acc: 0.7559 - val_loss: 0.6322 - val_acc: 0.8337\n",
      "Epoch 3/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.7962 - acc: 0.7722 - val_loss: 0.4669 - val_acc: 0.8666\n",
      "Epoch 4/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.5949 - acc: 0.8373 - val_loss: 0.4330 - val_acc: 0.8891\n",
      "Epoch 5/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.8152 - acc: 0.7711 - val_loss: 0.5115 - val_acc: 0.8480\n",
      "Epoch 6/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.7769 - acc: 0.7874 - val_loss: 0.8784 - val_acc: 0.7917\n",
      "Epoch 7/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.9680 - acc: 0.7315 - val_loss: 0.6360 - val_acc: 0.8153\n",
      "Epoch 8/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.7957 - acc: 0.7693 - val_loss: 0.4982 - val_acc: 0.8453\n",
      "Epoch 9/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.5834 - acc: 0.8260 - val_loss: 0.4831 - val_acc: 0.8529\n",
      "Epoch 10/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.5453 - acc: 0.8293 - val_loss: 0.3459 - val_acc: 0.8885\n",
      "Epoch 11/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.3518 - acc: 0.8806 - val_loss: 0.2383 - val_acc: 0.9224\n",
      "Epoch 12/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.2751 - acc: 0.9086 - val_loss: 0.2073 - val_acc: 0.9285\n",
      "Epoch 13/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.2565 - acc: 0.9135 - val_loss: 0.1869 - val_acc: 0.9448\n",
      "Epoch 14/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.2437 - acc: 0.9169 - val_loss: 0.1857 - val_acc: 0.9411\n",
      "Epoch 15/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.2086 - acc: 0.9299 - val_loss: 0.1881 - val_acc: 0.9411\n",
      "Epoch 16/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.1844 - acc: 0.9367 - val_loss: 0.1884 - val_acc: 0.9437\n",
      "Epoch 17/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.1805 - acc: 0.9399 - val_loss: 0.1738 - val_acc: 0.9434\n",
      "Epoch 18/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1728 - acc: 0.9404 - val_loss: 0.1517 - val_acc: 0.9513\n",
      "Epoch 19/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1621 - acc: 0.9445 - val_loss: 0.1733 - val_acc: 0.9454\n",
      "Epoch 20/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1561 - acc: 0.9465 - val_loss: 0.1360 - val_acc: 0.9565\n",
      "Epoch 21/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.1341 - acc: 0.9540 - val_loss: 0.1333 - val_acc: 0.9591\n",
      "Epoch 22/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1456 - acc: 0.9515 - val_loss: 0.1366 - val_acc: 0.9554\n",
      "Epoch 23/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1366 - acc: 0.9542 - val_loss: 0.1568 - val_acc: 0.9475\n",
      "Epoch 24/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.2062 - acc: 0.9355 - val_loss: 0.3275 - val_acc: 0.8938\n",
      "Epoch 25/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.2593 - acc: 0.9165 - val_loss: 0.1404 - val_acc: 0.9504\n",
      "Epoch 26/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1717 - acc: 0.9419 - val_loss: 0.1494 - val_acc: 0.9527\n",
      "Epoch 27/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1537 - acc: 0.9474 - val_loss: 0.1414 - val_acc: 0.9536\n",
      "Epoch 28/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1315 - acc: 0.9556 - val_loss: 0.1456 - val_acc: 0.9554\n",
      "Epoch 29/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.1218 - acc: 0.9597 - val_loss: 0.1261 - val_acc: 0.9618\n",
      "Epoch 30/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1102 - acc: 0.9623 - val_loss: 0.1163 - val_acc: 0.9609\n",
      "Epoch 31/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1073 - acc: 0.9654 - val_loss: 0.1095 - val_acc: 0.9612\n",
      "Epoch 32/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1036 - acc: 0.9647 - val_loss: 0.0942 - val_acc: 0.9688\n",
      "Epoch 33/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0984 - acc: 0.9672 - val_loss: 0.1107 - val_acc: 0.9635\n",
      "Epoch 34/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1133 - acc: 0.9612 - val_loss: 0.1135 - val_acc: 0.9626\n",
      "Epoch 35/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0902 - acc: 0.9684 - val_loss: 0.1025 - val_acc: 0.9662\n",
      "Epoch 36/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0901 - acc: 0.9704 - val_loss: 0.1173 - val_acc: 0.9586\n",
      "Epoch 37/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1012 - acc: 0.9650 - val_loss: 0.1268 - val_acc: 0.9612\n",
      "Epoch 38/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0923 - acc: 0.9687 - val_loss: 0.1314 - val_acc: 0.9591\n",
      "Epoch 39/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1021 - acc: 0.9659 - val_loss: 0.1125 - val_acc: 0.9626\n",
      "Epoch 40/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0837 - acc: 0.9709 - val_loss: 0.1017 - val_acc: 0.9650\n",
      "Epoch 41/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0881 - acc: 0.9696 - val_loss: 0.1048 - val_acc: 0.9644\n",
      "Epoch 42/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0815 - acc: 0.9738 - val_loss: 0.0959 - val_acc: 0.9699\n",
      "Epoch 43/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0950 - acc: 0.9701 - val_loss: 0.0964 - val_acc: 0.9708\n",
      "Epoch 44/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0845 - acc: 0.9720 - val_loss: 0.1044 - val_acc: 0.9679\n",
      "Epoch 45/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0689 - acc: 0.9771 - val_loss: 0.0991 - val_acc: 0.9697\n",
      "Epoch 46/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0727 - acc: 0.9752 - val_loss: 0.0985 - val_acc: 0.9714\n",
      "Epoch 47/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0782 - acc: 0.9740 - val_loss: 0.0998 - val_acc: 0.9679\n",
      "Epoch 48/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0828 - acc: 0.9728 - val_loss: 0.1234 - val_acc: 0.9589\n",
      "Epoch 49/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0797 - acc: 0.9729 - val_loss: 0.1026 - val_acc: 0.9676\n",
      "Epoch 50/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0828 - acc: 0.9707 - val_loss: 0.0912 - val_acc: 0.9685\n",
      "Epoch 51/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0910 - acc: 0.9695 - val_loss: 0.1290 - val_acc: 0.9612\n",
      "Epoch 52/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.1189 - acc: 0.9637 - val_loss: 0.1133 - val_acc: 0.9594\n",
      "Epoch 53/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0879 - acc: 0.9710 - val_loss: 0.1063 - val_acc: 0.9647\n",
      "Epoch 54/2500\n",
      "53/53 [==============================] - 14s 270ms/step - loss: 0.0826 - acc: 0.9734 - val_loss: 0.1232 - val_acc: 0.9670\n",
      "Epoch 55/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.0884 - acc: 0.9724 - val_loss: 0.0817 - val_acc: 0.9732\n",
      "Epoch 56/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0725 - acc: 0.9755 - val_loss: 0.0883 - val_acc: 0.9705\n",
      "Epoch 57/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0758 - acc: 0.9746 - val_loss: 0.0972 - val_acc: 0.9699\n",
      "Epoch 58/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0823 - acc: 0.9714 - val_loss: 0.1027 - val_acc: 0.9697\n",
      "Epoch 59/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0796 - acc: 0.9729 - val_loss: 0.1023 - val_acc: 0.9708\n",
      "Epoch 60/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0809 - acc: 0.9752 - val_loss: 0.0822 - val_acc: 0.9755\n",
      "Epoch 61/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0764 - acc: 0.9747 - val_loss: 0.0917 - val_acc: 0.9726\n",
      "Epoch 62/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0720 - acc: 0.9764 - val_loss: 0.0938 - val_acc: 0.9691\n",
      "Epoch 63/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0754 - acc: 0.9745 - val_loss: 0.0847 - val_acc: 0.9746\n",
      "Epoch 64/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0683 - acc: 0.9780 - val_loss: 0.1009 - val_acc: 0.9702\n",
      "Epoch 65/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0802 - acc: 0.9754 - val_loss: 0.0759 - val_acc: 0.9740\n",
      "Epoch 66/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0668 - acc: 0.9780 - val_loss: 0.0731 - val_acc: 0.9769\n",
      "Epoch 67/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0676 - acc: 0.9775 - val_loss: 0.0956 - val_acc: 0.9705\n",
      "Epoch 68/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0741 - acc: 0.9757 - val_loss: 0.0825 - val_acc: 0.9752\n",
      "Epoch 69/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0657 - acc: 0.9789 - val_loss: 0.0810 - val_acc: 0.9778\n",
      "Epoch 70/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0615 - acc: 0.9804 - val_loss: 0.0912 - val_acc: 0.9705\n",
      "Epoch 71/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0732 - acc: 0.9767 - val_loss: 0.0898 - val_acc: 0.9705\n",
      "Epoch 72/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0618 - acc: 0.9786 - val_loss: 0.0820 - val_acc: 0.9737\n",
      "Epoch 73/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0660 - acc: 0.9772 - val_loss: 0.0967 - val_acc: 0.9720\n",
      "Epoch 74/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0596 - acc: 0.9817 - val_loss: 0.0829 - val_acc: 0.9761\n",
      "Epoch 75/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0515 - acc: 0.9826 - val_loss: 0.0931 - val_acc: 0.9711\n",
      "Epoch 76/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0611 - acc: 0.9793 - val_loss: 0.0886 - val_acc: 0.9717\n",
      "Epoch 77/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0734 - acc: 0.9762 - val_loss: 0.0802 - val_acc: 0.9729\n",
      "Epoch 78/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0625 - acc: 0.9784 - val_loss: 0.0749 - val_acc: 0.9752\n",
      "Epoch 79/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0572 - acc: 0.9811 - val_loss: 0.0753 - val_acc: 0.9732\n",
      "Epoch 80/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0808 - acc: 0.9745 - val_loss: 0.0771 - val_acc: 0.9755\n",
      "Epoch 81/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0731 - acc: 0.9762 - val_loss: 0.0955 - val_acc: 0.9679\n",
      "Epoch 82/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0588 - acc: 0.9798 - val_loss: 0.0751 - val_acc: 0.9764\n",
      "Epoch 83/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0726 - acc: 0.9773 - val_loss: 0.0949 - val_acc: 0.9682\n",
      "Epoch 84/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0690 - acc: 0.9769 - val_loss: 0.0860 - val_acc: 0.9743\n",
      "Epoch 85/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0681 - acc: 0.9784 - val_loss: 0.0999 - val_acc: 0.9708\n",
      "Epoch 86/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0775 - acc: 0.9746 - val_loss: 0.0778 - val_acc: 0.9767\n",
      "Epoch 87/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0550 - acc: 0.9820 - val_loss: 0.0732 - val_acc: 0.9778\n",
      "Epoch 88/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0641 - acc: 0.9796 - val_loss: 0.0823 - val_acc: 0.9764\n",
      "Epoch 89/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0543 - acc: 0.9823 - val_loss: 0.0937 - val_acc: 0.9743\n",
      "Epoch 90/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0604 - acc: 0.9799 - val_loss: 0.0957 - val_acc: 0.9740\n",
      "Epoch 91/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0542 - acc: 0.9824 - val_loss: 0.0793 - val_acc: 0.9761\n",
      "Epoch 92/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0575 - acc: 0.9802 - val_loss: 0.0853 - val_acc: 0.9740\n",
      "Epoch 93/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0644 - acc: 0.9775 - val_loss: 0.0815 - val_acc: 0.9729\n",
      "Epoch 94/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0592 - acc: 0.9807 - val_loss: 0.0709 - val_acc: 0.9775\n",
      "Epoch 95/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0522 - acc: 0.9820 - val_loss: 0.0867 - val_acc: 0.9734\n",
      "Epoch 96/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0541 - acc: 0.9818 - val_loss: 0.0799 - val_acc: 0.9767\n",
      "Epoch 97/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0566 - acc: 0.9812 - val_loss: 0.0864 - val_acc: 0.9740\n",
      "Epoch 98/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0467 - acc: 0.9840 - val_loss: 0.0813 - val_acc: 0.9758\n",
      "Epoch 99/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0588 - acc: 0.9804 - val_loss: 0.1011 - val_acc: 0.9694\n",
      "Epoch 100/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0542 - acc: 0.9820 - val_loss: 0.0852 - val_acc: 0.9732\n",
      "Epoch 101/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0576 - acc: 0.9814 - val_loss: 0.0988 - val_acc: 0.9702\n",
      "Epoch 102/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0620 - acc: 0.9805 - val_loss: 0.0858 - val_acc: 0.9740\n",
      "Epoch 103/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0514 - acc: 0.9828 - val_loss: 0.0912 - val_acc: 0.9708\n",
      "Epoch 104/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0560 - acc: 0.9820 - val_loss: 0.0980 - val_acc: 0.9740\n",
      "Epoch 105/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0522 - acc: 0.9823 - val_loss: 0.0868 - val_acc: 0.9729\n",
      "Epoch 106/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0545 - acc: 0.9832 - val_loss: 0.0928 - val_acc: 0.9705\n",
      "Epoch 107/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0625 - acc: 0.9818 - val_loss: 0.1036 - val_acc: 0.9711\n",
      "Epoch 108/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0624 - acc: 0.9824 - val_loss: 0.1107 - val_acc: 0.9662\n",
      "Epoch 109/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0653 - acc: 0.9802 - val_loss: 0.0961 - val_acc: 0.9737\n",
      "Epoch 110/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0488 - acc: 0.9826 - val_loss: 0.0657 - val_acc: 0.9793\n",
      "Epoch 111/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0457 - acc: 0.9848 - val_loss: 0.0837 - val_acc: 0.9740\n",
      "Epoch 112/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0497 - acc: 0.9834 - val_loss: 0.0666 - val_acc: 0.9813\n",
      "Epoch 113/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0658 - acc: 0.9787 - val_loss: 0.0831 - val_acc: 0.9734\n",
      "Epoch 114/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0507 - acc: 0.9821 - val_loss: 0.0963 - val_acc: 0.9743\n",
      "Epoch 115/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0624 - acc: 0.9798 - val_loss: 0.0831 - val_acc: 0.9761\n",
      "Epoch 116/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0494 - acc: 0.9843 - val_loss: 0.0882 - val_acc: 0.9743\n",
      "Epoch 117/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0617 - acc: 0.9799 - val_loss: 0.0986 - val_acc: 0.9732\n",
      "Epoch 118/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0561 - acc: 0.9820 - val_loss: 0.0913 - val_acc: 0.9743\n",
      "Epoch 119/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0495 - acc: 0.9842 - val_loss: 0.0946 - val_acc: 0.9758\n",
      "Epoch 120/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0528 - acc: 0.9830 - val_loss: 0.0946 - val_acc: 0.9714\n",
      "Epoch 121/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0531 - acc: 0.9829 - val_loss: 0.0793 - val_acc: 0.9778\n",
      "Epoch 122/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0551 - acc: 0.9831 - val_loss: 0.0931 - val_acc: 0.9723\n",
      "Epoch 123/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0497 - acc: 0.9837 - val_loss: 0.1027 - val_acc: 0.9740\n",
      "Epoch 124/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0646 - acc: 0.9793 - val_loss: 0.1038 - val_acc: 0.9714\n",
      "Epoch 125/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0521 - acc: 0.9835 - val_loss: 0.0907 - val_acc: 0.9781\n",
      "Epoch 126/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0487 - acc: 0.9840 - val_loss: 0.0802 - val_acc: 0.9769\n",
      "Epoch 127/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0413 - acc: 0.9869 - val_loss: 0.0717 - val_acc: 0.9769\n",
      "Epoch 128/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0516 - acc: 0.9828 - val_loss: 0.0858 - val_acc: 0.9784\n",
      "Epoch 129/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0657 - acc: 0.9799 - val_loss: 0.0820 - val_acc: 0.9778\n",
      "Epoch 130/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0609 - acc: 0.9823 - val_loss: 0.1002 - val_acc: 0.9699\n",
      "Epoch 131/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0515 - acc: 0.9849 - val_loss: 0.0768 - val_acc: 0.9778\n",
      "Epoch 132/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0495 - acc: 0.9848 - val_loss: 0.0909 - val_acc: 0.9749\n",
      "Epoch 133/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0514 - acc: 0.9845 - val_loss: 0.0761 - val_acc: 0.9784\n",
      "Epoch 134/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0486 - acc: 0.9832 - val_loss: 0.0930 - val_acc: 0.9758\n",
      "Epoch 135/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0454 - acc: 0.9855 - val_loss: 0.0665 - val_acc: 0.9822\n",
      "Epoch 136/2500\n",
      "53/53 [==============================] - 14s 256ms/step - loss: 0.0454 - acc: 0.9850 - val_loss: 0.0757 - val_acc: 0.9775\n",
      "Epoch 137/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0714 - acc: 0.9796 - val_loss: 0.0865 - val_acc: 0.9749\n",
      "Epoch 138/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0638 - acc: 0.9815 - val_loss: 0.0732 - val_acc: 0.9790\n",
      "Epoch 139/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0608 - acc: 0.9832 - val_loss: 0.0698 - val_acc: 0.9804\n",
      "Epoch 140/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0455 - acc: 0.9849 - val_loss: 0.0723 - val_acc: 0.9802\n",
      "Epoch 141/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0529 - acc: 0.9828 - val_loss: 0.0755 - val_acc: 0.9790\n",
      "Epoch 142/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0467 - acc: 0.9848 - val_loss: 0.0675 - val_acc: 0.9822\n",
      "Epoch 143/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0425 - acc: 0.9867 - val_loss: 0.0830 - val_acc: 0.9781\n",
      "Epoch 144/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0492 - acc: 0.9848 - val_loss: 0.0679 - val_acc: 0.9813\n",
      "Epoch 145/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0413 - acc: 0.9863 - val_loss: 0.0756 - val_acc: 0.9772\n",
      "Epoch 146/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0397 - acc: 0.9874 - val_loss: 0.0796 - val_acc: 0.9764\n",
      "Epoch 147/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0397 - acc: 0.9879 - val_loss: 0.0683 - val_acc: 0.9807\n",
      "Epoch 148/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0347 - acc: 0.9892 - val_loss: 0.0720 - val_acc: 0.9796\n",
      "Epoch 149/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0317 - acc: 0.9895 - val_loss: 0.0724 - val_acc: 0.9816\n",
      "Epoch 150/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0381 - acc: 0.9878 - val_loss: 0.0851 - val_acc: 0.9764\n",
      "Epoch 151/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0381 - acc: 0.9889 - val_loss: 0.1057 - val_acc: 0.9737\n",
      "Epoch 152/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0478 - acc: 0.9850 - val_loss: 0.0925 - val_acc: 0.9758\n",
      "Epoch 153/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0448 - acc: 0.9847 - val_loss: 0.0815 - val_acc: 0.9764\n",
      "Epoch 154/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0544 - acc: 0.9833 - val_loss: 0.0983 - val_acc: 0.9699\n",
      "Epoch 155/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0538 - acc: 0.9847 - val_loss: 0.0856 - val_acc: 0.9737\n",
      "Epoch 156/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0485 - acc: 0.9850 - val_loss: 0.0788 - val_acc: 0.9758\n",
      "Epoch 157/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0313 - acc: 0.9888 - val_loss: 0.0859 - val_acc: 0.9790\n",
      "Epoch 158/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0399 - acc: 0.9880 - val_loss: 0.0757 - val_acc: 0.9796\n",
      "Epoch 159/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0311 - acc: 0.9904 - val_loss: 0.0706 - val_acc: 0.9799\n",
      "Epoch 160/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0385 - acc: 0.9863 - val_loss: 0.0763 - val_acc: 0.9784\n",
      "Epoch 161/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0513 - acc: 0.9843 - val_loss: 0.0780 - val_acc: 0.9784\n",
      "Epoch 162/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0539 - acc: 0.9836 - val_loss: 0.0807 - val_acc: 0.9761\n",
      "Epoch 163/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0433 - acc: 0.9876 - val_loss: 0.0780 - val_acc: 0.9778\n",
      "Epoch 164/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0439 - acc: 0.9856 - val_loss: 0.0831 - val_acc: 0.9767\n",
      "Epoch 165/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0451 - acc: 0.9844 - val_loss: 0.0913 - val_acc: 0.9787\n",
      "Epoch 166/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0519 - acc: 0.9853 - val_loss: 0.0662 - val_acc: 0.9825\n",
      "Epoch 167/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0338 - acc: 0.9887 - val_loss: 0.0644 - val_acc: 0.9840\n",
      "Epoch 168/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0316 - acc: 0.9893 - val_loss: 0.0847 - val_acc: 0.9799\n",
      "Epoch 169/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0378 - acc: 0.9872 - val_loss: 0.0800 - val_acc: 0.9796\n",
      "Epoch 170/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0407 - acc: 0.9874 - val_loss: 0.0793 - val_acc: 0.9787\n",
      "Epoch 171/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0341 - acc: 0.9896 - val_loss: 0.0802 - val_acc: 0.9767\n",
      "Epoch 172/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0409 - acc: 0.9886 - val_loss: 0.0903 - val_acc: 0.9743\n",
      "Epoch 173/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0443 - acc: 0.9854 - val_loss: 0.0725 - val_acc: 0.9807\n",
      "Epoch 174/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0395 - acc: 0.9875 - val_loss: 0.0716 - val_acc: 0.9799\n",
      "Epoch 175/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0302 - acc: 0.9899 - val_loss: 0.0757 - val_acc: 0.9781\n",
      "Epoch 176/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0355 - acc: 0.9893 - val_loss: 0.0818 - val_acc: 0.9787\n",
      "Epoch 177/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0352 - acc: 0.9891 - val_loss: 0.0738 - val_acc: 0.9802\n",
      "Epoch 178/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0291 - acc: 0.9901 - val_loss: 0.0705 - val_acc: 0.9813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0337 - acc: 0.9889 - val_loss: 0.0787 - val_acc: 0.9807\n",
      "Epoch 180/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0305 - acc: 0.9904 - val_loss: 0.0733 - val_acc: 0.9825\n",
      "Epoch 181/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0290 - acc: 0.9899 - val_loss: 0.0765 - val_acc: 0.9802\n",
      "Epoch 182/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0416 - acc: 0.9879 - val_loss: 0.0828 - val_acc: 0.9775\n",
      "Epoch 183/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0430 - acc: 0.9849 - val_loss: 0.0640 - val_acc: 0.9799\n",
      "Epoch 184/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0423 - acc: 0.9874 - val_loss: 0.0666 - val_acc: 0.9810\n",
      "Epoch 185/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0353 - acc: 0.9888 - val_loss: 0.0613 - val_acc: 0.9840\n",
      "Epoch 186/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0396 - acc: 0.9883 - val_loss: 0.0969 - val_acc: 0.9734\n",
      "Epoch 187/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0340 - acc: 0.9894 - val_loss: 0.0824 - val_acc: 0.9781\n",
      "Epoch 188/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0451 - acc: 0.9862 - val_loss: 0.0810 - val_acc: 0.9746\n",
      "Epoch 189/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0474 - acc: 0.9844 - val_loss: 0.0920 - val_acc: 0.9752\n",
      "Epoch 190/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0411 - acc: 0.9879 - val_loss: 0.0717 - val_acc: 0.9802\n",
      "Epoch 191/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0366 - acc: 0.9884 - val_loss: 0.0853 - val_acc: 0.9790\n",
      "Epoch 192/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0321 - acc: 0.9896 - val_loss: 0.0740 - val_acc: 0.9796\n",
      "Epoch 193/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0324 - acc: 0.9902 - val_loss: 0.0752 - val_acc: 0.9784\n",
      "Epoch 194/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0429 - acc: 0.9883 - val_loss: 0.0745 - val_acc: 0.9802\n",
      "Epoch 195/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0612 - acc: 0.9844 - val_loss: 0.0869 - val_acc: 0.9775\n",
      "Epoch 196/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.4420 - acc: 0.8955 - val_loss: 0.3026 - val_acc: 0.9367\n",
      "Epoch 197/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.3155 - acc: 0.9234 - val_loss: 0.2525 - val_acc: 0.9203\n",
      "Epoch 198/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.2487 - acc: 0.9307 - val_loss: 0.1792 - val_acc: 0.9440\n",
      "Epoch 199/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1723 - acc: 0.9537 - val_loss: 0.2591 - val_acc: 0.9314\n",
      "Epoch 200/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1653 - acc: 0.9510 - val_loss: 0.1935 - val_acc: 0.9545\n",
      "Epoch 201/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0915 - acc: 0.9720 - val_loss: 0.1010 - val_acc: 0.9702\n",
      "Epoch 202/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0631 - acc: 0.9784 - val_loss: 0.0864 - val_acc: 0.9734\n",
      "Epoch 203/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0453 - acc: 0.9841 - val_loss: 0.0942 - val_acc: 0.9749\n",
      "Epoch 204/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0443 - acc: 0.9849 - val_loss: 0.0853 - val_acc: 0.9787\n",
      "Epoch 205/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0323 - acc: 0.9889 - val_loss: 0.0795 - val_acc: 0.9793\n",
      "Epoch 206/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0345 - acc: 0.9881 - val_loss: 0.0773 - val_acc: 0.9778\n",
      "Epoch 207/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0391 - acc: 0.9878 - val_loss: 0.1154 - val_acc: 0.9723\n",
      "Epoch 208/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1200 - acc: 0.9752 - val_loss: 0.1221 - val_acc: 0.9761\n",
      "Epoch 209/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0586 - acc: 0.9837 - val_loss: 0.1133 - val_acc: 0.9702\n",
      "Epoch 210/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0600 - acc: 0.9816 - val_loss: 0.0890 - val_acc: 0.9749\n",
      "Epoch 211/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0467 - acc: 0.9865 - val_loss: 0.1042 - val_acc: 0.9752\n",
      "Epoch 212/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1241 - acc: 0.9629 - val_loss: 0.1218 - val_acc: 0.9673\n",
      "Epoch 213/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0744 - acc: 0.9775 - val_loss: 0.0806 - val_acc: 0.9729\n",
      "Epoch 214/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0489 - acc: 0.9843 - val_loss: 0.0921 - val_acc: 0.9758\n",
      "Epoch 215/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0365 - acc: 0.9886 - val_loss: 0.0755 - val_acc: 0.9752\n",
      "Epoch 216/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0360 - acc: 0.9896 - val_loss: 0.1016 - val_acc: 0.9699\n",
      "Epoch 217/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0969 - acc: 0.9732 - val_loss: 0.1326 - val_acc: 0.9714\n",
      "Epoch 218/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0954 - acc: 0.9748 - val_loss: 0.1181 - val_acc: 0.9694\n",
      "Epoch 219/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0471 - acc: 0.9847 - val_loss: 0.0928 - val_acc: 0.9758\n",
      "Epoch 220/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0308 - acc: 0.9902 - val_loss: 0.0855 - val_acc: 0.9764\n",
      "Epoch 221/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0264 - acc: 0.9909 - val_loss: 0.0877 - val_acc: 0.9737\n",
      "Epoch 222/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0274 - acc: 0.9915 - val_loss: 0.0895 - val_acc: 0.9758\n",
      "Epoch 223/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0285 - acc: 0.9905 - val_loss: 0.0858 - val_acc: 0.9769\n",
      "Epoch 224/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0253 - acc: 0.9912 - val_loss: 0.0996 - val_acc: 0.9772\n",
      "Epoch 225/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0254 - acc: 0.9915 - val_loss: 0.0870 - val_acc: 0.9772\n",
      "Epoch 226/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0299 - acc: 0.9907 - val_loss: 0.0835 - val_acc: 0.9790\n",
      "Epoch 227/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0286 - acc: 0.9915 - val_loss: 0.1055 - val_acc: 0.9761\n",
      "Epoch 228/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1000 - acc: 0.9731 - val_loss: 0.1180 - val_acc: 0.9685\n",
      "Epoch 229/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0583 - acc: 0.9836 - val_loss: 0.0883 - val_acc: 0.9778\n",
      "Epoch 230/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0327 - acc: 0.9896 - val_loss: 0.0848 - val_acc: 0.9778\n",
      "Epoch 231/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0342 - acc: 0.9892 - val_loss: 0.0844 - val_acc: 0.9802\n",
      "Epoch 232/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0294 - acc: 0.9910 - val_loss: 0.0871 - val_acc: 0.9784\n",
      "Epoch 233/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0228 - acc: 0.9924 - val_loss: 0.0702 - val_acc: 0.9822\n",
      "Epoch 234/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0301 - acc: 0.9905 - val_loss: 0.0605 - val_acc: 0.9822\n",
      "Epoch 235/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0322 - acc: 0.9898 - val_loss: 0.0706 - val_acc: 0.9816\n",
      "Epoch 236/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0223 - acc: 0.9931 - val_loss: 0.0732 - val_acc: 0.9810\n",
      "Epoch 237/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0196 - acc: 0.9931 - val_loss: 0.0610 - val_acc: 0.9822\n",
      "Epoch 238/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0244 - acc: 0.9913 - val_loss: 0.0704 - val_acc: 0.9793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0205 - acc: 0.9938 - val_loss: 0.0631 - val_acc: 0.9819\n",
      "Epoch 240/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0221 - acc: 0.9931 - val_loss: 0.0743 - val_acc: 0.9790\n",
      "Epoch 241/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0227 - acc: 0.9925 - val_loss: 0.0752 - val_acc: 0.9761\n",
      "Epoch 242/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0205 - acc: 0.9926 - val_loss: 0.0786 - val_acc: 0.9799\n",
      "Epoch 243/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0270 - acc: 0.9915 - val_loss: 0.0805 - val_acc: 0.9799\n",
      "Epoch 244/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0297 - acc: 0.9903 - val_loss: 0.0818 - val_acc: 0.9807\n",
      "Epoch 245/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0291 - acc: 0.9900 - val_loss: 0.0782 - val_acc: 0.9799\n",
      "Epoch 246/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0313 - acc: 0.9908 - val_loss: 0.0634 - val_acc: 0.9840\n",
      "Epoch 247/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0251 - acc: 0.9918 - val_loss: 0.0679 - val_acc: 0.9834\n",
      "Epoch 248/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0194 - acc: 0.9934 - val_loss: 0.0886 - val_acc: 0.9796\n",
      "Epoch 249/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0266 - acc: 0.9917 - val_loss: 0.0738 - val_acc: 0.9831\n",
      "Epoch 250/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0226 - acc: 0.9922 - val_loss: 0.0764 - val_acc: 0.9819\n",
      "Epoch 251/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0170 - acc: 0.9948 - val_loss: 0.0729 - val_acc: 0.9828\n",
      "Epoch 252/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0261 - acc: 0.9919 - val_loss: 0.0849 - val_acc: 0.9802\n",
      "Epoch 253/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0255 - acc: 0.9920 - val_loss: 0.0904 - val_acc: 0.9784\n",
      "Epoch 254/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0280 - acc: 0.9920 - val_loss: 0.0842 - val_acc: 0.9802\n",
      "Epoch 255/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.2465 - acc: 0.9365 - val_loss: 0.2164 - val_acc: 0.9376\n",
      "Epoch 256/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1901 - acc: 0.9460 - val_loss: 0.1377 - val_acc: 0.9597\n",
      "Epoch 257/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0814 - acc: 0.9755 - val_loss: 0.1093 - val_acc: 0.9717\n",
      "Epoch 258/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0689 - acc: 0.9796 - val_loss: 0.1186 - val_acc: 0.9682\n",
      "Epoch 259/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0430 - acc: 0.9859 - val_loss: 0.0842 - val_acc: 0.9769\n",
      "Epoch 260/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0354 - acc: 0.9875 - val_loss: 0.0678 - val_acc: 0.9793\n",
      "Epoch 261/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0355 - acc: 0.9890 - val_loss: 0.0786 - val_acc: 0.9787\n",
      "Epoch 262/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0299 - acc: 0.9901 - val_loss: 0.1017 - val_acc: 0.9764\n",
      "Epoch 263/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0409 - acc: 0.9887 - val_loss: 0.1639 - val_acc: 0.9615\n",
      "Epoch 264/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.2157 - acc: 0.9495 - val_loss: 0.2208 - val_acc: 0.9457\n",
      "Epoch 265/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.3385 - acc: 0.9151 - val_loss: 0.2667 - val_acc: 0.9440\n",
      "Epoch 266/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.2670 - acc: 0.9366 - val_loss: 0.2663 - val_acc: 0.9402\n",
      "Epoch 267/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.2227 - acc: 0.9466 - val_loss: 0.2127 - val_acc: 0.9527\n",
      "Epoch 268/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.2033 - acc: 0.9574 - val_loss: 0.2415 - val_acc: 0.9504\n",
      "Epoch 269/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1555 - acc: 0.9600 - val_loss: 0.1391 - val_acc: 0.9597\n",
      "Epoch 270/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0878 - acc: 0.9746 - val_loss: 0.1398 - val_acc: 0.9676\n",
      "Epoch 271/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0550 - acc: 0.9825 - val_loss: 0.0903 - val_acc: 0.9752\n",
      "Epoch 272/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0455 - acc: 0.9857 - val_loss: 0.0810 - val_acc: 0.9752\n",
      "Epoch 273/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0411 - acc: 0.9881 - val_loss: 0.0787 - val_acc: 0.9767\n",
      "Epoch 274/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0335 - acc: 0.9901 - val_loss: 0.0755 - val_acc: 0.9778\n",
      "Epoch 275/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0293 - acc: 0.9897 - val_loss: 0.0703 - val_acc: 0.9819\n",
      "Epoch 276/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0344 - acc: 0.9886 - val_loss: 0.0813 - val_acc: 0.9787\n",
      "Epoch 277/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0374 - acc: 0.9891 - val_loss: 0.0748 - val_acc: 0.9813\n",
      "Epoch 278/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0374 - acc: 0.9892 - val_loss: 0.0676 - val_acc: 0.9810\n",
      "Epoch 279/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0436 - acc: 0.9878 - val_loss: 0.0922 - val_acc: 0.9784\n",
      "Epoch 280/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0818 - acc: 0.9785 - val_loss: 0.1060 - val_acc: 0.9688\n",
      "Epoch 281/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0489 - acc: 0.9829 - val_loss: 0.0708 - val_acc: 0.9793\n",
      "Epoch 282/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0366 - acc: 0.9896 - val_loss: 0.0810 - val_acc: 0.9802\n",
      "Epoch 283/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0354 - acc: 0.9900 - val_loss: 0.0847 - val_acc: 0.9761\n",
      "Epoch 284/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0330 - acc: 0.9900 - val_loss: 0.0854 - val_acc: 0.9799\n",
      "Epoch 285/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0354 - acc: 0.9893 - val_loss: 0.0827 - val_acc: 0.9810\n",
      "Epoch 286/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0236 - acc: 0.9921 - val_loss: 0.0791 - val_acc: 0.9825\n",
      "Epoch 287/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0262 - acc: 0.9913 - val_loss: 0.0700 - val_acc: 0.9813\n",
      "Epoch 288/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0260 - acc: 0.9922 - val_loss: 0.0779 - val_acc: 0.9822\n",
      "Epoch 289/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0263 - acc: 0.9913 - val_loss: 0.0642 - val_acc: 0.9828\n",
      "Epoch 290/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0170 - acc: 0.9942 - val_loss: 0.0699 - val_acc: 0.9845\n",
      "Epoch 291/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0519 - val_acc: 0.9857\n",
      "Epoch 292/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0204 - acc: 0.9934 - val_loss: 0.0696 - val_acc: 0.9840\n",
      "Epoch 293/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0188 - acc: 0.9940 - val_loss: 0.0608 - val_acc: 0.9842\n",
      "Epoch 294/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0192 - acc: 0.9937 - val_loss: 0.0550 - val_acc: 0.9845\n",
      "Epoch 295/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0215 - acc: 0.9933 - val_loss: 0.0629 - val_acc: 0.9863\n",
      "Epoch 296/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0224 - acc: 0.9932 - val_loss: 0.0697 - val_acc: 0.9840\n",
      "Epoch 297/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0176 - acc: 0.9938 - val_loss: 0.0730 - val_acc: 0.9825\n",
      "Epoch 298/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0178 - acc: 0.9942 - val_loss: 0.0892 - val_acc: 0.9787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0281 - acc: 0.9912 - val_loss: 0.1082 - val_acc: 0.9764\n",
      "Epoch 300/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0249 - acc: 0.9921 - val_loss: 0.0928 - val_acc: 0.9784\n",
      "Epoch 301/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0298 - acc: 0.9906 - val_loss: 0.0780 - val_acc: 0.9790\n",
      "Epoch 302/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0286 - acc: 0.9915 - val_loss: 0.0710 - val_acc: 0.9810\n",
      "Epoch 303/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0206 - acc: 0.9935 - val_loss: 0.0667 - val_acc: 0.9819\n",
      "Epoch 304/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0212 - acc: 0.9936 - val_loss: 0.0716 - val_acc: 0.9810\n",
      "Epoch 305/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0295 - acc: 0.9914 - val_loss: 0.0923 - val_acc: 0.9796\n",
      "Epoch 306/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0197 - acc: 0.9946 - val_loss: 0.0820 - val_acc: 0.9813\n",
      "Epoch 307/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0204 - acc: 0.9936 - val_loss: 0.0744 - val_acc: 0.9834\n",
      "Epoch 308/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0165 - acc: 0.9954 - val_loss: 0.0784 - val_acc: 0.9840\n",
      "Epoch 309/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0166 - acc: 0.9944 - val_loss: 0.0890 - val_acc: 0.9813\n",
      "Epoch 310/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0225 - acc: 0.9934 - val_loss: 0.0845 - val_acc: 0.9822\n",
      "Epoch 311/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0168 - acc: 0.9946 - val_loss: 0.0822 - val_acc: 0.9804\n",
      "Epoch 312/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.0869 - val_acc: 0.9804\n",
      "Epoch 313/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0262 - acc: 0.9927 - val_loss: 0.0736 - val_acc: 0.9828\n",
      "Epoch 314/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0249 - acc: 0.9924 - val_loss: 0.0946 - val_acc: 0.9769\n",
      "Epoch 315/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0289 - acc: 0.9916 - val_loss: 0.0859 - val_acc: 0.9796\n",
      "Epoch 316/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0234 - acc: 0.9934 - val_loss: 0.0731 - val_acc: 0.9831\n",
      "Epoch 317/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0172 - acc: 0.9949 - val_loss: 0.0609 - val_acc: 0.9869\n",
      "Epoch 318/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0211 - acc: 0.9935 - val_loss: 0.0678 - val_acc: 0.9840\n",
      "Epoch 319/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0257 - acc: 0.9918 - val_loss: 0.0901 - val_acc: 0.9799\n",
      "Epoch 320/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0277 - acc: 0.9912 - val_loss: 0.0834 - val_acc: 0.9793\n",
      "Epoch 321/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0283 - acc: 0.9912 - val_loss: 0.0866 - val_acc: 0.9784\n",
      "Epoch 322/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0211 - acc: 0.9933 - val_loss: 0.0772 - val_acc: 0.9813\n",
      "Epoch 323/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0231 - acc: 0.9926 - val_loss: 0.0735 - val_acc: 0.9828\n",
      "Epoch 324/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0185 - acc: 0.9939 - val_loss: 0.0984 - val_acc: 0.9764\n",
      "Epoch 325/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0201 - acc: 0.9935 - val_loss: 0.0684 - val_acc: 0.9834\n",
      "Epoch 326/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0225 - acc: 0.9922 - val_loss: 0.0591 - val_acc: 0.9872\n",
      "Epoch 327/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0238 - acc: 0.9934 - val_loss: 0.0563 - val_acc: 0.9889\n",
      "Epoch 328/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0267 - acc: 0.9920 - val_loss: 0.0697 - val_acc: 0.9837\n",
      "Epoch 329/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0183 - acc: 0.9946 - val_loss: 0.0630 - val_acc: 0.9857\n",
      "Epoch 330/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0212 - acc: 0.9934 - val_loss: 0.0812 - val_acc: 0.9848\n",
      "Epoch 331/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0224 - acc: 0.9931 - val_loss: 0.0648 - val_acc: 0.9860\n",
      "Epoch 332/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0257 - acc: 0.9914 - val_loss: 0.0963 - val_acc: 0.9784\n",
      "Epoch 333/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0263 - acc: 0.9928 - val_loss: 0.0764 - val_acc: 0.9825\n",
      "Epoch 334/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0275 - acc: 0.9919 - val_loss: 0.0719 - val_acc: 0.9837\n",
      "Epoch 335/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0294 - acc: 0.9909 - val_loss: 0.0878 - val_acc: 0.9816\n",
      "Epoch 336/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0358 - acc: 0.9899 - val_loss: 0.0822 - val_acc: 0.9793\n",
      "Epoch 337/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0366 - acc: 0.9893 - val_loss: 0.0820 - val_acc: 0.9784\n",
      "Epoch 338/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0290 - acc: 0.9914 - val_loss: 0.0719 - val_acc: 0.9842\n",
      "Epoch 339/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0281 - acc: 0.9921 - val_loss: 0.0670 - val_acc: 0.9825\n",
      "Epoch 340/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0204 - acc: 0.9932 - val_loss: 0.0677 - val_acc: 0.9840\n",
      "Epoch 341/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0231 - acc: 0.9926 - val_loss: 0.0661 - val_acc: 0.9807\n",
      "Epoch 342/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0299 - acc: 0.9911 - val_loss: 0.0569 - val_acc: 0.9863\n",
      "Epoch 343/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0232 - acc: 0.9924 - val_loss: 0.0645 - val_acc: 0.9854\n",
      "Epoch 344/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0213 - acc: 0.9930 - val_loss: 0.0863 - val_acc: 0.9793\n",
      "Epoch 345/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0210 - acc: 0.9938 - val_loss: 0.0746 - val_acc: 0.9810\n",
      "Epoch 346/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0197 - acc: 0.9937 - val_loss: 0.0824 - val_acc: 0.9816\n",
      "Epoch 347/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0163 - acc: 0.9945 - val_loss: 0.0612 - val_acc: 0.9869\n",
      "Epoch 348/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0273 - acc: 0.9916 - val_loss: 0.0776 - val_acc: 0.9825\n",
      "Epoch 349/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0234 - acc: 0.9926 - val_loss: 0.0870 - val_acc: 0.9793\n",
      "Epoch 350/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0228 - acc: 0.9924 - val_loss: 0.0873 - val_acc: 0.9804\n",
      "Epoch 351/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0292 - acc: 0.9917 - val_loss: 0.0660 - val_acc: 0.9863\n",
      "Epoch 352/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0263 - acc: 0.9918 - val_loss: 0.0849 - val_acc: 0.9781\n",
      "Epoch 353/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0251 - acc: 0.9924 - val_loss: 0.0802 - val_acc: 0.9802\n",
      "Epoch 354/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0225 - acc: 0.9944 - val_loss: 0.0717 - val_acc: 0.9834\n",
      "Epoch 355/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0750 - val_acc: 0.9860\n",
      "Epoch 356/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0282 - acc: 0.9913 - val_loss: 0.0704 - val_acc: 0.9834\n",
      "Epoch 357/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0183 - acc: 0.9940 - val_loss: 0.0621 - val_acc: 0.9848\n",
      "Epoch 358/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0796 - val_acc: 0.9784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0217 - acc: 0.9937 - val_loss: 0.0612 - val_acc: 0.9848\n",
      "Epoch 360/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0236 - acc: 0.9920 - val_loss: 0.0647 - val_acc: 0.9872\n",
      "Epoch 361/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0229 - acc: 0.9931 - val_loss: 0.0481 - val_acc: 0.9872\n",
      "Epoch 362/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0232 - acc: 0.9930 - val_loss: 0.0526 - val_acc: 0.9880\n",
      "Epoch 363/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0705 - val_acc: 0.9834\n",
      "Epoch 364/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0618 - acc: 0.9848 - val_loss: 0.0782 - val_acc: 0.9769\n",
      "Epoch 365/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0406 - acc: 0.9867 - val_loss: 0.0867 - val_acc: 0.9816\n",
      "Epoch 366/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0391 - acc: 0.9901 - val_loss: 0.0854 - val_acc: 0.9802\n",
      "Epoch 367/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0362 - acc: 0.9899 - val_loss: 0.0810 - val_acc: 0.9802\n",
      "Epoch 368/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0312 - acc: 0.9920 - val_loss: 0.0764 - val_acc: 0.9819\n",
      "Epoch 369/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0218 - acc: 0.9939 - val_loss: 0.0723 - val_acc: 0.9840\n",
      "Epoch 370/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0327 - acc: 0.9920 - val_loss: 0.0655 - val_acc: 0.9840\n",
      "Epoch 371/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0189 - acc: 0.9938 - val_loss: 0.0585 - val_acc: 0.9863\n",
      "Epoch 372/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0219 - acc: 0.9935 - val_loss: 0.0854 - val_acc: 0.9787\n",
      "Epoch 373/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0231 - acc: 0.9938 - val_loss: 0.0683 - val_acc: 0.9848\n",
      "Epoch 374/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0195 - acc: 0.9935 - val_loss: 0.0788 - val_acc: 0.9819\n",
      "Epoch 375/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0205 - acc: 0.9929 - val_loss: 0.0652 - val_acc: 0.9831\n",
      "Epoch 376/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0167 - acc: 0.9941 - val_loss: 0.0838 - val_acc: 0.9828\n",
      "Epoch 377/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0259 - acc: 0.9932 - val_loss: 0.0736 - val_acc: 0.9816\n",
      "Epoch 378/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0411 - acc: 0.9904 - val_loss: 0.0955 - val_acc: 0.9828\n",
      "Epoch 379/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0314 - acc: 0.9903 - val_loss: 0.0819 - val_acc: 0.9828\n",
      "Epoch 380/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0256 - acc: 0.9914 - val_loss: 0.0895 - val_acc: 0.9804\n",
      "Epoch 381/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0253 - acc: 0.9925 - val_loss: 0.0795 - val_acc: 0.9845\n",
      "Epoch 382/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0408 - acc: 0.9889 - val_loss: 0.0850 - val_acc: 0.9790\n",
      "Epoch 383/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0400 - acc: 0.9911 - val_loss: 0.0782 - val_acc: 0.9799\n",
      "Epoch 384/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0274 - acc: 0.9921 - val_loss: 0.0795 - val_acc: 0.9816\n",
      "Epoch 385/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0399 - acc: 0.9908 - val_loss: 0.0932 - val_acc: 0.9767\n",
      "Epoch 386/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0481 - acc: 0.9864 - val_loss: 0.0891 - val_acc: 0.9793\n",
      "Epoch 387/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0278 - acc: 0.9913 - val_loss: 0.0731 - val_acc: 0.9825\n",
      "Epoch 388/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0621 - acc: 0.9831 - val_loss: 0.1122 - val_acc: 0.9734\n",
      "Epoch 389/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0356 - acc: 0.9903 - val_loss: 0.0691 - val_acc: 0.9834\n",
      "Epoch 390/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0304 - acc: 0.9914 - val_loss: 0.0705 - val_acc: 0.9845\n",
      "Epoch 391/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0278 - acc: 0.9929 - val_loss: 0.0673 - val_acc: 0.9834\n",
      "Epoch 392/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0199 - acc: 0.9939 - val_loss: 0.0793 - val_acc: 0.9828\n",
      "Epoch 393/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0185 - acc: 0.9949 - val_loss: 0.0719 - val_acc: 0.9845\n",
      "Epoch 394/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0219 - acc: 0.9940 - val_loss: 0.0771 - val_acc: 0.9831\n",
      "Epoch 395/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0178 - acc: 0.9950 - val_loss: 0.0903 - val_acc: 0.9807\n",
      "Epoch 396/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0236 - acc: 0.9932 - val_loss: 0.0717 - val_acc: 0.9851\n",
      "Epoch 397/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0257 - acc: 0.9920 - val_loss: 0.0850 - val_acc: 0.9804\n",
      "Epoch 398/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0201 - acc: 0.9935 - val_loss: 0.0776 - val_acc: 0.9837\n",
      "Epoch 399/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0178 - acc: 0.9944 - val_loss: 0.0929 - val_acc: 0.9799\n",
      "Epoch 400/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0220 - acc: 0.9936 - val_loss: 0.1327 - val_acc: 0.9769\n",
      "Epoch 401/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0506 - acc: 0.9878 - val_loss: 0.0801 - val_acc: 0.9793\n",
      "Epoch 402/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0328 - acc: 0.9914 - val_loss: 0.0820 - val_acc: 0.9828\n",
      "Epoch 403/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0216 - acc: 0.9941 - val_loss: 0.0755 - val_acc: 0.9802\n",
      "Epoch 404/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0160 - acc: 0.9953 - val_loss: 0.0824 - val_acc: 0.9828\n",
      "Epoch 405/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0330 - acc: 0.9911 - val_loss: 0.0943 - val_acc: 0.9796\n",
      "Epoch 406/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0300 - acc: 0.9921 - val_loss: 0.0756 - val_acc: 0.9848\n",
      "Epoch 407/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0258 - acc: 0.9924 - val_loss: 0.0836 - val_acc: 0.9831\n",
      "Epoch 408/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0217 - acc: 0.9932 - val_loss: 0.0788 - val_acc: 0.9799\n",
      "Epoch 409/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0519 - val_acc: 0.9877\n",
      "Epoch 410/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0139 - acc: 0.9959 - val_loss: 0.0638 - val_acc: 0.9860\n",
      "Epoch 411/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0194 - acc: 0.9945 - val_loss: 0.0800 - val_acc: 0.9816\n",
      "Epoch 412/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0262 - acc: 0.9937 - val_loss: 0.0628 - val_acc: 0.9840\n",
      "Epoch 413/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0169 - acc: 0.9942 - val_loss: 0.0729 - val_acc: 0.9848\n",
      "Epoch 414/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0241 - acc: 0.9926 - val_loss: 0.0783 - val_acc: 0.9810\n",
      "Epoch 415/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0227 - acc: 0.9926 - val_loss: 0.0727 - val_acc: 0.9793\n",
      "Epoch 416/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0201 - acc: 0.9950 - val_loss: 0.0820 - val_acc: 0.9796\n",
      "Epoch 417/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0215 - acc: 0.9940 - val_loss: 0.0788 - val_acc: 0.9807\n",
      "Epoch 418/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0260 - acc: 0.9927 - val_loss: 0.0835 - val_acc: 0.9793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0205 - acc: 0.9939 - val_loss: 0.0616 - val_acc: 0.9848\n",
      "Epoch 420/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0164 - acc: 0.9947 - val_loss: 0.0592 - val_acc: 0.9825\n",
      "Epoch 421/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0191 - acc: 0.9945 - val_loss: 0.0631 - val_acc: 0.9834\n",
      "Epoch 422/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0151 - acc: 0.9954 - val_loss: 0.0698 - val_acc: 0.9822\n",
      "Epoch 423/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0157 - acc: 0.9948 - val_loss: 0.0593 - val_acc: 0.9837\n",
      "Epoch 424/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0198 - acc: 0.9946 - val_loss: 0.0749 - val_acc: 0.9819\n",
      "Epoch 425/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0121 - acc: 0.9957 - val_loss: 0.0783 - val_acc: 0.9834\n",
      "Epoch 426/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0183 - acc: 0.9942 - val_loss: 0.0906 - val_acc: 0.9793\n",
      "Epoch 427/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0232 - acc: 0.9932 - val_loss: 0.0893 - val_acc: 0.9796\n",
      "Epoch 428/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0268 - acc: 0.9926 - val_loss: 0.0831 - val_acc: 0.9807\n",
      "Epoch 429/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0205 - acc: 0.9929 - val_loss: 0.0905 - val_acc: 0.9802\n",
      "Epoch 430/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0253 - acc: 0.9929 - val_loss: 0.0676 - val_acc: 0.9831\n",
      "Epoch 431/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0248 - acc: 0.9929 - val_loss: 0.0848 - val_acc: 0.9799\n",
      "Epoch 432/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0365 - acc: 0.9909 - val_loss: 0.1253 - val_acc: 0.9755\n",
      "Epoch 433/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0237 - acc: 0.9923 - val_loss: 0.0706 - val_acc: 0.9842\n",
      "Epoch 434/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0201 - acc: 0.9940 - val_loss: 0.0844 - val_acc: 0.9804\n",
      "Epoch 435/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0213 - acc: 0.9935 - val_loss: 0.0865 - val_acc: 0.9822\n",
      "Epoch 436/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0183 - acc: 0.9948 - val_loss: 0.0851 - val_acc: 0.9802\n",
      "Epoch 437/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0231 - acc: 0.9932 - val_loss: 0.0822 - val_acc: 0.9807\n",
      "Epoch 438/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0199 - acc: 0.9939 - val_loss: 0.0883 - val_acc: 0.9807\n",
      "Epoch 439/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0213 - acc: 0.9943 - val_loss: 0.0706 - val_acc: 0.9842\n",
      "Epoch 440/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0234 - acc: 0.9934 - val_loss: 0.0737 - val_acc: 0.9822\n",
      "Epoch 441/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0249 - acc: 0.9931 - val_loss: 0.0711 - val_acc: 0.9837\n",
      "Epoch 442/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0269 - acc: 0.9914 - val_loss: 0.0929 - val_acc: 0.9804\n",
      "Epoch 443/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0292 - acc: 0.9919 - val_loss: 0.0754 - val_acc: 0.9848\n",
      "Epoch 444/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0209 - acc: 0.9943 - val_loss: 0.0832 - val_acc: 0.9834\n",
      "Epoch 445/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0244 - acc: 0.9937 - val_loss: 0.0733 - val_acc: 0.9834\n",
      "Epoch 446/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0224 - acc: 0.9940 - val_loss: 0.0749 - val_acc: 0.9842\n",
      "Epoch 447/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0184 - acc: 0.9955 - val_loss: 0.0653 - val_acc: 0.9848\n",
      "Epoch 448/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0141 - acc: 0.9962 - val_loss: 0.0649 - val_acc: 0.9866\n",
      "Epoch 449/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0157 - acc: 0.9954 - val_loss: 0.0624 - val_acc: 0.9863\n",
      "Epoch 450/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0146 - acc: 0.9957 - val_loss: 0.0596 - val_acc: 0.9883\n",
      "Epoch 451/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0246 - acc: 0.9930 - val_loss: 0.0899 - val_acc: 0.9804\n",
      "Epoch 452/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0279 - acc: 0.9913 - val_loss: 0.0791 - val_acc: 0.9837\n",
      "Epoch 453/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0256 - acc: 0.9928 - val_loss: 0.0725 - val_acc: 0.9854\n",
      "Epoch 454/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0178 - acc: 0.9947 - val_loss: 0.0642 - val_acc: 0.9845\n",
      "Epoch 455/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0193 - acc: 0.9948 - val_loss: 0.0703 - val_acc: 0.9872\n",
      "Epoch 456/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0171 - acc: 0.9948 - val_loss: 0.0836 - val_acc: 0.9840\n",
      "Epoch 457/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0158 - acc: 0.9949 - val_loss: 0.0832 - val_acc: 0.9851\n",
      "Epoch 458/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0135 - acc: 0.9960 - val_loss: 0.0758 - val_acc: 0.9848\n",
      "Epoch 459/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0163 - acc: 0.9954 - val_loss: 0.0744 - val_acc: 0.9851\n",
      "Epoch 460/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0315 - acc: 0.9919 - val_loss: 0.0793 - val_acc: 0.9837\n",
      "Epoch 461/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0375 - acc: 0.9893 - val_loss: 0.0971 - val_acc: 0.9799\n",
      "Epoch 462/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0390 - acc: 0.9877 - val_loss: 0.0842 - val_acc: 0.9810\n",
      "Epoch 463/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0254 - acc: 0.9916 - val_loss: 0.0779 - val_acc: 0.9810\n",
      "Epoch 464/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0246 - acc: 0.9927 - val_loss: 0.0729 - val_acc: 0.9834\n",
      "Epoch 465/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0181 - acc: 0.9945 - val_loss: 0.0743 - val_acc: 0.9848\n",
      "Epoch 466/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0153 - acc: 0.9960 - val_loss: 0.0633 - val_acc: 0.9869\n",
      "Epoch 467/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0155 - acc: 0.9954 - val_loss: 0.0526 - val_acc: 0.9875\n",
      "Epoch 468/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0163 - acc: 0.9950 - val_loss: 0.0694 - val_acc: 0.9851\n",
      "Epoch 469/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0111 - acc: 0.9959 - val_loss: 0.0630 - val_acc: 0.9845\n",
      "Epoch 470/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0822 - val_acc: 0.9854\n",
      "Epoch 471/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0863 - val_acc: 0.9828\n",
      "Epoch 472/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0273 - acc: 0.9922 - val_loss: 0.0979 - val_acc: 0.9790\n",
      "Epoch 473/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0272 - acc: 0.9926 - val_loss: 0.0842 - val_acc: 0.9825\n",
      "Epoch 474/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0226 - acc: 0.9935 - val_loss: 0.0730 - val_acc: 0.9842\n",
      "Epoch 475/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0148 - acc: 0.9957 - val_loss: 0.0772 - val_acc: 0.9810\n",
      "Epoch 476/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0181 - acc: 0.9951 - val_loss: 0.1009 - val_acc: 0.9793\n",
      "Epoch 477/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0104 - acc: 0.9971 - val_loss: 0.0925 - val_acc: 0.9799\n",
      "Epoch 478/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0185 - acc: 0.9940 - val_loss: 0.0858 - val_acc: 0.9813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0207 - acc: 0.9945 - val_loss: 0.0740 - val_acc: 0.9837\n",
      "Epoch 480/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0182 - acc: 0.9947 - val_loss: 0.0740 - val_acc: 0.9842\n",
      "Epoch 481/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0767 - val_acc: 0.9842\n",
      "Epoch 482/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0156 - acc: 0.9951 - val_loss: 0.0699 - val_acc: 0.9822\n",
      "Epoch 483/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0172 - acc: 0.9956 - val_loss: 0.0700 - val_acc: 0.9860\n",
      "Epoch 484/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0155 - acc: 0.9944 - val_loss: 0.0638 - val_acc: 0.9854\n",
      "Epoch 485/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0184 - acc: 0.9952 - val_loss: 0.0701 - val_acc: 0.9804\n",
      "Epoch 486/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0152 - acc: 0.9948 - val_loss: 0.0844 - val_acc: 0.9819\n",
      "Epoch 487/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0136 - acc: 0.9959 - val_loss: 0.0792 - val_acc: 0.9819\n",
      "Epoch 488/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0167 - acc: 0.9954 - val_loss: 0.0835 - val_acc: 0.9813\n",
      "Epoch 489/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0160 - acc: 0.9944 - val_loss: 0.0702 - val_acc: 0.9837\n",
      "Epoch 490/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.0810 - val_acc: 0.9840\n",
      "Epoch 491/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0193 - acc: 0.9946 - val_loss: 0.0724 - val_acc: 0.9837\n",
      "Epoch 492/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0165 - acc: 0.9957 - val_loss: 0.0696 - val_acc: 0.9840\n",
      "Epoch 493/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0139 - acc: 0.9959 - val_loss: 0.0688 - val_acc: 0.9840\n",
      "Epoch 494/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0200 - acc: 0.9940 - val_loss: 0.0620 - val_acc: 0.9845\n",
      "Epoch 495/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0154 - acc: 0.9965 - val_loss: 0.0710 - val_acc: 0.9854\n",
      "Epoch 496/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0168 - acc: 0.9950 - val_loss: 0.0811 - val_acc: 0.9863\n",
      "Epoch 497/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0189 - acc: 0.9946 - val_loss: 0.0741 - val_acc: 0.9854\n",
      "Epoch 498/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0188 - acc: 0.9937 - val_loss: 0.0547 - val_acc: 0.9866\n",
      "Epoch 499/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0205 - acc: 0.9936 - val_loss: 0.0725 - val_acc: 0.9837\n",
      "Epoch 500/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0261 - acc: 0.9929 - val_loss: 0.0685 - val_acc: 0.9822\n",
      "Epoch 501/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0202 - acc: 0.9942 - val_loss: 0.0577 - val_acc: 0.9857\n",
      "Epoch 502/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0161 - acc: 0.9946 - val_loss: 0.0578 - val_acc: 0.9860\n",
      "Epoch 503/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0177 - acc: 0.9948 - val_loss: 0.0660 - val_acc: 0.9863\n",
      "Epoch 504/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0164 - acc: 0.9948 - val_loss: 0.0729 - val_acc: 0.9860\n",
      "Epoch 505/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0114 - acc: 0.9965 - val_loss: 0.0766 - val_acc: 0.9848\n",
      "Epoch 506/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0151 - acc: 0.9962 - val_loss: 0.0841 - val_acc: 0.9842\n",
      "Epoch 507/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0134 - acc: 0.9960 - val_loss: 0.0593 - val_acc: 0.9854\n",
      "Epoch 508/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0125 - acc: 0.9954 - val_loss: 0.0602 - val_acc: 0.9857\n",
      "Epoch 509/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0123 - acc: 0.9958 - val_loss: 0.0676 - val_acc: 0.9845\n",
      "Epoch 510/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0132 - acc: 0.9960 - val_loss: 0.0569 - val_acc: 0.9872\n",
      "Epoch 511/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0218 - acc: 0.9940 - val_loss: 0.0621 - val_acc: 0.9854\n",
      "Epoch 512/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0193 - acc: 0.9945 - val_loss: 0.0734 - val_acc: 0.9831\n",
      "Epoch 513/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0231 - acc: 0.9931 - val_loss: 0.0803 - val_acc: 0.9813\n",
      "Epoch 514/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0224 - acc: 0.9936 - val_loss: 0.0632 - val_acc: 0.9854\n",
      "Epoch 515/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0143 - acc: 0.9959 - val_loss: 0.0652 - val_acc: 0.9854\n",
      "Epoch 516/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0172 - acc: 0.9950 - val_loss: 0.0747 - val_acc: 0.9848\n",
      "Epoch 517/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0165 - acc: 0.9950 - val_loss: 0.0751 - val_acc: 0.9854\n",
      "Epoch 518/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0245 - acc: 0.9937 - val_loss: 0.1010 - val_acc: 0.9781\n",
      "Epoch 519/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0268 - acc: 0.9928 - val_loss: 0.0964 - val_acc: 0.9804\n",
      "Epoch 520/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0232 - acc: 0.9924 - val_loss: 0.0862 - val_acc: 0.9804\n",
      "Epoch 521/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0268 - acc: 0.9932 - val_loss: 0.0926 - val_acc: 0.9810\n",
      "Epoch 522/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0227 - acc: 0.9935 - val_loss: 0.1048 - val_acc: 0.9784\n",
      "Epoch 523/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0259 - acc: 0.9924 - val_loss: 0.0970 - val_acc: 0.9793\n",
      "Epoch 524/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0197 - acc: 0.9941 - val_loss: 0.0854 - val_acc: 0.9816\n",
      "Epoch 525/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0134 - acc: 0.9961 - val_loss: 0.0924 - val_acc: 0.9816\n",
      "Epoch 526/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0142 - acc: 0.9957 - val_loss: 0.0876 - val_acc: 0.9804\n",
      "Epoch 527/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.0969 - val_acc: 0.9816\n",
      "Epoch 528/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0203 - acc: 0.9949 - val_loss: 0.0836 - val_acc: 0.9822\n",
      "Epoch 529/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0263 - acc: 0.9941 - val_loss: 0.1090 - val_acc: 0.9799\n",
      "Epoch 530/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0175 - acc: 0.9959 - val_loss: 0.0888 - val_acc: 0.9834\n",
      "Epoch 531/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0118 - acc: 0.9969 - val_loss: 0.0735 - val_acc: 0.9834\n",
      "Epoch 532/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0222 - acc: 0.9949 - val_loss: 0.1017 - val_acc: 0.9781\n",
      "Epoch 533/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0316 - acc: 0.9915 - val_loss: 0.0703 - val_acc: 0.9834\n",
      "Epoch 534/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0228 - acc: 0.9934 - val_loss: 0.0598 - val_acc: 0.9866\n",
      "Epoch 535/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0154 - acc: 0.9947 - val_loss: 0.0662 - val_acc: 0.9854\n",
      "Epoch 536/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0170 - acc: 0.9944 - val_loss: 0.0697 - val_acc: 0.9869\n",
      "Epoch 537/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0176 - acc: 0.9942 - val_loss: 0.0807 - val_acc: 0.9825\n",
      "Epoch 538/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0148 - acc: 0.9958 - val_loss: 0.0793 - val_acc: 0.9831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 539/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0160 - acc: 0.9954 - val_loss: 0.0735 - val_acc: 0.9834\n",
      "Epoch 540/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0163 - acc: 0.9954 - val_loss: 0.0954 - val_acc: 0.9842\n",
      "Epoch 541/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0137 - acc: 0.9958 - val_loss: 0.0536 - val_acc: 0.9889\n",
      "Epoch 542/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0173 - acc: 0.9951 - val_loss: 0.0749 - val_acc: 0.9845\n",
      "Epoch 543/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0295 - acc: 0.9944 - val_loss: 0.1652 - val_acc: 0.9737\n",
      "Epoch 544/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.3497 - acc: 0.9236 - val_loss: 0.2532 - val_acc: 0.9451\n",
      "Epoch 545/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.3050 - acc: 0.9318 - val_loss: 0.1978 - val_acc: 0.9603\n",
      "Epoch 546/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.2217 - acc: 0.9528 - val_loss: 0.4053 - val_acc: 0.9052\n",
      "Epoch 547/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.3167 - acc: 0.9222 - val_loss: 0.4054 - val_acc: 0.9011\n",
      "Epoch 548/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.2306 - acc: 0.9440 - val_loss: 0.2050 - val_acc: 0.9574\n",
      "Epoch 549/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1416 - acc: 0.9681 - val_loss: 0.1939 - val_acc: 0.9586\n",
      "Epoch 550/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1186 - acc: 0.9771 - val_loss: 0.1789 - val_acc: 0.9647\n",
      "Epoch 551/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.2010 - acc: 0.9587 - val_loss: 0.2439 - val_acc: 0.9495\n",
      "Epoch 552/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1937 - acc: 0.9497 - val_loss: 0.1642 - val_acc: 0.9554\n",
      "Epoch 553/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1127 - acc: 0.9679 - val_loss: 0.1263 - val_acc: 0.9667\n",
      "Epoch 554/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0814 - acc: 0.9758 - val_loss: 0.1196 - val_acc: 0.9688\n",
      "Epoch 555/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0713 - acc: 0.9816 - val_loss: 0.1166 - val_acc: 0.9723\n",
      "Epoch 556/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0499 - acc: 0.9848 - val_loss: 0.1188 - val_acc: 0.9714\n",
      "Epoch 557/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0574 - acc: 0.9834 - val_loss: 0.1044 - val_acc: 0.9752\n",
      "Epoch 558/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0501 - acc: 0.9851 - val_loss: 0.0892 - val_acc: 0.9767\n",
      "Epoch 559/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0632 - acc: 0.9856 - val_loss: 0.1003 - val_acc: 0.9769\n",
      "Epoch 560/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0456 - acc: 0.9858 - val_loss: 0.0944 - val_acc: 0.9769\n",
      "Epoch 561/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0397 - acc: 0.9894 - val_loss: 0.0840 - val_acc: 0.9796\n",
      "Epoch 562/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0395 - acc: 0.9893 - val_loss: 0.0772 - val_acc: 0.9804\n",
      "Epoch 563/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0387 - acc: 0.9891 - val_loss: 0.0960 - val_acc: 0.9790\n",
      "Epoch 564/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0440 - acc: 0.9875 - val_loss: 0.1015 - val_acc: 0.9761\n",
      "Epoch 565/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0362 - acc: 0.9889 - val_loss: 0.1088 - val_acc: 0.9740\n",
      "Epoch 566/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0374 - acc: 0.9894 - val_loss: 0.1003 - val_acc: 0.9772\n",
      "Epoch 567/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0342 - acc: 0.9899 - val_loss: 0.1003 - val_acc: 0.9758\n",
      "Epoch 568/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0412 - acc: 0.9883 - val_loss: 0.0903 - val_acc: 0.9764\n",
      "Epoch 569/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0433 - acc: 0.9878 - val_loss: 0.0906 - val_acc: 0.9772\n",
      "Epoch 570/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0446 - acc: 0.9855 - val_loss: 0.0931 - val_acc: 0.9778\n",
      "Epoch 571/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0384 - acc: 0.9887 - val_loss: 0.0757 - val_acc: 0.9793\n",
      "Epoch 572/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0308 - acc: 0.9910 - val_loss: 0.0777 - val_acc: 0.9784\n",
      "Epoch 573/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0324 - acc: 0.9896 - val_loss: 0.0825 - val_acc: 0.9793\n",
      "Epoch 574/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0275 - acc: 0.9916 - val_loss: 0.0840 - val_acc: 0.9781\n",
      "Epoch 575/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0281 - acc: 0.9921 - val_loss: 0.0760 - val_acc: 0.9828\n",
      "Epoch 576/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.0829 - val_acc: 0.9813\n",
      "Epoch 577/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0171 - acc: 0.9941 - val_loss: 0.0924 - val_acc: 0.9796\n",
      "Epoch 578/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0229 - acc: 0.9935 - val_loss: 0.0694 - val_acc: 0.9851\n",
      "Epoch 579/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0133 - acc: 0.9959 - val_loss: 0.0662 - val_acc: 0.9854\n",
      "Epoch 580/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0141 - acc: 0.9951 - val_loss: 0.0840 - val_acc: 0.9819\n",
      "Epoch 581/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0177 - acc: 0.9951 - val_loss: 0.0708 - val_acc: 0.9851\n",
      "Epoch 582/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0127 - acc: 0.9958 - val_loss: 0.0738 - val_acc: 0.9840\n",
      "Epoch 583/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0130 - acc: 0.9962 - val_loss: 0.0717 - val_acc: 0.9840\n",
      "Epoch 584/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0131 - acc: 0.9964 - val_loss: 0.0694 - val_acc: 0.9837\n",
      "Epoch 585/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0161 - acc: 0.9957 - val_loss: 0.0661 - val_acc: 0.9848\n",
      "Epoch 586/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0147 - acc: 0.9954 - val_loss: 0.0756 - val_acc: 0.9840\n",
      "Epoch 587/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0158 - acc: 0.9961 - val_loss: 0.0646 - val_acc: 0.9851\n",
      "Epoch 588/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0102 - acc: 0.9970 - val_loss: 0.0685 - val_acc: 0.9872\n",
      "Epoch 589/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.0730 - val_acc: 0.9854\n",
      "Epoch 590/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0155 - acc: 0.9953 - val_loss: 0.0665 - val_acc: 0.9851\n",
      "Epoch 591/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0093 - acc: 0.9971 - val_loss: 0.0659 - val_acc: 0.9872\n",
      "Epoch 592/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0659 - val_acc: 0.9842\n",
      "Epoch 593/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0109 - acc: 0.9963 - val_loss: 0.0654 - val_acc: 0.9845\n",
      "Epoch 594/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0107 - acc: 0.9965 - val_loss: 0.0818 - val_acc: 0.9828\n",
      "Epoch 595/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0148 - acc: 0.9962 - val_loss: 0.0759 - val_acc: 0.9840\n",
      "Epoch 596/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0132 - acc: 0.9957 - val_loss: 0.0725 - val_acc: 0.9866\n",
      "Epoch 597/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0107 - acc: 0.9962 - val_loss: 0.0799 - val_acc: 0.9831\n",
      "Epoch 598/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0640 - val_acc: 0.9857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0114 - acc: 0.9963 - val_loss: 0.0725 - val_acc: 0.9848\n",
      "Epoch 600/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0132 - acc: 0.9965 - val_loss: 0.0734 - val_acc: 0.9857\n",
      "Epoch 601/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0111 - acc: 0.9963 - val_loss: 0.0733 - val_acc: 0.9837\n",
      "Epoch 602/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0130 - acc: 0.9963 - val_loss: 0.0900 - val_acc: 0.9851\n",
      "Epoch 603/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0164 - acc: 0.9951 - val_loss: 0.0702 - val_acc: 0.9863\n",
      "Epoch 604/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0179 - acc: 0.9955 - val_loss: 0.0790 - val_acc: 0.9848\n",
      "Epoch 605/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0191 - acc: 0.9957 - val_loss: 0.0860 - val_acc: 0.9840\n",
      "Epoch 606/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0121 - acc: 0.9958 - val_loss: 0.0807 - val_acc: 0.9848\n",
      "Epoch 607/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0137 - acc: 0.9956 - val_loss: 0.0689 - val_acc: 0.9877\n",
      "Epoch 608/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0190 - acc: 0.9952 - val_loss: 0.0734 - val_acc: 0.9842\n",
      "Epoch 609/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0174 - acc: 0.9949 - val_loss: 0.0707 - val_acc: 0.9837\n",
      "Epoch 610/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0178 - acc: 0.9952 - val_loss: 0.0810 - val_acc: 0.9837\n",
      "Epoch 611/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0128 - acc: 0.9958 - val_loss: 0.0683 - val_acc: 0.9848\n",
      "Epoch 612/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0697 - val_acc: 0.9851\n",
      "Epoch 613/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0130 - acc: 0.9962 - val_loss: 0.0771 - val_acc: 0.9851\n",
      "Epoch 614/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0114 - acc: 0.9966 - val_loss: 0.0720 - val_acc: 0.9857\n",
      "Epoch 615/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0149 - acc: 0.9962 - val_loss: 0.0708 - val_acc: 0.9840\n",
      "Epoch 616/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0173 - acc: 0.9947 - val_loss: 0.0538 - val_acc: 0.9872\n",
      "Epoch 617/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0177 - acc: 0.9947 - val_loss: 0.0559 - val_acc: 0.9848\n",
      "Epoch 618/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0118 - acc: 0.9968 - val_loss: 0.0618 - val_acc: 0.9866\n",
      "Epoch 619/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0135 - acc: 0.9958 - val_loss: 0.0803 - val_acc: 0.9840\n",
      "Epoch 620/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0093 - acc: 0.9970 - val_loss: 0.0737 - val_acc: 0.9840\n",
      "Epoch 621/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0257 - acc: 0.9940 - val_loss: 0.0926 - val_acc: 0.9796\n",
      "Epoch 622/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0351 - acc: 0.9917 - val_loss: 0.0848 - val_acc: 0.9816\n",
      "Epoch 623/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0217 - acc: 0.9948 - val_loss: 0.0763 - val_acc: 0.9819\n",
      "Epoch 624/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0202 - acc: 0.9940 - val_loss: 0.0779 - val_acc: 0.9819\n",
      "Epoch 625/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0243 - acc: 0.9940 - val_loss: 0.0647 - val_acc: 0.9872\n",
      "Epoch 626/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0187 - acc: 0.9946 - val_loss: 0.0833 - val_acc: 0.9840\n",
      "Epoch 627/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0142 - acc: 0.9955 - val_loss: 0.0627 - val_acc: 0.9857\n",
      "Epoch 628/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0212 - acc: 0.9950 - val_loss: 0.0610 - val_acc: 0.9860\n",
      "Epoch 629/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0141 - acc: 0.9955 - val_loss: 0.0795 - val_acc: 0.9857\n",
      "Epoch 630/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0188 - acc: 0.9949 - val_loss: 0.0570 - val_acc: 0.9880\n",
      "Epoch 631/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0180 - acc: 0.9953 - val_loss: 0.0663 - val_acc: 0.9848\n",
      "Epoch 632/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0160 - acc: 0.9953 - val_loss: 0.0717 - val_acc: 0.9831\n",
      "Epoch 633/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0127 - acc: 0.9962 - val_loss: 0.0538 - val_acc: 0.9877\n",
      "Epoch 634/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.0561 - val_acc: 0.9851\n",
      "Epoch 635/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0123 - acc: 0.9957 - val_loss: 0.0623 - val_acc: 0.9854\n",
      "Epoch 636/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0122 - acc: 0.9962 - val_loss: 0.0570 - val_acc: 0.9869\n",
      "Epoch 637/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0127 - acc: 0.9963 - val_loss: 0.0630 - val_acc: 0.9845\n",
      "Epoch 638/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9965 - val_loss: 0.0626 - val_acc: 0.9872\n",
      "Epoch 639/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0686 - val_acc: 0.9834\n",
      "Epoch 640/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0675 - val_acc: 0.9854\n",
      "Epoch 641/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0139 - acc: 0.9955 - val_loss: 0.0621 - val_acc: 0.9857\n",
      "Epoch 642/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0155 - acc: 0.9958 - val_loss: 0.0695 - val_acc: 0.9863\n",
      "Epoch 643/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0152 - acc: 0.9960 - val_loss: 0.0809 - val_acc: 0.9842\n",
      "Epoch 644/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0156 - acc: 0.9955 - val_loss: 0.0752 - val_acc: 0.9831\n",
      "Epoch 645/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0186 - acc: 0.9945 - val_loss: 0.0712 - val_acc: 0.9837\n",
      "Epoch 646/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0181 - acc: 0.9951 - val_loss: 0.0808 - val_acc: 0.9816\n",
      "Epoch 647/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0145 - acc: 0.9964 - val_loss: 0.0679 - val_acc: 0.9842\n",
      "Epoch 648/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0133 - acc: 0.9962 - val_loss: 0.0866 - val_acc: 0.9807\n",
      "Epoch 649/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0128 - acc: 0.9961 - val_loss: 0.0750 - val_acc: 0.9854\n",
      "Epoch 650/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0091 - acc: 0.9973 - val_loss: 0.0713 - val_acc: 0.9840\n",
      "Epoch 651/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9968 - val_loss: 0.0820 - val_acc: 0.9857\n",
      "Epoch 652/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0090 - acc: 0.9971 - val_loss: 0.0730 - val_acc: 0.9857\n",
      "Epoch 653/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0130 - acc: 0.9968 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 654/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.0675 - val_acc: 0.9875\n",
      "Epoch 655/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0109 - acc: 0.9969 - val_loss: 0.0752 - val_acc: 0.9860\n",
      "Epoch 656/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0764 - val_acc: 0.9845\n",
      "Epoch 657/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0133 - acc: 0.9963 - val_loss: 0.0629 - val_acc: 0.9866\n",
      "Epoch 658/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0752 - val_acc: 0.9837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 659/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0183 - acc: 0.9952 - val_loss: 0.0693 - val_acc: 0.9845\n",
      "Epoch 660/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0130 - acc: 0.9962 - val_loss: 0.0687 - val_acc: 0.9877\n",
      "Epoch 661/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0147 - acc: 0.9955 - val_loss: 0.0624 - val_acc: 0.9863\n",
      "Epoch 662/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0225 - acc: 0.9943 - val_loss: 0.0782 - val_acc: 0.9819\n",
      "Epoch 663/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0184 - acc: 0.9953 - val_loss: 0.0656 - val_acc: 0.9842\n",
      "Epoch 664/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0212 - acc: 0.9943 - val_loss: 0.0661 - val_acc: 0.9840\n",
      "Epoch 665/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0153 - acc: 0.9955 - val_loss: 0.0591 - val_acc: 0.9863\n",
      "Epoch 666/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0102 - acc: 0.9973 - val_loss: 0.0686 - val_acc: 0.9845\n",
      "Epoch 667/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0190 - acc: 0.9951 - val_loss: 0.0875 - val_acc: 0.9822\n",
      "Epoch 668/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0229 - acc: 0.9935 - val_loss: 0.0807 - val_acc: 0.9825\n",
      "Epoch 669/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0230 - acc: 0.9940 - val_loss: 0.0765 - val_acc: 0.9837\n",
      "Epoch 670/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0191 - acc: 0.9943 - val_loss: 0.0947 - val_acc: 0.9813\n",
      "Epoch 671/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.1024 - val_acc: 0.9822\n",
      "Epoch 672/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0208 - acc: 0.9949 - val_loss: 0.0785 - val_acc: 0.9840\n",
      "Epoch 673/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0158 - acc: 0.9959 - val_loss: 0.0712 - val_acc: 0.9851\n",
      "Epoch 674/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0185 - acc: 0.9948 - val_loss: 0.0910 - val_acc: 0.9822\n",
      "Epoch 675/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0256 - acc: 0.9939 - val_loss: 0.0717 - val_acc: 0.9851\n",
      "Epoch 676/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0153 - acc: 0.9958 - val_loss: 0.0848 - val_acc: 0.9848\n",
      "Epoch 677/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0177 - acc: 0.9950 - val_loss: 0.0817 - val_acc: 0.9848\n",
      "Epoch 678/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0262 - acc: 0.9926 - val_loss: 0.1017 - val_acc: 0.9769\n",
      "Epoch 679/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0461 - acc: 0.9884 - val_loss: 0.1223 - val_acc: 0.9758\n",
      "Epoch 680/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0316 - acc: 0.9911 - val_loss: 0.0930 - val_acc: 0.9819\n",
      "Epoch 681/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0243 - acc: 0.9930 - val_loss: 0.0788 - val_acc: 0.9842\n",
      "Epoch 682/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0154 - acc: 0.9957 - val_loss: 0.0765 - val_acc: 0.9831\n",
      "Epoch 683/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0154 - acc: 0.9963 - val_loss: 0.0882 - val_acc: 0.9825\n",
      "Epoch 684/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0302 - acc: 0.9916 - val_loss: 0.1148 - val_acc: 0.9767\n",
      "Epoch 685/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0233 - acc: 0.9933 - val_loss: 0.0965 - val_acc: 0.9810\n",
      "Epoch 686/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0132 - acc: 0.9959 - val_loss: 0.0755 - val_acc: 0.9857\n",
      "Epoch 687/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0157 - acc: 0.9957 - val_loss: 0.0770 - val_acc: 0.9831\n",
      "Epoch 688/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0159 - acc: 0.9952 - val_loss: 0.1023 - val_acc: 0.9807\n",
      "Epoch 689/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0148 - acc: 0.9951 - val_loss: 0.0795 - val_acc: 0.9851\n",
      "Epoch 690/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0114 - acc: 0.9963 - val_loss: 0.0754 - val_acc: 0.9863\n",
      "Epoch 691/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0149 - acc: 0.9961 - val_loss: 0.0878 - val_acc: 0.9842\n",
      "Epoch 692/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0169 - acc: 0.9942 - val_loss: 0.0755 - val_acc: 0.9851\n",
      "Epoch 693/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0218 - acc: 0.9952 - val_loss: 0.0773 - val_acc: 0.9872\n",
      "Epoch 694/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0157 - acc: 0.9954 - val_loss: 0.0700 - val_acc: 0.9869\n",
      "Epoch 695/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0208 - acc: 0.9945 - val_loss: 0.0850 - val_acc: 0.9831\n",
      "Epoch 696/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0151 - acc: 0.9955 - val_loss: 0.0719 - val_acc: 0.9848\n",
      "Epoch 697/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0117 - acc: 0.9962 - val_loss: 0.0610 - val_acc: 0.9875\n",
      "Epoch 698/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0802 - val_acc: 0.9863\n",
      "Epoch 699/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0137 - acc: 0.9963 - val_loss: 0.0658 - val_acc: 0.9834\n",
      "Epoch 700/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0152 - acc: 0.9954 - val_loss: 0.0851 - val_acc: 0.9837\n",
      "Epoch 701/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0127 - acc: 0.9960 - val_loss: 0.0878 - val_acc: 0.9842\n",
      "Epoch 702/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0129 - acc: 0.9962 - val_loss: 0.0992 - val_acc: 0.9822\n",
      "Epoch 703/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0078 - acc: 0.9975 - val_loss: 0.0850 - val_acc: 0.9834\n",
      "Epoch 704/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0785 - val_acc: 0.9860\n",
      "Epoch 705/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0131 - acc: 0.9966 - val_loss: 0.0748 - val_acc: 0.9869\n",
      "Epoch 706/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0810 - val_acc: 0.9842\n",
      "Epoch 707/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0152 - acc: 0.9963 - val_loss: 0.0726 - val_acc: 0.9851\n",
      "Epoch 708/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0660 - val_acc: 0.9869\n",
      "Epoch 709/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0112 - acc: 0.9968 - val_loss: 0.0760 - val_acc: 0.9851\n",
      "Epoch 710/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0146 - acc: 0.9960 - val_loss: 0.0806 - val_acc: 0.9851\n",
      "Epoch 711/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0099 - acc: 0.9965 - val_loss: 0.0723 - val_acc: 0.9872\n",
      "Epoch 712/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0114 - acc: 0.9963 - val_loss: 0.0740 - val_acc: 0.9848\n",
      "Epoch 713/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0109 - acc: 0.9970 - val_loss: 0.0824 - val_acc: 0.9837\n",
      "Epoch 714/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.2563 - acc: 0.9422 - val_loss: 0.2392 - val_acc: 0.9481\n",
      "Epoch 715/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1149 - acc: 0.9705 - val_loss: 0.1257 - val_acc: 0.9723\n",
      "Epoch 716/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1747 - acc: 0.9645 - val_loss: 0.1537 - val_acc: 0.9629\n",
      "Epoch 717/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0875 - acc: 0.9781 - val_loss: 0.1077 - val_acc: 0.9764\n",
      "Epoch 718/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0484 - acc: 0.9871 - val_loss: 0.0800 - val_acc: 0.9810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0305 - acc: 0.9905 - val_loss: 0.0833 - val_acc: 0.9804\n",
      "Epoch 720/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0252 - acc: 0.9920 - val_loss: 0.0890 - val_acc: 0.9793\n",
      "Epoch 721/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0342 - acc: 0.9921 - val_loss: 0.0785 - val_acc: 0.9819\n",
      "Epoch 722/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0297 - acc: 0.9928 - val_loss: 0.0772 - val_acc: 0.9819\n",
      "Epoch 723/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0211 - acc: 0.9948 - val_loss: 0.0810 - val_acc: 0.9804\n",
      "Epoch 724/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0151 - acc: 0.9954 - val_loss: 0.0777 - val_acc: 0.9828\n",
      "Epoch 725/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0154 - acc: 0.9957 - val_loss: 0.0734 - val_acc: 0.9845\n",
      "Epoch 726/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0121 - acc: 0.9957 - val_loss: 0.0657 - val_acc: 0.9842\n",
      "Epoch 727/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0698 - val_acc: 0.9828\n",
      "Epoch 728/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0128 - acc: 0.9967 - val_loss: 0.0667 - val_acc: 0.9851\n",
      "Epoch 729/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0128 - acc: 0.9960 - val_loss: 0.0662 - val_acc: 0.9840\n",
      "Epoch 730/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0147 - acc: 0.9957 - val_loss: 0.0743 - val_acc: 0.9837\n",
      "Epoch 731/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0128 - acc: 0.9962 - val_loss: 0.0715 - val_acc: 0.9860\n",
      "Epoch 732/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0103 - acc: 0.9971 - val_loss: 0.0743 - val_acc: 0.9860\n",
      "Epoch 733/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0132 - acc: 0.9963 - val_loss: 0.0714 - val_acc: 0.9837\n",
      "Epoch 734/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.0786 - val_acc: 0.9863\n",
      "Epoch 735/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0697 - val_acc: 0.9866\n",
      "Epoch 736/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0068 - acc: 0.9975 - val_loss: 0.0836 - val_acc: 0.9857\n",
      "Epoch 737/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0096 - acc: 0.9973 - val_loss: 0.0735 - val_acc: 0.9860\n",
      "Epoch 738/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0116 - acc: 0.9963 - val_loss: 0.0685 - val_acc: 0.9837\n",
      "Epoch 739/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0097 - acc: 0.9969 - val_loss: 0.0521 - val_acc: 0.9895\n",
      "Epoch 740/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0522 - val_acc: 0.9872\n",
      "Epoch 741/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0495 - val_acc: 0.9889\n",
      "Epoch 742/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0622 - val_acc: 0.9857\n",
      "Epoch 743/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0088 - acc: 0.9969 - val_loss: 0.0704 - val_acc: 0.9851\n",
      "Epoch 744/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0130 - acc: 0.9973 - val_loss: 0.0557 - val_acc: 0.9875\n",
      "Epoch 745/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0120 - acc: 0.9965 - val_loss: 0.0707 - val_acc: 0.9863\n",
      "Epoch 746/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0104 - acc: 0.9971 - val_loss: 0.0585 - val_acc: 0.9892\n",
      "Epoch 747/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0119 - acc: 0.9967 - val_loss: 0.0674 - val_acc: 0.9857\n",
      "Epoch 748/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0131 - acc: 0.9965 - val_loss: 0.0709 - val_acc: 0.9837\n",
      "Epoch 749/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0127 - acc: 0.9972 - val_loss: 0.0786 - val_acc: 0.9848\n",
      "Epoch 750/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0112 - acc: 0.9962 - val_loss: 0.0675 - val_acc: 0.9848\n",
      "Epoch 751/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0100 - acc: 0.9968 - val_loss: 0.0628 - val_acc: 0.9863\n",
      "Epoch 752/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0094 - acc: 0.9976 - val_loss: 0.0631 - val_acc: 0.9854\n",
      "Epoch 753/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0060 - acc: 0.9978 - val_loss: 0.0673 - val_acc: 0.9872\n",
      "Epoch 754/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9972 - val_loss: 0.0610 - val_acc: 0.9875\n",
      "Epoch 755/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0094 - acc: 0.9976 - val_loss: 0.0601 - val_acc: 0.9875\n",
      "Epoch 756/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0082 - acc: 0.9979 - val_loss: 0.0775 - val_acc: 0.9854\n",
      "Epoch 757/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0716 - val_acc: 0.9840\n",
      "Epoch 758/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0136 - acc: 0.9964 - val_loss: 0.0705 - val_acc: 0.9880\n",
      "Epoch 759/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0722 - val_acc: 0.9857\n",
      "Epoch 760/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0691 - val_acc: 0.9857\n",
      "Epoch 761/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0103 - acc: 0.9973 - val_loss: 0.0681 - val_acc: 0.9854\n",
      "Epoch 762/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0133 - acc: 0.9964 - val_loss: 0.0705 - val_acc: 0.9863\n",
      "Epoch 763/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0114 - acc: 0.9971 - val_loss: 0.0554 - val_acc: 0.9886\n",
      "Epoch 764/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0125 - acc: 0.9965 - val_loss: 0.0619 - val_acc: 0.9848\n",
      "Epoch 765/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0113 - acc: 0.9971 - val_loss: 0.0650 - val_acc: 0.9877\n",
      "Epoch 766/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0104 - acc: 0.9969 - val_loss: 0.0758 - val_acc: 0.9854\n",
      "Epoch 767/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0147 - acc: 0.9960 - val_loss: 0.0763 - val_acc: 0.9851\n",
      "Epoch 768/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0098 - acc: 0.9973 - val_loss: 0.0805 - val_acc: 0.9842\n",
      "Epoch 769/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0732 - val_acc: 0.9842\n",
      "Epoch 770/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0116 - acc: 0.9972 - val_loss: 0.0807 - val_acc: 0.9840\n",
      "Epoch 771/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0121 - acc: 0.9967 - val_loss: 0.0755 - val_acc: 0.9825\n",
      "Epoch 772/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0113 - acc: 0.9973 - val_loss: 0.0734 - val_acc: 0.9860\n",
      "Epoch 773/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0131 - acc: 0.9963 - val_loss: 0.0757 - val_acc: 0.9857\n",
      "Epoch 774/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0160 - acc: 0.9958 - val_loss: 0.0682 - val_acc: 0.9863\n",
      "Epoch 775/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0656 - val_acc: 0.9854\n",
      "Epoch 776/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0096 - acc: 0.9971 - val_loss: 0.0809 - val_acc: 0.9860\n",
      "Epoch 777/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0108 - acc: 0.9975 - val_loss: 0.0725 - val_acc: 0.9886\n",
      "Epoch 778/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0273 - acc: 0.9951 - val_loss: 0.0780 - val_acc: 0.9819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0130 - acc: 0.9959 - val_loss: 0.0767 - val_acc: 0.9831\n",
      "Epoch 780/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0116 - acc: 0.9966 - val_loss: 0.0785 - val_acc: 0.9848\n",
      "Epoch 781/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0679 - val_acc: 0.9857\n",
      "Epoch 782/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0081 - acc: 0.9977 - val_loss: 0.0717 - val_acc: 0.9854\n",
      "Epoch 783/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0779 - val_acc: 0.9837\n",
      "Epoch 784/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0094 - acc: 0.9976 - val_loss: 0.0648 - val_acc: 0.9860\n",
      "Epoch 785/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0655 - val_acc: 0.9845\n",
      "Epoch 786/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0105 - acc: 0.9968 - val_loss: 0.0840 - val_acc: 0.9825\n",
      "Epoch 787/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0271 - acc: 0.9933 - val_loss: 0.0738 - val_acc: 0.9822\n",
      "Epoch 788/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0139 - acc: 0.9963 - val_loss: 0.0793 - val_acc: 0.9857\n",
      "Epoch 789/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0161 - acc: 0.9966 - val_loss: 0.0694 - val_acc: 0.9828\n",
      "Epoch 790/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0195 - acc: 0.9944 - val_loss: 0.0800 - val_acc: 0.9837\n",
      "Epoch 791/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0180 - acc: 0.9957 - val_loss: 0.0675 - val_acc: 0.9845\n",
      "Epoch 792/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0219 - acc: 0.9964 - val_loss: 0.0675 - val_acc: 0.9848\n",
      "Epoch 793/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0075 - acc: 0.9976 - val_loss: 0.0699 - val_acc: 0.9848\n",
      "Epoch 794/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0080 - acc: 0.9973 - val_loss: 0.0761 - val_acc: 0.9825\n",
      "Epoch 795/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0131 - acc: 0.9966 - val_loss: 0.0646 - val_acc: 0.9854\n",
      "Epoch 796/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0186 - acc: 0.9957 - val_loss: 0.0678 - val_acc: 0.9831\n",
      "Epoch 797/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0195 - acc: 0.9952 - val_loss: 0.0954 - val_acc: 0.9825\n",
      "Epoch 798/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0130 - acc: 0.9965 - val_loss: 0.0751 - val_acc: 0.9845\n",
      "Epoch 799/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0175 - acc: 0.9965 - val_loss: 0.0942 - val_acc: 0.9816\n",
      "Epoch 800/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0180 - acc: 0.9955 - val_loss: 0.0718 - val_acc: 0.9831\n",
      "Epoch 801/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0143 - acc: 0.9963 - val_loss: 0.0988 - val_acc: 0.9813\n",
      "Epoch 802/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0141 - acc: 0.9962 - val_loss: 0.0736 - val_acc: 0.9854\n",
      "Epoch 803/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0149 - acc: 0.9959 - val_loss: 0.0725 - val_acc: 0.9842\n",
      "Epoch 804/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0132 - acc: 0.9968 - val_loss: 0.0757 - val_acc: 0.9842\n",
      "Epoch 805/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0143 - acc: 0.9960 - val_loss: 0.0801 - val_acc: 0.9842\n",
      "Epoch 806/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0098 - acc: 0.9971 - val_loss: 0.0786 - val_acc: 0.9837\n",
      "Epoch 807/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0121 - acc: 0.9971 - val_loss: 0.0756 - val_acc: 0.9860\n",
      "Epoch 808/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0127 - acc: 0.9960 - val_loss: 0.0700 - val_acc: 0.9854\n",
      "Epoch 809/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0084 - acc: 0.9975 - val_loss: 0.0884 - val_acc: 0.9840\n",
      "Epoch 810/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0787 - val_acc: 0.9834\n",
      "Epoch 811/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0117 - acc: 0.9968 - val_loss: 0.0744 - val_acc: 0.9857\n",
      "Epoch 812/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0157 - acc: 0.9963 - val_loss: 0.0967 - val_acc: 0.9825\n",
      "Epoch 813/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0174 - acc: 0.9955 - val_loss: 0.0985 - val_acc: 0.9804\n",
      "Epoch 814/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0157 - acc: 0.9955 - val_loss: 0.0702 - val_acc: 0.9863\n",
      "Epoch 815/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0094 - acc: 0.9981 - val_loss: 0.0852 - val_acc: 0.9828\n",
      "Epoch 816/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0119 - acc: 0.9971 - val_loss: 0.0814 - val_acc: 0.9840\n",
      "Epoch 817/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9981 - val_loss: 0.0894 - val_acc: 0.9842\n",
      "Epoch 818/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0095 - acc: 0.9975 - val_loss: 0.0870 - val_acc: 0.9831\n",
      "Epoch 819/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0239 - acc: 0.9959 - val_loss: 0.1149 - val_acc: 0.9822\n",
      "Epoch 820/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0262 - acc: 0.9949 - val_loss: 0.1050 - val_acc: 0.9819\n",
      "Epoch 821/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0138 - acc: 0.9961 - val_loss: 0.0778 - val_acc: 0.9825\n",
      "Epoch 822/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0160 - acc: 0.9955 - val_loss: 0.0865 - val_acc: 0.9828\n",
      "Epoch 823/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0203 - acc: 0.9948 - val_loss: 0.0953 - val_acc: 0.9822\n",
      "Epoch 824/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0114 - acc: 0.9968 - val_loss: 0.1230 - val_acc: 0.9834\n",
      "Epoch 825/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0098 - acc: 0.9972 - val_loss: 0.0941 - val_acc: 0.9851\n",
      "Epoch 826/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0782 - val_acc: 0.9866\n",
      "Epoch 827/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0095 - acc: 0.9979 - val_loss: 0.0804 - val_acc: 0.9854\n",
      "Epoch 828/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0173 - acc: 0.9960 - val_loss: 0.0832 - val_acc: 0.9857\n",
      "Epoch 829/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0149 - acc: 0.9959 - val_loss: 0.0809 - val_acc: 0.9837\n",
      "Epoch 830/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0948 - val_acc: 0.9831\n",
      "Epoch 831/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.0882 - val_acc: 0.9857\n",
      "Epoch 832/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0084 - acc: 0.9973 - val_loss: 0.0807 - val_acc: 0.9872\n",
      "Epoch 833/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0150 - acc: 0.9964 - val_loss: 0.0971 - val_acc: 0.9828\n",
      "Epoch 834/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0123 - acc: 0.9969 - val_loss: 0.1037 - val_acc: 0.9837\n",
      "Epoch 835/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0110 - acc: 0.9973 - val_loss: 0.0922 - val_acc: 0.9831\n",
      "Epoch 836/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0189 - acc: 0.9957 - val_loss: 0.0674 - val_acc: 0.9854\n",
      "Epoch 837/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0132 - acc: 0.9966 - val_loss: 0.0665 - val_acc: 0.9860\n",
      "Epoch 838/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0127 - acc: 0.9956 - val_loss: 0.0979 - val_acc: 0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0154 - acc: 0.9960 - val_loss: 0.0921 - val_acc: 0.9845\n",
      "Epoch 840/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0194 - acc: 0.9958 - val_loss: 0.0956 - val_acc: 0.9819\n",
      "Epoch 841/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0224 - acc: 0.9954 - val_loss: 0.0852 - val_acc: 0.9842\n",
      "Epoch 842/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0163 - acc: 0.9956 - val_loss: 0.0825 - val_acc: 0.9834\n",
      "Epoch 843/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0155 - acc: 0.9957 - val_loss: 0.0688 - val_acc: 0.9825\n",
      "Epoch 844/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0142 - acc: 0.9952 - val_loss: 0.0963 - val_acc: 0.9804\n",
      "Epoch 845/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0215 - acc: 0.9940 - val_loss: 0.0921 - val_acc: 0.9840\n",
      "Epoch 846/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0178 - acc: 0.9958 - val_loss: 0.0762 - val_acc: 0.9869\n",
      "Epoch 847/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0108 - acc: 0.9968 - val_loss: 0.0764 - val_acc: 0.9851\n",
      "Epoch 848/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0152 - acc: 0.9953 - val_loss: 0.0801 - val_acc: 0.9848\n",
      "Epoch 849/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0103 - acc: 0.9958 - val_loss: 0.0884 - val_acc: 0.9854\n",
      "Epoch 850/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0119 - acc: 0.9967 - val_loss: 0.0868 - val_acc: 0.9831\n",
      "Epoch 851/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0236 - acc: 0.9954 - val_loss: 0.0915 - val_acc: 0.9845\n",
      "Epoch 852/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0153 - acc: 0.9959 - val_loss: 0.0884 - val_acc: 0.9831\n",
      "Epoch 853/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0166 - acc: 0.9952 - val_loss: 0.0687 - val_acc: 0.9860\n",
      "Epoch 854/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0114 - acc: 0.9965 - val_loss: 0.0583 - val_acc: 0.9877\n",
      "Epoch 855/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0632 - acc: 0.9856 - val_loss: 0.1353 - val_acc: 0.9699\n",
      "Epoch 856/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0336 - acc: 0.9915 - val_loss: 0.0833 - val_acc: 0.9802\n",
      "Epoch 857/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0192 - acc: 0.9950 - val_loss: 0.0706 - val_acc: 0.9816\n",
      "Epoch 858/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0177 - acc: 0.9957 - val_loss: 0.0633 - val_acc: 0.9842\n",
      "Epoch 859/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0141 - acc: 0.9957 - val_loss: 0.0780 - val_acc: 0.9837\n",
      "Epoch 860/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0205 - acc: 0.9959 - val_loss: 0.0762 - val_acc: 0.9807\n",
      "Epoch 861/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0180 - acc: 0.9959 - val_loss: 0.0753 - val_acc: 0.9845\n",
      "Epoch 862/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0136 - acc: 0.9967 - val_loss: 0.0767 - val_acc: 0.9842\n",
      "Epoch 863/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0143 - acc: 0.9956 - val_loss: 0.0867 - val_acc: 0.9819\n",
      "Epoch 864/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 0.0761 - val_acc: 0.9828\n",
      "Epoch 865/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0104 - acc: 0.9969 - val_loss: 0.0700 - val_acc: 0.9842\n",
      "Epoch 866/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0104 - acc: 0.9968 - val_loss: 0.0610 - val_acc: 0.9863\n",
      "Epoch 867/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0141 - acc: 0.9961 - val_loss: 0.0649 - val_acc: 0.9854\n",
      "Epoch 868/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0095 - acc: 0.9969 - val_loss: 0.0623 - val_acc: 0.9866\n",
      "Epoch 869/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0148 - acc: 0.9964 - val_loss: 0.0784 - val_acc: 0.9842\n",
      "Epoch 870/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0118 - acc: 0.9976 - val_loss: 0.0767 - val_acc: 0.9842\n",
      "Epoch 871/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0122 - acc: 0.9971 - val_loss: 0.0762 - val_acc: 0.9831\n",
      "Epoch 872/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0061 - acc: 0.9976 - val_loss: 0.0717 - val_acc: 0.9845\n",
      "Epoch 873/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0120 - acc: 0.9970 - val_loss: 0.0862 - val_acc: 0.9828\n",
      "Epoch 874/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0137 - acc: 0.9965 - val_loss: 0.1044 - val_acc: 0.9816\n",
      "Epoch 875/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0097 - acc: 0.9979 - val_loss: 0.0853 - val_acc: 0.9851\n",
      "Epoch 876/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0095 - acc: 0.9977 - val_loss: 0.0968 - val_acc: 0.9837\n",
      "Epoch 877/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0095 - acc: 0.9976 - val_loss: 0.0886 - val_acc: 0.9825\n",
      "Epoch 878/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0099 - acc: 0.9979 - val_loss: 0.0686 - val_acc: 0.9863\n",
      "Epoch 879/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0695 - val_acc: 0.9863\n",
      "Epoch 880/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9983 - val_loss: 0.0806 - val_acc: 0.9854\n",
      "Epoch 881/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0837 - val_acc: 0.9869\n",
      "Epoch 882/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.0836 - val_acc: 0.9860\n",
      "Epoch 883/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9971 - val_loss: 0.0701 - val_acc: 0.9848\n",
      "Epoch 884/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0153 - acc: 0.9967 - val_loss: 0.0769 - val_acc: 0.9872\n",
      "Epoch 885/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0103 - acc: 0.9966 - val_loss: 0.0747 - val_acc: 0.9851\n",
      "Epoch 886/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0107 - acc: 0.9972 - val_loss: 0.1012 - val_acc: 0.9834\n",
      "Epoch 887/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0167 - acc: 0.9963 - val_loss: 0.0911 - val_acc: 0.9860\n",
      "Epoch 888/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0128 - acc: 0.9957 - val_loss: 0.0760 - val_acc: 0.9872\n",
      "Epoch 889/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0105 - acc: 0.9969 - val_loss: 0.0923 - val_acc: 0.9854\n",
      "Epoch 890/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0707 - val_acc: 0.9875\n",
      "Epoch 891/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0149 - acc: 0.9965 - val_loss: 0.0861 - val_acc: 0.9863\n",
      "Epoch 892/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0191 - acc: 0.9965 - val_loss: 0.0626 - val_acc: 0.9869\n",
      "Epoch 893/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0094 - acc: 0.9971 - val_loss: 0.0723 - val_acc: 0.9869\n",
      "Epoch 894/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0181 - acc: 0.9951 - val_loss: 0.0715 - val_acc: 0.9851\n",
      "Epoch 895/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0106 - acc: 0.9968 - val_loss: 0.0753 - val_acc: 0.9866\n",
      "Epoch 896/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0156 - acc: 0.9962 - val_loss: 0.0879 - val_acc: 0.9845\n",
      "Epoch 897/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0164 - acc: 0.9948 - val_loss: 0.0902 - val_acc: 0.9834\n",
      "Epoch 898/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0190 - acc: 0.9948 - val_loss: 0.0947 - val_acc: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0118 - acc: 0.9968 - val_loss: 0.0813 - val_acc: 0.9863\n",
      "Epoch 900/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0137 - acc: 0.9962 - val_loss: 0.0885 - val_acc: 0.9851\n",
      "Epoch 901/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0286 - acc: 0.9946 - val_loss: 0.0723 - val_acc: 0.9840\n",
      "Epoch 902/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0467 - acc: 0.9940 - val_loss: 0.1359 - val_acc: 0.9807\n",
      "Epoch 903/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0783 - acc: 0.9854 - val_loss: 0.1043 - val_acc: 0.9746\n",
      "Epoch 904/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0332 - acc: 0.9922 - val_loss: 0.0842 - val_acc: 0.9845\n",
      "Epoch 905/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0222 - acc: 0.9951 - val_loss: 0.0737 - val_acc: 0.9848\n",
      "Epoch 906/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.0688 - val_acc: 0.9866\n",
      "Epoch 907/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0213 - acc: 0.9942 - val_loss: 0.0563 - val_acc: 0.9872\n",
      "Epoch 908/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0184 - acc: 0.9954 - val_loss: 0.0827 - val_acc: 0.9851\n",
      "Epoch 909/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0143 - acc: 0.9957 - val_loss: 0.0618 - val_acc: 0.9863\n",
      "Epoch 910/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0176 - acc: 0.9959 - val_loss: 0.0705 - val_acc: 0.9828\n",
      "Epoch 911/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0156 - acc: 0.9958 - val_loss: 0.0685 - val_acc: 0.9866\n",
      "Epoch 912/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0122 - acc: 0.9966 - val_loss: 0.0607 - val_acc: 0.9872\n",
      "Epoch 913/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0163 - acc: 0.9962 - val_loss: 0.0662 - val_acc: 0.9872\n",
      "Epoch 914/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0109 - acc: 0.9971 - val_loss: 0.0701 - val_acc: 0.9860\n",
      "Epoch 915/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0085 - acc: 0.9980 - val_loss: 0.0713 - val_acc: 0.9869\n",
      "Epoch 916/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0120 - acc: 0.9968 - val_loss: 0.0824 - val_acc: 0.9863\n",
      "Epoch 917/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0844 - val_acc: 0.9848\n",
      "Epoch 918/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0094 - acc: 0.9971 - val_loss: 0.0930 - val_acc: 0.9822\n",
      "Epoch 919/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0844 - val_acc: 0.9854\n",
      "Epoch 920/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0107 - acc: 0.9973 - val_loss: 0.0787 - val_acc: 0.9877\n",
      "Epoch 921/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0105 - acc: 0.9975 - val_loss: 0.0732 - val_acc: 0.9869\n",
      "Epoch 922/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0817 - val_acc: 0.9845\n",
      "Epoch 923/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0721 - val_acc: 0.9857\n",
      "Epoch 924/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0108 - acc: 0.9978 - val_loss: 0.0788 - val_acc: 0.9866\n",
      "Epoch 925/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0109 - acc: 0.9972 - val_loss: 0.0786 - val_acc: 0.9863\n",
      "Epoch 926/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.0847 - val_acc: 0.9842\n",
      "Epoch 927/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0789 - val_acc: 0.9875\n",
      "Epoch 928/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0058 - acc: 0.9978 - val_loss: 0.0847 - val_acc: 0.9857\n",
      "Epoch 929/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0747 - val_acc: 0.9872\n",
      "Epoch 930/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0050 - acc: 0.9981 - val_loss: 0.0672 - val_acc: 0.9883\n",
      "Epoch 931/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0125 - acc: 0.9967 - val_loss: 0.0602 - val_acc: 0.9872\n",
      "Epoch 932/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0093 - acc: 0.9972 - val_loss: 0.0652 - val_acc: 0.9875\n",
      "Epoch 933/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0092 - acc: 0.9973 - val_loss: 0.0776 - val_acc: 0.9857\n",
      "Epoch 934/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 0.0774 - val_acc: 0.9848\n",
      "Epoch 935/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0791 - val_acc: 0.9860\n",
      "Epoch 936/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.0684 - val_acc: 0.9869\n",
      "Epoch 937/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0113 - acc: 0.9967 - val_loss: 0.0664 - val_acc: 0.9872\n",
      "Epoch 938/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0081 - acc: 0.9973 - val_loss: 0.0899 - val_acc: 0.9854\n",
      "Epoch 939/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0111 - acc: 0.9963 - val_loss: 0.0765 - val_acc: 0.9860\n",
      "Epoch 940/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0796 - val_acc: 0.9872\n",
      "Epoch 941/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.1000 - val_acc: 0.9869\n",
      "Epoch 942/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0888 - val_acc: 0.9851\n",
      "Epoch 943/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0890 - val_acc: 0.9834\n",
      "Epoch 944/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0133 - acc: 0.9971 - val_loss: 0.0863 - val_acc: 0.9875\n",
      "Epoch 945/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0125 - acc: 0.9968 - val_loss: 0.0812 - val_acc: 0.9848\n",
      "Epoch 946/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0778 - val_acc: 0.9845\n",
      "Epoch 947/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0194 - acc: 0.9945 - val_loss: 0.0800 - val_acc: 0.9845\n",
      "Epoch 948/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0230 - acc: 0.9946 - val_loss: 0.0949 - val_acc: 0.9834\n",
      "Epoch 949/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0123 - acc: 0.9965 - val_loss: 0.0842 - val_acc: 0.9860\n",
      "Epoch 950/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0147 - acc: 0.9967 - val_loss: 0.0986 - val_acc: 0.9851\n",
      "Epoch 951/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0098 - acc: 0.9965 - val_loss: 0.0789 - val_acc: 0.9872\n",
      "Epoch 952/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0101 - acc: 0.9972 - val_loss: 0.0899 - val_acc: 0.9863\n",
      "Epoch 953/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0099 - acc: 0.9968 - val_loss: 0.0924 - val_acc: 0.9845\n",
      "Epoch 954/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0141 - acc: 0.9966 - val_loss: 0.1059 - val_acc: 0.9834\n",
      "Epoch 955/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0145 - acc: 0.9958 - val_loss: 0.0996 - val_acc: 0.9816\n",
      "Epoch 956/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0180 - acc: 0.9959 - val_loss: 0.1242 - val_acc: 0.9816\n",
      "Epoch 957/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0129 - acc: 0.9962 - val_loss: 0.0849 - val_acc: 0.9845\n",
      "Epoch 958/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0989 - val_acc: 0.9831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0680 - acc: 0.9905 - val_loss: 0.1554 - val_acc: 0.9778\n",
      "Epoch 960/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1071 - acc: 0.9834 - val_loss: 0.1512 - val_acc: 0.9702\n",
      "Epoch 961/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1198 - acc: 0.9736 - val_loss: 0.1461 - val_acc: 0.9761\n",
      "Epoch 962/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.2430 - acc: 0.9512 - val_loss: 0.1676 - val_acc: 0.9583\n",
      "Epoch 963/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0823 - acc: 0.9800 - val_loss: 0.1516 - val_acc: 0.9734\n",
      "Epoch 964/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0651 - acc: 0.9853 - val_loss: 0.1051 - val_acc: 0.9778\n",
      "Epoch 965/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0313 - acc: 0.9914 - val_loss: 0.0809 - val_acc: 0.9819\n",
      "Epoch 966/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0303 - acc: 0.9937 - val_loss: 0.0787 - val_acc: 0.9842\n",
      "Epoch 967/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0216 - acc: 0.9945 - val_loss: 0.0898 - val_acc: 0.9842\n",
      "Epoch 968/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0181 - acc: 0.9942 - val_loss: 0.0832 - val_acc: 0.9848\n",
      "Epoch 969/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0152 - acc: 0.9962 - val_loss: 0.0842 - val_acc: 0.9828\n",
      "Epoch 970/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0145 - acc: 0.9957 - val_loss: 0.0932 - val_acc: 0.9825\n",
      "Epoch 971/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0567 - acc: 0.9861 - val_loss: 0.1200 - val_acc: 0.9755\n",
      "Epoch 972/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0441 - acc: 0.9900 - val_loss: 0.1263 - val_acc: 0.9755\n",
      "Epoch 973/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0569 - acc: 0.9878 - val_loss: 0.1289 - val_acc: 0.9761\n",
      "Epoch 974/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0358 - acc: 0.9898 - val_loss: 0.0895 - val_acc: 0.9822\n",
      "Epoch 975/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0168 - acc: 0.9957 - val_loss: 0.0869 - val_acc: 0.9831\n",
      "Epoch 976/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0179 - acc: 0.9954 - val_loss: 0.0875 - val_acc: 0.9822\n",
      "Epoch 977/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0132 - acc: 0.9961 - val_loss: 0.0822 - val_acc: 0.9828\n",
      "Epoch 978/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0803 - val_acc: 0.9842\n",
      "Epoch 979/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0100 - acc: 0.9972 - val_loss: 0.0782 - val_acc: 0.9866\n",
      "Epoch 980/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0114 - acc: 0.9972 - val_loss: 0.0754 - val_acc: 0.9854\n",
      "Epoch 981/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0106 - acc: 0.9971 - val_loss: 0.0804 - val_acc: 0.9854\n",
      "Epoch 982/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0096 - acc: 0.9973 - val_loss: 0.0861 - val_acc: 0.9851\n",
      "Epoch 983/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0101 - acc: 0.9974 - val_loss: 0.0839 - val_acc: 0.9875\n",
      "Epoch 984/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0132 - acc: 0.9972 - val_loss: 0.0911 - val_acc: 0.9837\n",
      "Epoch 985/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0769 - val_acc: 0.9860\n",
      "Epoch 986/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0791 - val_acc: 0.9863\n",
      "Epoch 987/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0131 - acc: 0.9966 - val_loss: 0.0715 - val_acc: 0.9889\n",
      "Epoch 988/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0121 - acc: 0.9973 - val_loss: 0.0654 - val_acc: 0.9895\n",
      "Epoch 989/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0119 - acc: 0.9968 - val_loss: 0.0782 - val_acc: 0.9875\n",
      "Epoch 990/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0120 - acc: 0.9971 - val_loss: 0.0738 - val_acc: 0.9845\n",
      "Epoch 991/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0108 - acc: 0.9975 - val_loss: 0.0872 - val_acc: 0.9851\n",
      "Epoch 992/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0071 - acc: 0.9982 - val_loss: 0.0857 - val_acc: 0.9866\n",
      "Epoch 993/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0085 - acc: 0.9975 - val_loss: 0.0679 - val_acc: 0.9872\n",
      "Epoch 994/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0057 - acc: 0.9982 - val_loss: 0.0770 - val_acc: 0.9869\n",
      "Epoch 995/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0089 - acc: 0.9978 - val_loss: 0.0707 - val_acc: 0.9869\n",
      "Epoch 996/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9978 - val_loss: 0.0740 - val_acc: 0.9866\n",
      "Epoch 997/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9982 - val_loss: 0.0772 - val_acc: 0.9877\n",
      "Epoch 998/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0813 - val_acc: 0.9869\n",
      "Epoch 999/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 0.0882 - val_acc: 0.9880\n",
      "Epoch 1000/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.0757 - val_acc: 0.9883\n",
      "Epoch 1001/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.0752 - val_acc: 0.9875\n",
      "Epoch 1002/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 1003/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0838 - val_acc: 0.9875\n",
      "Epoch 1004/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0781 - acc: 0.9857 - val_loss: 0.1321 - val_acc: 0.9743\n",
      "Epoch 1005/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0326 - acc: 0.9921 - val_loss: 0.0827 - val_acc: 0.9831\n",
      "Epoch 1006/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0213 - acc: 0.9946 - val_loss: 0.0931 - val_acc: 0.9825\n",
      "Epoch 1007/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0145 - acc: 0.9964 - val_loss: 0.0888 - val_acc: 0.9816\n",
      "Epoch 1008/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0103 - acc: 0.9973 - val_loss: 0.0899 - val_acc: 0.9813\n",
      "Epoch 1009/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0926 - val_acc: 0.9831\n",
      "Epoch 1010/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0145 - acc: 0.9958 - val_loss: 0.0861 - val_acc: 0.9837\n",
      "Epoch 1011/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0097 - acc: 0.9969 - val_loss: 0.0901 - val_acc: 0.9819\n",
      "Epoch 1012/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0209 - acc: 0.9955 - val_loss: 0.0976 - val_acc: 0.9831\n",
      "Epoch 1013/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0269 - acc: 0.9938 - val_loss: 0.1140 - val_acc: 0.9819\n",
      "Epoch 1014/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0159 - acc: 0.9952 - val_loss: 0.1021 - val_acc: 0.9825\n",
      "Epoch 1015/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0805 - acc: 0.9891 - val_loss: 0.1134 - val_acc: 0.9793\n",
      "Epoch 1016/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.2372 - acc: 0.9603 - val_loss: 0.3414 - val_acc: 0.9282\n",
      "Epoch 1017/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1767 - acc: 0.9677 - val_loss: 0.1861 - val_acc: 0.9691\n",
      "Epoch 1018/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0929 - acc: 0.9871 - val_loss: 0.1101 - val_acc: 0.9778\n",
      "Epoch 1019/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0668 - acc: 0.9910 - val_loss: 0.1145 - val_acc: 0.9793\n",
      "Epoch 1020/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0638 - acc: 0.9880 - val_loss: 0.1628 - val_acc: 0.9676\n",
      "Epoch 1021/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0848 - acc: 0.9796 - val_loss: 0.1245 - val_acc: 0.9758\n",
      "Epoch 1022/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0422 - acc: 0.9916 - val_loss: 0.1015 - val_acc: 0.9810\n",
      "Epoch 1023/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1816 - acc: 0.9581 - val_loss: 0.1584 - val_acc: 0.9688\n",
      "Epoch 1024/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1057 - acc: 0.9792 - val_loss: 0.1478 - val_acc: 0.9685\n",
      "Epoch 1025/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0857 - acc: 0.9800 - val_loss: 0.0986 - val_acc: 0.9778\n",
      "Epoch 1026/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0725 - acc: 0.9876 - val_loss: 0.2053 - val_acc: 0.9664\n",
      "Epoch 1027/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0966 - acc: 0.9867 - val_loss: 0.1521 - val_acc: 0.9685\n",
      "Epoch 1028/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1354 - acc: 0.9686 - val_loss: 0.1220 - val_acc: 0.9734\n",
      "Epoch 1029/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0671 - acc: 0.9854 - val_loss: 0.1173 - val_acc: 0.9740\n",
      "Epoch 1030/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0450 - acc: 0.9899 - val_loss: 0.0950 - val_acc: 0.9793\n",
      "Epoch 1031/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0353 - acc: 0.9923 - val_loss: 0.0921 - val_acc: 0.9799\n",
      "Epoch 1032/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0290 - acc: 0.9939 - val_loss: 0.0854 - val_acc: 0.9819\n",
      "Epoch 1033/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0286 - acc: 0.9944 - val_loss: 0.0847 - val_acc: 0.9840\n",
      "Epoch 1034/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0207 - acc: 0.9951 - val_loss: 0.0860 - val_acc: 0.9825\n",
      "Epoch 1035/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0204 - acc: 0.9955 - val_loss: 0.0875 - val_acc: 0.9819\n",
      "Epoch 1036/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0194 - acc: 0.9949 - val_loss: 0.0771 - val_acc: 0.9840\n",
      "Epoch 1037/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0213 - acc: 0.9953 - val_loss: 0.0714 - val_acc: 0.9851\n",
      "Epoch 1038/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0230 - acc: 0.9947 - val_loss: 0.0766 - val_acc: 0.9845\n",
      "Epoch 1039/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0166 - acc: 0.9964 - val_loss: 0.0781 - val_acc: 0.9848\n",
      "Epoch 1040/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0162 - acc: 0.9960 - val_loss: 0.0739 - val_acc: 0.9860\n",
      "Epoch 1041/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0599 - acc: 0.9895 - val_loss: 0.2229 - val_acc: 0.9612\n",
      "Epoch 1042/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0968 - acc: 0.9835 - val_loss: 0.1341 - val_acc: 0.9761\n",
      "Epoch 1043/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0483 - acc: 0.9896 - val_loss: 0.1105 - val_acc: 0.9807\n",
      "Epoch 1044/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0252 - acc: 0.9936 - val_loss: 0.0861 - val_acc: 0.9837\n",
      "Epoch 1045/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0212 - acc: 0.9948 - val_loss: 0.0824 - val_acc: 0.9842\n",
      "Epoch 1046/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0174 - acc: 0.9959 - val_loss: 0.0834 - val_acc: 0.9851\n",
      "Epoch 1047/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0121 - acc: 0.9968 - val_loss: 0.0811 - val_acc: 0.9860\n",
      "Epoch 1048/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0155 - acc: 0.9962 - val_loss: 0.0716 - val_acc: 0.9851\n",
      "Epoch 1049/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0149 - acc: 0.9971 - val_loss: 0.0786 - val_acc: 0.9860\n",
      "Epoch 1050/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0127 - acc: 0.9969 - val_loss: 0.0809 - val_acc: 0.9869\n",
      "Epoch 1051/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0171 - acc: 0.9962 - val_loss: 0.0785 - val_acc: 0.9857\n",
      "Epoch 1052/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0128 - acc: 0.9963 - val_loss: 0.0777 - val_acc: 0.9863\n",
      "Epoch 1053/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0165 - acc: 0.9962 - val_loss: 0.0724 - val_acc: 0.9863\n",
      "Epoch 1054/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0116 - acc: 0.9968 - val_loss: 0.0672 - val_acc: 0.9869\n",
      "Epoch 1055/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9977 - val_loss: 0.0719 - val_acc: 0.9863\n",
      "Epoch 1056/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0064 - acc: 0.9978 - val_loss: 0.0668 - val_acc: 0.9869\n",
      "Epoch 1057/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9966 - val_loss: 0.0735 - val_acc: 0.9869\n",
      "Epoch 1058/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0641 - val_acc: 0.9880\n",
      "Epoch 1059/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0136 - acc: 0.9967 - val_loss: 0.0686 - val_acc: 0.9860\n",
      "Epoch 1060/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0107 - acc: 0.9968 - val_loss: 0.0684 - val_acc: 0.9875\n",
      "Epoch 1061/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0148 - acc: 0.9959 - val_loss: 0.0680 - val_acc: 0.9863\n",
      "Epoch 1062/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0111 - acc: 0.9977 - val_loss: 0.0749 - val_acc: 0.9848\n",
      "Epoch 1063/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0105 - acc: 0.9980 - val_loss: 0.0799 - val_acc: 0.9869\n",
      "Epoch 1064/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0826 - val_acc: 0.9863\n",
      "Epoch 1065/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0047 - acc: 0.9982 - val_loss: 0.0863 - val_acc: 0.9857\n",
      "Epoch 1066/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0848 - val_acc: 0.9828\n",
      "Epoch 1067/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0111 - acc: 0.9965 - val_loss: 0.0811 - val_acc: 0.9877\n",
      "Epoch 1068/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0111 - acc: 0.9969 - val_loss: 0.0862 - val_acc: 0.9863\n",
      "Epoch 1069/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0079 - acc: 0.9976 - val_loss: 0.0830 - val_acc: 0.9848\n",
      "Epoch 1070/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0119 - acc: 0.9973 - val_loss: 0.0685 - val_acc: 0.9892\n",
      "Epoch 1071/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0759 - val_acc: 0.9869\n",
      "Epoch 1072/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9976 - val_loss: 0.0689 - val_acc: 0.9872\n",
      "Epoch 1073/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0117 - acc: 0.9968 - val_loss: 0.0807 - val_acc: 0.9866\n",
      "Epoch 1074/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0098 - acc: 0.9971 - val_loss: 0.0817 - val_acc: 0.9842\n",
      "Epoch 1075/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0085 - acc: 0.9966 - val_loss: 0.0764 - val_acc: 0.9866\n",
      "Epoch 1076/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0092 - acc: 0.9973 - val_loss: 0.0814 - val_acc: 0.9848\n",
      "Epoch 1077/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.0758 - val_acc: 0.9875\n",
      "Epoch 1078/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0787 - val_acc: 0.9863\n",
      "Epoch 1079/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.0753 - val_acc: 0.9869\n",
      "Epoch 1080/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0095 - acc: 0.9978 - val_loss: 0.0826 - val_acc: 0.9845\n",
      "Epoch 1081/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0942 - val_acc: 0.9842\n",
      "Epoch 1082/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.0881 - val_acc: 0.9866\n",
      "Epoch 1083/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0088 - acc: 0.9979 - val_loss: 0.0867 - val_acc: 0.9857\n",
      "Epoch 1084/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0772 - val_acc: 0.9872\n",
      "Epoch 1085/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0101 - acc: 0.9977 - val_loss: 0.0816 - val_acc: 0.9854\n",
      "Epoch 1086/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0328 - acc: 0.9935 - val_loss: 0.0694 - val_acc: 0.9880\n",
      "Epoch 1087/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0183 - acc: 0.9959 - val_loss: 0.0874 - val_acc: 0.9819\n",
      "Epoch 1088/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0183 - acc: 0.9952 - val_loss: 0.0702 - val_acc: 0.9869\n",
      "Epoch 1089/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0082 - acc: 0.9976 - val_loss: 0.0910 - val_acc: 0.9854\n",
      "Epoch 1090/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0131 - acc: 0.9968 - val_loss: 0.0695 - val_acc: 0.9872\n",
      "Epoch 1091/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0094 - acc: 0.9978 - val_loss: 0.0760 - val_acc: 0.9880\n",
      "Epoch 1092/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0114 - acc: 0.9970 - val_loss: 0.0725 - val_acc: 0.9872\n",
      "Epoch 1093/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0095 - acc: 0.9975 - val_loss: 0.0692 - val_acc: 0.9872\n",
      "Epoch 1094/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0080 - acc: 0.9976 - val_loss: 0.0752 - val_acc: 0.9872\n",
      "Epoch 1095/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0702 - val_acc: 0.9869\n",
      "Epoch 1096/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0897 - val_acc: 0.9840\n",
      "Epoch 1097/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0056 - acc: 0.9980 - val_loss: 0.0820 - val_acc: 0.9877\n",
      "Epoch 1098/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0794 - val_acc: 0.9875\n",
      "Epoch 1099/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0814 - val_acc: 0.9851\n",
      "Epoch 1100/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0810 - val_acc: 0.9877\n",
      "Epoch 1101/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.0803 - val_acc: 0.9854\n",
      "Epoch 1102/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0881 - val_acc: 0.9845\n",
      "Epoch 1103/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0769 - val_acc: 0.9866\n",
      "Epoch 1104/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0085 - acc: 0.9977 - val_loss: 0.0741 - val_acc: 0.9866\n",
      "Epoch 1105/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0120 - acc: 0.9971 - val_loss: 0.0731 - val_acc: 0.9837\n",
      "Epoch 1106/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0142 - acc: 0.9962 - val_loss: 0.0967 - val_acc: 0.9837\n",
      "Epoch 1107/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0152 - acc: 0.9961 - val_loss: 0.0848 - val_acc: 0.9822\n",
      "Epoch 1108/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0125 - acc: 0.9968 - val_loss: 0.0699 - val_acc: 0.9860\n",
      "Epoch 1109/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.0789 - val_acc: 0.9851\n",
      "Epoch 1110/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0098 - acc: 0.9975 - val_loss: 0.0738 - val_acc: 0.9857\n",
      "Epoch 1111/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0136 - acc: 0.9963 - val_loss: 0.0806 - val_acc: 0.9840\n",
      "Epoch 1112/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0100 - acc: 0.9974 - val_loss: 0.1056 - val_acc: 0.9822\n",
      "Epoch 1113/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0152 - acc: 0.9959 - val_loss: 0.0790 - val_acc: 0.9845\n",
      "Epoch 1114/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0126 - acc: 0.9963 - val_loss: 0.0814 - val_acc: 0.9825\n",
      "Epoch 1115/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0097 - acc: 0.9971 - val_loss: 0.0729 - val_acc: 0.9877\n",
      "Epoch 1116/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0082 - acc: 0.9979 - val_loss: 0.0705 - val_acc: 0.9875\n",
      "Epoch 1117/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0072 - acc: 0.9972 - val_loss: 0.0746 - val_acc: 0.9886\n",
      "Epoch 1118/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0065 - acc: 0.9984 - val_loss: 0.0549 - val_acc: 0.9880\n",
      "Epoch 1119/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0083 - acc: 0.9973 - val_loss: 0.0590 - val_acc: 0.9889\n",
      "Epoch 1120/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9976 - val_loss: 0.0825 - val_acc: 0.9851\n",
      "Epoch 1121/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0858 - val_acc: 0.9860\n",
      "Epoch 1122/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0857 - val_acc: 0.9857\n",
      "Epoch 1123/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9977 - val_loss: 0.0673 - val_acc: 0.9863\n",
      "Epoch 1124/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0055 - acc: 0.9979 - val_loss: 0.0662 - val_acc: 0.9863\n",
      "Epoch 1125/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0729 - val_acc: 0.9842\n",
      "Epoch 1126/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0168 - acc: 0.9953 - val_loss: 0.0695 - val_acc: 0.9872\n",
      "Epoch 1127/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0142 - acc: 0.9968 - val_loss: 0.0848 - val_acc: 0.9860\n",
      "Epoch 1128/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0113 - acc: 0.9973 - val_loss: 0.0690 - val_acc: 0.9875\n",
      "Epoch 1129/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0128 - acc: 0.9965 - val_loss: 0.0644 - val_acc: 0.9877\n",
      "Epoch 1130/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9967 - val_loss: 0.0784 - val_acc: 0.9854\n",
      "Epoch 1131/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0118 - acc: 0.9965 - val_loss: 0.0708 - val_acc: 0.9883\n",
      "Epoch 1132/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0116 - acc: 0.9970 - val_loss: 0.0787 - val_acc: 0.9857\n",
      "Epoch 1133/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0744 - val_acc: 0.9866\n",
      "Epoch 1134/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0112 - acc: 0.9968 - val_loss: 0.0689 - val_acc: 0.9863\n",
      "Epoch 1135/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0152 - acc: 0.9956 - val_loss: 0.0724 - val_acc: 0.9831\n",
      "Epoch 1136/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0132 - acc: 0.9968 - val_loss: 0.0801 - val_acc: 0.9845\n",
      "Epoch 1137/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0115 - acc: 0.9971 - val_loss: 0.0686 - val_acc: 0.9872\n",
      "Epoch 1138/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0727 - val_acc: 0.9898\n",
      "Epoch 1139/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0125 - acc: 0.9971 - val_loss: 0.0659 - val_acc: 0.9877\n",
      "Epoch 1140/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0137 - acc: 0.9960 - val_loss: 0.0925 - val_acc: 0.9834\n",
      "Epoch 1141/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0158 - acc: 0.9959 - val_loss: 0.0740 - val_acc: 0.9845\n",
      "Epoch 1142/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0142 - acc: 0.9960 - val_loss: 0.0903 - val_acc: 0.9837\n",
      "Epoch 1143/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0743 - val_acc: 0.9866\n",
      "Epoch 1144/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0125 - acc: 0.9967 - val_loss: 0.0828 - val_acc: 0.9860\n",
      "Epoch 1145/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0116 - acc: 0.9973 - val_loss: 0.0766 - val_acc: 0.9848\n",
      "Epoch 1146/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0798 - val_acc: 0.9840\n",
      "Epoch 1147/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0972 - val_acc: 0.9816\n",
      "Epoch 1148/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0856 - val_acc: 0.9854\n",
      "Epoch 1149/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0142 - acc: 0.9964 - val_loss: 0.0621 - val_acc: 0.9880\n",
      "Epoch 1150/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0093 - acc: 0.9976 - val_loss: 0.0708 - val_acc: 0.9854\n",
      "Epoch 1151/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.0699 - val_acc: 0.9869\n",
      "Epoch 1152/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.0730 - val_acc: 0.9877\n",
      "Epoch 1153/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0124 - acc: 0.9969 - val_loss: 0.0740 - val_acc: 0.9869\n",
      "Epoch 1154/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0101 - acc: 0.9974 - val_loss: 0.0704 - val_acc: 0.9877\n",
      "Epoch 1155/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0422 - acc: 0.9901 - val_loss: 0.1075 - val_acc: 0.9796\n",
      "Epoch 1156/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0185 - acc: 0.9946 - val_loss: 0.0874 - val_acc: 0.9834\n",
      "Epoch 1157/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0149 - acc: 0.9959 - val_loss: 0.0965 - val_acc: 0.9813\n",
      "Epoch 1158/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0186 - acc: 0.9959 - val_loss: 0.0867 - val_acc: 0.9842\n",
      "Epoch 1159/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0123 - acc: 0.9962 - val_loss: 0.0663 - val_acc: 0.9877\n",
      "Epoch 1160/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0107 - acc: 0.9971 - val_loss: 0.0802 - val_acc: 0.9872\n",
      "Epoch 1161/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0102 - acc: 0.9973 - val_loss: 0.0827 - val_acc: 0.9854\n",
      "Epoch 1162/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0112 - acc: 0.9968 - val_loss: 0.0698 - val_acc: 0.9854\n",
      "Epoch 1163/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0157 - acc: 0.9961 - val_loss: 0.0793 - val_acc: 0.9845\n",
      "Epoch 1164/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0153 - acc: 0.9968 - val_loss: 0.0712 - val_acc: 0.9875\n",
      "Epoch 1165/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0131 - acc: 0.9964 - val_loss: 0.0628 - val_acc: 0.9869\n",
      "Epoch 1166/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0181 - acc: 0.9951 - val_loss: 0.0791 - val_acc: 0.9831\n",
      "Epoch 1167/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0130 - acc: 0.9965 - val_loss: 0.0799 - val_acc: 0.9869\n",
      "Epoch 1168/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0127 - acc: 0.9966 - val_loss: 0.0837 - val_acc: 0.9848\n",
      "Epoch 1169/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0127 - acc: 0.9965 - val_loss: 0.0769 - val_acc: 0.9851\n",
      "Epoch 1170/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0726 - val_acc: 0.9872\n",
      "Epoch 1171/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0091 - acc: 0.9971 - val_loss: 0.0712 - val_acc: 0.9877\n",
      "Epoch 1172/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0122 - acc: 0.9972 - val_loss: 0.0788 - val_acc: 0.9848\n",
      "Epoch 1173/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0102 - acc: 0.9976 - val_loss: 0.0676 - val_acc: 0.9880\n",
      "Epoch 1174/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0104 - acc: 0.9976 - val_loss: 0.0725 - val_acc: 0.9857\n",
      "Epoch 1175/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0120 - acc: 0.9965 - val_loss: 0.0777 - val_acc: 0.9872\n",
      "Epoch 1176/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0084 - acc: 0.9978 - val_loss: 0.0843 - val_acc: 0.9860\n",
      "Epoch 1177/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0756 - val_acc: 0.9869\n",
      "Epoch 1178/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.0824 - val_acc: 0.9877\n",
      "Epoch 1179/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0074 - acc: 0.9972 - val_loss: 0.0885 - val_acc: 0.9866\n",
      "Epoch 1180/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0108 - acc: 0.9972 - val_loss: 0.1158 - val_acc: 0.9825\n",
      "Epoch 1181/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0131 - acc: 0.9964 - val_loss: 0.0921 - val_acc: 0.9834\n",
      "Epoch 1182/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0157 - acc: 0.9961 - val_loss: 0.0754 - val_acc: 0.9860\n",
      "Epoch 1183/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0110 - acc: 0.9970 - val_loss: 0.0815 - val_acc: 0.9877\n",
      "Epoch 1184/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0097 - acc: 0.9973 - val_loss: 0.0858 - val_acc: 0.9869\n",
      "Epoch 1185/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0132 - acc: 0.9964 - val_loss: 0.0962 - val_acc: 0.9828\n",
      "Epoch 1186/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0122 - acc: 0.9969 - val_loss: 0.0729 - val_acc: 0.9883\n",
      "Epoch 1187/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9971 - val_loss: 0.0890 - val_acc: 0.9860\n",
      "Epoch 1188/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0115 - acc: 0.9965 - val_loss: 0.0904 - val_acc: 0.9845\n",
      "Epoch 1189/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0100 - acc: 0.9973 - val_loss: 0.0740 - val_acc: 0.9880\n",
      "Epoch 1190/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0104 - acc: 0.9978 - val_loss: 0.0684 - val_acc: 0.9877\n",
      "Epoch 1191/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0111 - acc: 0.9972 - val_loss: 0.0818 - val_acc: 0.9875\n",
      "Epoch 1192/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0126 - acc: 0.9970 - val_loss: 0.0654 - val_acc: 0.9883\n",
      "Epoch 1193/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0135 - acc: 0.9966 - val_loss: 0.0951 - val_acc: 0.9854\n",
      "Epoch 1194/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0152 - acc: 0.9969 - val_loss: 0.1087 - val_acc: 0.9813\n",
      "Epoch 1195/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0186 - acc: 0.9959 - val_loss: 0.0778 - val_acc: 0.9866\n",
      "Epoch 1196/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0128 - acc: 0.9968 - val_loss: 0.0841 - val_acc: 0.9860\n",
      "Epoch 1197/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0085 - acc: 0.9978 - val_loss: 0.0839 - val_acc: 0.9886\n",
      "Epoch 1198/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0147 - acc: 0.9968 - val_loss: 0.0765 - val_acc: 0.9854\n",
      "Epoch 1199/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0079 - acc: 0.9972 - val_loss: 0.0735 - val_acc: 0.9877\n",
      "Epoch 1200/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.0762 - val_acc: 0.9875\n",
      "Epoch 1201/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0069 - acc: 0.9974 - val_loss: 0.0778 - val_acc: 0.9869\n",
      "Epoch 1202/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0127 - acc: 0.9971 - val_loss: 0.0823 - val_acc: 0.9860\n",
      "Epoch 1203/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0163 - acc: 0.9958 - val_loss: 0.0712 - val_acc: 0.9854\n",
      "Epoch 1204/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0663 - val_acc: 0.9872\n",
      "Epoch 1205/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0130 - acc: 0.9968 - val_loss: 0.0754 - val_acc: 0.9880\n",
      "Epoch 1206/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0074 - acc: 0.9972 - val_loss: 0.0731 - val_acc: 0.9869\n",
      "Epoch 1207/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9976 - val_loss: 0.0713 - val_acc: 0.9883\n",
      "Epoch 1208/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.0783 - val_acc: 0.9886\n",
      "Epoch 1209/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0145 - acc: 0.9964 - val_loss: 0.0806 - val_acc: 0.9880\n",
      "Epoch 1210/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0128 - acc: 0.9971 - val_loss: 0.0738 - val_acc: 0.9880\n",
      "Epoch 1211/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0090 - acc: 0.9980 - val_loss: 0.0600 - val_acc: 0.9869\n",
      "Epoch 1212/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.0637 - val_acc: 0.9886\n",
      "Epoch 1213/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0116 - acc: 0.9976 - val_loss: 0.0554 - val_acc: 0.9892\n",
      "Epoch 1214/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0082 - acc: 0.9976 - val_loss: 0.0567 - val_acc: 0.9907\n",
      "Epoch 1215/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0113 - acc: 0.9972 - val_loss: 0.0686 - val_acc: 0.9869\n",
      "Epoch 1216/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0144 - acc: 0.9963 - val_loss: 0.0695 - val_acc: 0.9866\n",
      "Epoch 1217/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0082 - acc: 0.9976 - val_loss: 0.0909 - val_acc: 0.9854\n",
      "Epoch 1218/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0085 - acc: 0.9978 - val_loss: 0.0861 - val_acc: 0.9845\n",
      "Epoch 1219/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0077 - acc: 0.9978 - val_loss: 0.0704 - val_acc: 0.9845\n",
      "Epoch 1220/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0153 - acc: 0.9965 - val_loss: 0.0658 - val_acc: 0.9866\n",
      "Epoch 1221/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0138 - acc: 0.9968 - val_loss: 0.0886 - val_acc: 0.9837\n",
      "Epoch 1222/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0140 - acc: 0.9968 - val_loss: 0.1011 - val_acc: 0.9825\n",
      "Epoch 1223/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0101 - acc: 0.9981 - val_loss: 0.0840 - val_acc: 0.9860\n",
      "Epoch 1224/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0130 - acc: 0.9968 - val_loss: 0.0926 - val_acc: 0.9819\n",
      "Epoch 1225/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0102 - acc: 0.9973 - val_loss: 0.0801 - val_acc: 0.9851\n",
      "Epoch 1226/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0114 - acc: 0.9968 - val_loss: 0.0694 - val_acc: 0.9851\n",
      "Epoch 1227/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0099 - acc: 0.9971 - val_loss: 0.0814 - val_acc: 0.9860\n",
      "Epoch 1228/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0131 - acc: 0.9972 - val_loss: 0.0830 - val_acc: 0.9863\n",
      "Epoch 1229/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.0684 - val_acc: 0.9857\n",
      "Epoch 1230/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0119 - acc: 0.9970 - val_loss: 0.0541 - val_acc: 0.9886\n",
      "Epoch 1231/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0129 - acc: 0.9963 - val_loss: 0.0648 - val_acc: 0.9869\n",
      "Epoch 1232/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0097 - acc: 0.9972 - val_loss: 0.0580 - val_acc: 0.9877\n",
      "Epoch 1233/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0589 - val_acc: 0.9889\n",
      "Epoch 1234/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0068 - acc: 0.9979 - val_loss: 0.0817 - val_acc: 0.9857\n",
      "Epoch 1235/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0072 - acc: 0.9979 - val_loss: 0.0724 - val_acc: 0.9875\n",
      "Epoch 1236/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.0742 - val_acc: 0.9880\n",
      "Epoch 1237/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0129 - acc: 0.9967 - val_loss: 0.0927 - val_acc: 0.9863\n",
      "Epoch 1238/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0124 - acc: 0.9970 - val_loss: 0.0698 - val_acc: 0.9872\n",
      "Epoch 1239/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0094 - acc: 0.9975 - val_loss: 0.0777 - val_acc: 0.9877\n",
      "Epoch 1240/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0718 - val_acc: 0.9860\n",
      "Epoch 1241/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0109 - acc: 0.9975 - val_loss: 0.0782 - val_acc: 0.9854\n",
      "Epoch 1242/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0109 - acc: 0.9971 - val_loss: 0.0854 - val_acc: 0.9834\n",
      "Epoch 1243/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0595 - val_acc: 0.9886\n",
      "Epoch 1244/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0652 - val_acc: 0.9889\n",
      "Epoch 1245/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0060 - acc: 0.9988 - val_loss: 0.0679 - val_acc: 0.9889\n",
      "Epoch 1246/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.0860 - val_acc: 0.9854\n",
      "Epoch 1247/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0097 - acc: 0.9976 - val_loss: 0.0620 - val_acc: 0.9883\n",
      "Epoch 1248/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0121 - acc: 0.9971 - val_loss: 0.0632 - val_acc: 0.9880\n",
      "Epoch 1249/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0113 - acc: 0.9973 - val_loss: 0.0822 - val_acc: 0.9869\n",
      "Epoch 1250/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0122 - acc: 0.9953 - val_loss: 0.0757 - val_acc: 0.9837\n",
      "Epoch 1251/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0105 - acc: 0.9973 - val_loss: 0.0769 - val_acc: 0.9869\n",
      "Epoch 1252/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0130 - acc: 0.9965 - val_loss: 0.0952 - val_acc: 0.9845\n",
      "Epoch 1253/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0127 - acc: 0.9975 - val_loss: 0.0848 - val_acc: 0.9872\n",
      "Epoch 1254/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0126 - acc: 0.9966 - val_loss: 0.0762 - val_acc: 0.9875\n",
      "Epoch 1255/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0170 - acc: 0.9958 - val_loss: 0.0997 - val_acc: 0.9842\n",
      "Epoch 1256/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0113 - acc: 0.9966 - val_loss: 0.0911 - val_acc: 0.9840\n",
      "Epoch 1257/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0141 - acc: 0.9975 - val_loss: 0.0942 - val_acc: 0.9837\n",
      "Epoch 1258/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0127 - acc: 0.9968 - val_loss: 0.0909 - val_acc: 0.9854\n",
      "Epoch 1259/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0118 - acc: 0.9965 - val_loss: 0.0663 - val_acc: 0.9872\n",
      "Epoch 1260/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0082 - acc: 0.9976 - val_loss: 0.0784 - val_acc: 0.9875\n",
      "Epoch 1261/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0833 - val_acc: 0.9851\n",
      "Epoch 1262/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0091 - acc: 0.9977 - val_loss: 0.1001 - val_acc: 0.9851\n",
      "Epoch 1263/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0827 - val_acc: 0.9857\n",
      "Epoch 1264/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0141 - acc: 0.9966 - val_loss: 0.0762 - val_acc: 0.9866\n",
      "Epoch 1265/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.0821 - val_acc: 0.9851\n",
      "Epoch 1266/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0095 - acc: 0.9976 - val_loss: 0.0618 - val_acc: 0.9901\n",
      "Epoch 1267/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0113 - acc: 0.9971 - val_loss: 0.0800 - val_acc: 0.9869\n",
      "Epoch 1268/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0167 - acc: 0.9963 - val_loss: 0.0844 - val_acc: 0.9834\n",
      "Epoch 1269/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0125 - acc: 0.9971 - val_loss: 0.0910 - val_acc: 0.9848\n",
      "Epoch 1270/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0110 - acc: 0.9969 - val_loss: 0.0801 - val_acc: 0.9872\n",
      "Epoch 1271/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0072 - acc: 0.9979 - val_loss: 0.0928 - val_acc: 0.9837\n",
      "Epoch 1272/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0192 - acc: 0.9960 - val_loss: 0.0894 - val_acc: 0.9851\n",
      "Epoch 1273/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0157 - acc: 0.9963 - val_loss: 0.0801 - val_acc: 0.9854\n",
      "Epoch 1274/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0108 - acc: 0.9972 - val_loss: 0.0660 - val_acc: 0.9875\n",
      "Epoch 1275/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.0660 - val_acc: 0.9863\n",
      "Epoch 1276/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0093 - acc: 0.9978 - val_loss: 0.0948 - val_acc: 0.9842\n",
      "Epoch 1277/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0114 - acc: 0.9972 - val_loss: 0.0865 - val_acc: 0.9866\n",
      "Epoch 1278/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0132 - acc: 0.9966 - val_loss: 0.0720 - val_acc: 0.9851\n",
      "Epoch 1279/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0127 - acc: 0.9968 - val_loss: 0.0844 - val_acc: 0.9863\n",
      "Epoch 1280/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0114 - acc: 0.9971 - val_loss: 0.0719 - val_acc: 0.9886\n",
      "Epoch 1281/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0684 - val_acc: 0.9892\n",
      "Epoch 1282/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0110 - acc: 0.9981 - val_loss: 0.0776 - val_acc: 0.9872\n",
      "Epoch 1283/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.0954 - val_acc: 0.9834\n",
      "Epoch 1284/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0170 - acc: 0.9965 - val_loss: 0.0819 - val_acc: 0.9851\n",
      "Epoch 1285/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0113 - acc: 0.9969 - val_loss: 0.0863 - val_acc: 0.9877\n",
      "Epoch 1286/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0110 - acc: 0.9970 - val_loss: 0.0984 - val_acc: 0.9851\n",
      "Epoch 1287/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.0842 - val_acc: 0.9860\n",
      "Epoch 1288/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0039 - acc: 0.9993 - val_loss: 0.0854 - val_acc: 0.9866\n",
      "Epoch 1289/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0084 - acc: 0.9975 - val_loss: 0.0785 - val_acc: 0.9860\n",
      "Epoch 1290/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.0918 - val_acc: 0.9854\n",
      "Epoch 1291/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0096 - acc: 0.9976 - val_loss: 0.0848 - val_acc: 0.9866\n",
      "Epoch 1292/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0082 - acc: 0.9980 - val_loss: 0.0713 - val_acc: 0.9866\n",
      "Epoch 1293/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0125 - acc: 0.9968 - val_loss: 0.1012 - val_acc: 0.9866\n",
      "Epoch 1294/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0127 - acc: 0.9972 - val_loss: 0.0909 - val_acc: 0.9863\n",
      "Epoch 1295/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0108 - acc: 0.9971 - val_loss: 0.0892 - val_acc: 0.9875\n",
      "Epoch 1296/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0179 - acc: 0.9957 - val_loss: 0.1060 - val_acc: 0.9831\n",
      "Epoch 1297/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0181 - acc: 0.9962 - val_loss: 0.1040 - val_acc: 0.9819\n",
      "Epoch 1298/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0122 - acc: 0.9968 - val_loss: 0.1074 - val_acc: 0.9813\n",
      "Epoch 1299/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0130 - acc: 0.9960 - val_loss: 0.0813 - val_acc: 0.9845\n",
      "Epoch 1300/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0087 - acc: 0.9982 - val_loss: 0.0928 - val_acc: 0.9845\n",
      "Epoch 1301/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0848 - val_acc: 0.9854\n",
      "Epoch 1302/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0092 - acc: 0.9971 - val_loss: 0.0998 - val_acc: 0.9837\n",
      "Epoch 1303/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0150 - acc: 0.9973 - val_loss: 0.0850 - val_acc: 0.9840\n",
      "Epoch 1304/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0081 - acc: 0.9973 - val_loss: 0.0967 - val_acc: 0.9842\n",
      "Epoch 1305/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0120 - acc: 0.9974 - val_loss: 0.0733 - val_acc: 0.9834\n",
      "Epoch 1306/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0812 - val_acc: 0.9840\n",
      "Epoch 1307/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0884 - val_acc: 0.9840\n",
      "Epoch 1308/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0062 - acc: 0.9984 - val_loss: 0.0796 - val_acc: 0.9842\n",
      "Epoch 1309/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0832 - val_acc: 0.9854\n",
      "Epoch 1310/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.1029 - val_acc: 0.9845\n",
      "Epoch 1311/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0108 - acc: 0.9976 - val_loss: 0.0900 - val_acc: 0.9840\n",
      "Epoch 1312/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0882 - val_acc: 0.9837\n",
      "Epoch 1313/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0160 - acc: 0.9968 - val_loss: 0.0967 - val_acc: 0.9842\n",
      "Epoch 1314/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0509 - acc: 0.9918 - val_loss: 0.1149 - val_acc: 0.9790\n",
      "Epoch 1315/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0868 - acc: 0.9834 - val_loss: 0.1106 - val_acc: 0.9752\n",
      "Epoch 1316/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0416 - acc: 0.9906 - val_loss: 0.1100 - val_acc: 0.9799\n",
      "Epoch 1317/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0207 - acc: 0.9943 - val_loss: 0.1177 - val_acc: 0.9787\n",
      "Epoch 1318/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0178 - acc: 0.9957 - val_loss: 0.0884 - val_acc: 0.9822\n",
      "Epoch 1319/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0145 - acc: 0.9961 - val_loss: 0.0851 - val_acc: 0.9840\n",
      "Epoch 1320/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0129 - acc: 0.9966 - val_loss: 0.0898 - val_acc: 0.9831\n",
      "Epoch 1321/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0837 - val_acc: 0.9857\n",
      "Epoch 1322/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0135 - acc: 0.9969 - val_loss: 0.0900 - val_acc: 0.9822\n",
      "Epoch 1323/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0808 - val_acc: 0.9848\n",
      "Epoch 1324/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0069 - acc: 0.9974 - val_loss: 0.0733 - val_acc: 0.9854\n",
      "Epoch 1325/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0042 - acc: 0.9985 - val_loss: 0.0766 - val_acc: 0.9848\n",
      "Epoch 1326/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0079 - acc: 0.9973 - val_loss: 0.0860 - val_acc: 0.9834\n",
      "Epoch 1327/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0112 - acc: 0.9975 - val_loss: 0.0765 - val_acc: 0.9837\n",
      "Epoch 1328/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9977 - val_loss: 0.0801 - val_acc: 0.9848\n",
      "Epoch 1329/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0864 - val_acc: 0.9866\n",
      "Epoch 1330/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0718 - val_acc: 0.9854\n",
      "Epoch 1331/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0109 - acc: 0.9977 - val_loss: 0.0788 - val_acc: 0.9840\n",
      "Epoch 1332/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0077 - acc: 0.9978 - val_loss: 0.0758 - val_acc: 0.9857\n",
      "Epoch 1333/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0056 - acc: 0.9980 - val_loss: 0.0800 - val_acc: 0.9842\n",
      "Epoch 1334/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.0820 - val_acc: 0.9857\n",
      "Epoch 1335/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0936 - val_acc: 0.9845\n",
      "Epoch 1336/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0844 - val_acc: 0.9854\n",
      "Epoch 1337/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0083 - acc: 0.9979 - val_loss: 0.0982 - val_acc: 0.9831\n",
      "Epoch 1338/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0118 - acc: 0.9971 - val_loss: 0.0845 - val_acc: 0.9875\n",
      "Epoch 1339/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0900 - val_acc: 0.9857\n",
      "Epoch 1340/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.0836 - val_acc: 0.9834\n",
      "Epoch 1341/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0897 - val_acc: 0.9831\n",
      "Epoch 1342/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.0943 - val_acc: 0.9842\n",
      "Epoch 1343/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0803 - val_acc: 0.9854\n",
      "Epoch 1344/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0096 - acc: 0.9979 - val_loss: 0.0855 - val_acc: 0.9828\n",
      "Epoch 1345/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0074 - acc: 0.9976 - val_loss: 0.0855 - val_acc: 0.9842\n",
      "Epoch 1346/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0091 - acc: 0.9973 - val_loss: 0.1022 - val_acc: 0.9807\n",
      "Epoch 1347/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0785 - val_acc: 0.9840\n",
      "Epoch 1348/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0077 - acc: 0.9977 - val_loss: 0.0715 - val_acc: 0.9863\n",
      "Epoch 1349/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9976 - val_loss: 0.0753 - val_acc: 0.9837\n",
      "Epoch 1350/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0133 - acc: 0.9971 - val_loss: 0.0780 - val_acc: 0.9848\n",
      "Epoch 1351/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0816 - val_acc: 0.9842\n",
      "Epoch 1352/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0086 - acc: 0.9979 - val_loss: 0.0850 - val_acc: 0.9837\n",
      "Epoch 1353/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0072 - acc: 0.9977 - val_loss: 0.0808 - val_acc: 0.9857\n",
      "Epoch 1354/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0119 - acc: 0.9970 - val_loss: 0.0667 - val_acc: 0.9863\n",
      "Epoch 1355/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0103 - acc: 0.9974 - val_loss: 0.0670 - val_acc: 0.9857\n",
      "Epoch 1356/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0117 - acc: 0.9967 - val_loss: 0.0666 - val_acc: 0.9866\n",
      "Epoch 1357/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0140 - acc: 0.9965 - val_loss: 0.0735 - val_acc: 0.9854\n",
      "Epoch 1358/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0263 - acc: 0.9958 - val_loss: 0.0764 - val_acc: 0.9796\n",
      "Epoch 1359/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0477 - acc: 0.9895 - val_loss: 0.0807 - val_acc: 0.9793\n",
      "Epoch 1360/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0253 - acc: 0.9945 - val_loss: 0.0906 - val_acc: 0.9840\n",
      "Epoch 1361/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0160 - acc: 0.9957 - val_loss: 0.0774 - val_acc: 0.9845\n",
      "Epoch 1362/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0793 - val_acc: 0.9828\n",
      "Epoch 1363/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.0909 - val_acc: 0.9848\n",
      "Epoch 1364/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0042 - acc: 0.9985 - val_loss: 0.0873 - val_acc: 0.9848\n",
      "Epoch 1365/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0130 - acc: 0.9972 - val_loss: 0.0738 - val_acc: 0.9840\n",
      "Epoch 1366/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0105 - acc: 0.9973 - val_loss: 0.0992 - val_acc: 0.9840\n",
      "Epoch 1367/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0154 - acc: 0.9970 - val_loss: 0.0792 - val_acc: 0.9845\n",
      "Epoch 1368/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0615 - val_acc: 0.9857\n",
      "Epoch 1369/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0103 - acc: 0.9975 - val_loss: 0.0730 - val_acc: 0.9842\n",
      "Epoch 1370/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0087 - acc: 0.9977 - val_loss: 0.0662 - val_acc: 0.9857\n",
      "Epoch 1371/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0074 - acc: 0.9984 - val_loss: 0.0550 - val_acc: 0.9860\n",
      "Epoch 1372/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0594 - val_acc: 0.9875\n",
      "Epoch 1373/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0856 - val_acc: 0.9875\n",
      "Epoch 1374/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.0797 - val_acc: 0.9866\n",
      "Epoch 1375/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9976 - val_loss: 0.0805 - val_acc: 0.9857\n",
      "Epoch 1376/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0070 - acc: 0.9979 - val_loss: 0.0710 - val_acc: 0.9872\n",
      "Epoch 1377/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0089 - acc: 0.9976 - val_loss: 0.0784 - val_acc: 0.9857\n",
      "Epoch 1378/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9980 - val_loss: 0.0739 - val_acc: 0.9854\n",
      "Epoch 1379/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0085 - acc: 0.9980 - val_loss: 0.0681 - val_acc: 0.9883\n",
      "Epoch 1380/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0065 - acc: 0.9985 - val_loss: 0.0874 - val_acc: 0.9854\n",
      "Epoch 1381/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0807 - val_acc: 0.9848\n",
      "Epoch 1382/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0094 - acc: 0.9982 - val_loss: 0.0831 - val_acc: 0.9860\n",
      "Epoch 1383/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0057 - acc: 0.9987 - val_loss: 0.0789 - val_acc: 0.9851\n",
      "Epoch 1384/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0750 - val_acc: 0.9877\n",
      "Epoch 1385/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0095 - acc: 0.9980 - val_loss: 0.0989 - val_acc: 0.9854\n",
      "Epoch 1386/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.0903 - val_acc: 0.9877\n",
      "Epoch 1387/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9979 - val_loss: 0.0810 - val_acc: 0.9872\n",
      "Epoch 1388/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.1113 - val_acc: 0.9822\n",
      "Epoch 1389/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0119 - acc: 0.9976 - val_loss: 0.0915 - val_acc: 0.9857\n",
      "Epoch 1390/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.1112 - val_acc: 0.9813\n",
      "Epoch 1391/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.0830 - val_acc: 0.9851\n",
      "Epoch 1392/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0089 - acc: 0.9976 - val_loss: 0.0775 - val_acc: 0.9851\n",
      "Epoch 1393/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0081 - acc: 0.9981 - val_loss: 0.0835 - val_acc: 0.9860\n",
      "Epoch 1394/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0091 - acc: 0.9979 - val_loss: 0.1087 - val_acc: 0.9807\n",
      "Epoch 1395/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0144 - acc: 0.9968 - val_loss: 0.0957 - val_acc: 0.9810\n",
      "Epoch 1396/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0911 - val_acc: 0.9840\n",
      "Epoch 1397/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0112 - acc: 0.9971 - val_loss: 0.0748 - val_acc: 0.9854\n",
      "Epoch 1398/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0086 - acc: 0.9979 - val_loss: 0.0718 - val_acc: 0.9866\n",
      "Epoch 1399/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0135 - acc: 0.9970 - val_loss: 0.0900 - val_acc: 0.9831\n",
      "Epoch 1400/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9978 - val_loss: 0.0889 - val_acc: 0.9834\n",
      "Epoch 1401/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0153 - acc: 0.9972 - val_loss: 0.0919 - val_acc: 0.9816\n",
      "Epoch 1402/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0126 - acc: 0.9968 - val_loss: 0.0969 - val_acc: 0.9834\n",
      "Epoch 1403/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0109 - acc: 0.9973 - val_loss: 0.0868 - val_acc: 0.9845\n",
      "Epoch 1404/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0829 - val_acc: 0.9840\n",
      "Epoch 1405/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0939 - val_acc: 0.9834\n",
      "Epoch 1406/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0106 - acc: 0.9966 - val_loss: 0.0850 - val_acc: 0.9840\n",
      "Epoch 1407/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0753 - val_acc: 0.9854\n",
      "Epoch 1408/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0087 - acc: 0.9975 - val_loss: 0.0801 - val_acc: 0.9840\n",
      "Epoch 1409/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0092 - acc: 0.9979 - val_loss: 0.0812 - val_acc: 0.9840\n",
      "Epoch 1410/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.0746 - val_acc: 0.9866\n",
      "Epoch 1411/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0102 - acc: 0.9971 - val_loss: 0.0648 - val_acc: 0.9877\n",
      "Epoch 1412/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0103 - acc: 0.9974 - val_loss: 0.0716 - val_acc: 0.9863\n",
      "Epoch 1413/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0053 - acc: 0.9979 - val_loss: 0.0797 - val_acc: 0.9854\n",
      "Epoch 1414/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0077 - acc: 0.9985 - val_loss: 0.1002 - val_acc: 0.9831\n",
      "Epoch 1415/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0081 - acc: 0.9972 - val_loss: 0.0855 - val_acc: 0.9863\n",
      "Epoch 1416/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0096 - acc: 0.9973 - val_loss: 0.0660 - val_acc: 0.9869\n",
      "Epoch 1417/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0685 - val_acc: 0.9869\n",
      "Epoch 1418/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9973 - val_loss: 0.0872 - val_acc: 0.9845\n",
      "Epoch 1419/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0866 - val_acc: 0.9863\n",
      "Epoch 1420/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0103 - acc: 0.9975 - val_loss: 0.0928 - val_acc: 0.9837\n",
      "Epoch 1421/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0127 - acc: 0.9971 - val_loss: 0.1009 - val_acc: 0.9845\n",
      "Epoch 1422/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0146 - acc: 0.9962 - val_loss: 0.0730 - val_acc: 0.9840\n",
      "Epoch 1423/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0784 - val_acc: 0.9857\n",
      "Epoch 1424/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0068 - acc: 0.9984 - val_loss: 0.0765 - val_acc: 0.9863\n",
      "Epoch 1425/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0915 - val_acc: 0.9831\n",
      "Epoch 1426/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0131 - acc: 0.9972 - val_loss: 0.0896 - val_acc: 0.9845\n",
      "Epoch 1427/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0745 - val_acc: 0.9851\n",
      "Epoch 1428/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0148 - acc: 0.9968 - val_loss: 0.0839 - val_acc: 0.9845\n",
      "Epoch 1429/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0124 - acc: 0.9979 - val_loss: 0.0807 - val_acc: 0.9845\n",
      "Epoch 1430/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0113 - acc: 0.9977 - val_loss: 0.0635 - val_acc: 0.9869\n",
      "Epoch 1431/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0119 - acc: 0.9981 - val_loss: 0.0698 - val_acc: 0.9866\n",
      "Epoch 1432/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0721 - val_acc: 0.9857\n",
      "Epoch 1433/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9979 - val_loss: 0.0823 - val_acc: 0.9810\n",
      "Epoch 1434/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0077 - acc: 0.9979 - val_loss: 0.0760 - val_acc: 0.9854\n",
      "Epoch 1435/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.0688 - val_acc: 0.9866\n",
      "Epoch 1436/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0039 - acc: 0.9990 - val_loss: 0.0645 - val_acc: 0.9883\n",
      "Epoch 1437/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0068 - acc: 0.9987 - val_loss: 0.0733 - val_acc: 0.9889\n",
      "Epoch 1438/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0686 - acc: 0.9900 - val_loss: 0.1428 - val_acc: 0.9734\n",
      "Epoch 1439/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0774 - acc: 0.9888 - val_loss: 0.0959 - val_acc: 0.9848\n",
      "Epoch 1440/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0374 - acc: 0.9934 - val_loss: 0.0719 - val_acc: 0.9848\n",
      "Epoch 1441/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0298 - acc: 0.9954 - val_loss: 0.0755 - val_acc: 0.9845\n",
      "Epoch 1442/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0168 - acc: 0.9970 - val_loss: 0.0878 - val_acc: 0.9845\n",
      "Epoch 1443/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0205 - acc: 0.9962 - val_loss: 0.0767 - val_acc: 0.9854\n",
      "Epoch 1444/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0157 - acc: 0.9970 - val_loss: 0.0622 - val_acc: 0.9869\n",
      "Epoch 1445/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0364 - acc: 0.9959 - val_loss: 0.0912 - val_acc: 0.9819\n",
      "Epoch 1446/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0388 - acc: 0.9951 - val_loss: 0.0834 - val_acc: 0.9851\n",
      "Epoch 1447/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0388 - acc: 0.9949 - val_loss: 0.0860 - val_acc: 0.9834\n",
      "Epoch 1448/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0243 - acc: 0.9974 - val_loss: 0.0885 - val_acc: 0.9834\n",
      "Epoch 1449/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0398 - acc: 0.9959 - val_loss: 0.0947 - val_acc: 0.9854\n",
      "Epoch 1450/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0388 - acc: 0.9965 - val_loss: 0.0927 - val_acc: 0.9854\n",
      "Epoch 1451/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0266 - acc: 0.9971 - val_loss: 0.0797 - val_acc: 0.9877\n",
      "Epoch 1452/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0267 - acc: 0.9971 - val_loss: 0.0762 - val_acc: 0.9869\n",
      "Epoch 1453/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0173 - acc: 0.9971 - val_loss: 0.0613 - val_acc: 0.9877\n",
      "Epoch 1454/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0228 - acc: 0.9972 - val_loss: 0.0776 - val_acc: 0.9869\n",
      "Epoch 1455/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0250 - acc: 0.9966 - val_loss: 0.0699 - val_acc: 0.9880\n",
      "Epoch 1456/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0146 - acc: 0.9979 - val_loss: 0.0824 - val_acc: 0.9883\n",
      "Epoch 1457/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0181 - acc: 0.9978 - val_loss: 0.0826 - val_acc: 0.9869\n",
      "Epoch 1458/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0470 - acc: 0.9946 - val_loss: 0.0858 - val_acc: 0.9854\n",
      "Epoch 1459/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0476 - acc: 0.9956 - val_loss: 0.1173 - val_acc: 0.9837\n",
      "Epoch 1460/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0411 - acc: 0.9957 - val_loss: 0.0995 - val_acc: 0.9837\n",
      "Epoch 1461/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0434 - acc: 0.9954 - val_loss: 0.0781 - val_acc: 0.9857\n",
      "Epoch 1462/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0211 - acc: 0.9974 - val_loss: 0.0868 - val_acc: 0.9880\n",
      "Epoch 1463/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0278 - acc: 0.9971 - val_loss: 0.0737 - val_acc: 0.9877\n",
      "Epoch 1464/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0206 - acc: 0.9978 - val_loss: 0.0701 - val_acc: 0.9904\n",
      "Epoch 1465/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0243 - acc: 0.9966 - val_loss: 0.0842 - val_acc: 0.9875\n",
      "Epoch 1466/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.0169 - acc: 0.9971 - val_loss: 0.0825 - val_acc: 0.9866\n",
      "Epoch 1467/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.0228 - acc: 0.9971 - val_loss: 0.0748 - val_acc: 0.9875\n",
      "Epoch 1468/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0150 - acc: 0.9983 - val_loss: 0.0798 - val_acc: 0.9863\n",
      "Epoch 1469/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0253 - acc: 0.9969 - val_loss: 0.0723 - val_acc: 0.9880\n",
      "Epoch 1470/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0506 - acc: 0.9906 - val_loss: 0.1758 - val_acc: 0.9510\n",
      "Epoch 1471/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.1164 - acc: 0.9710 - val_loss: 0.1433 - val_acc: 0.9708\n",
      "Epoch 1472/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0572 - acc: 0.9852 - val_loss: 0.1161 - val_acc: 0.9781\n",
      "Epoch 1473/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0504 - acc: 0.9877 - val_loss: 0.1059 - val_acc: 0.9784\n",
      "Epoch 1474/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0315 - acc: 0.9912 - val_loss: 0.0886 - val_acc: 0.9807\n",
      "Epoch 1475/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0255 - acc: 0.9937 - val_loss: 0.0853 - val_acc: 0.9834\n",
      "Epoch 1476/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0200 - acc: 0.9944 - val_loss: 0.0836 - val_acc: 0.9822\n",
      "Epoch 1477/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0202 - acc: 0.9943 - val_loss: 0.0881 - val_acc: 0.9828\n",
      "Epoch 1478/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0186 - acc: 0.9953 - val_loss: 0.0879 - val_acc: 0.9819\n",
      "Epoch 1479/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0227 - acc: 0.9943 - val_loss: 0.0845 - val_acc: 0.9825\n",
      "Epoch 1480/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0131 - acc: 0.9953 - val_loss: 0.0769 - val_acc: 0.9845\n",
      "Epoch 1481/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.0170 - acc: 0.9956 - val_loss: 0.0890 - val_acc: 0.9840\n",
      "Epoch 1482/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0161 - acc: 0.9960 - val_loss: 0.0853 - val_acc: 0.9822\n",
      "Epoch 1483/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0146 - acc: 0.9965 - val_loss: 0.0801 - val_acc: 0.9842\n",
      "Epoch 1484/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0150 - acc: 0.9966 - val_loss: 0.0780 - val_acc: 0.9845\n",
      "Epoch 1485/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0079 - acc: 0.9979 - val_loss: 0.0763 - val_acc: 0.9875\n",
      "Epoch 1486/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0158 - acc: 0.9968 - val_loss: 0.0813 - val_acc: 0.9863\n",
      "Epoch 1487/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0127 - acc: 0.9971 - val_loss: 0.0802 - val_acc: 0.9851\n",
      "Epoch 1488/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0081 - acc: 0.9978 - val_loss: 0.0848 - val_acc: 0.9845\n",
      "Epoch 1489/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0107 - acc: 0.9978 - val_loss: 0.0772 - val_acc: 0.9857\n",
      "Epoch 1490/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9977 - val_loss: 0.0775 - val_acc: 0.9848\n",
      "Epoch 1491/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0100 - acc: 0.9978 - val_loss: 0.0801 - val_acc: 0.9842\n",
      "Epoch 1492/2500\n",
      "53/53 [==============================] - 14s 256ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0787 - val_acc: 0.9863\n",
      "Epoch 1493/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0765 - val_acc: 0.9866\n",
      "Epoch 1494/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0066 - acc: 0.9984 - val_loss: 0.0784 - val_acc: 0.9863\n",
      "Epoch 1495/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0066 - acc: 0.9984 - val_loss: 0.0786 - val_acc: 0.9866\n",
      "Epoch 1496/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0876 - val_acc: 0.9860\n",
      "Epoch 1497/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 0.0925 - val_acc: 0.9857\n",
      "Epoch 1498/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.0969 - val_acc: 0.9848\n",
      "Epoch 1499/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0927 - val_acc: 0.9845\n",
      "Epoch 1500/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0042 - acc: 0.9984 - val_loss: 0.1009 - val_acc: 0.9845\n",
      "Epoch 1501/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0944 - val_acc: 0.9837\n",
      "Epoch 1502/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0056 - acc: 0.9979 - val_loss: 0.0830 - val_acc: 0.9863\n",
      "Epoch 1503/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0823 - val_acc: 0.9863\n",
      "Epoch 1504/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0775 - val_acc: 0.9851\n",
      "Epoch 1505/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0811 - val_acc: 0.9860\n",
      "Epoch 1506/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0082 - acc: 0.9976 - val_loss: 0.0861 - val_acc: 0.9860\n",
      "Epoch 1507/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0086 - acc: 0.9980 - val_loss: 0.0784 - val_acc: 0.9866\n",
      "Epoch 1508/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0087 - acc: 0.9979 - val_loss: 0.0780 - val_acc: 0.9869\n",
      "Epoch 1509/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0031 - acc: 0.9986 - val_loss: 0.0796 - val_acc: 0.9877\n",
      "Epoch 1510/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0074 - acc: 0.9980 - val_loss: 0.0795 - val_acc: 0.9866\n",
      "Epoch 1511/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 0.0788 - val_acc: 0.9877\n",
      "Epoch 1512/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.0857 - val_acc: 0.9854\n",
      "Epoch 1513/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0744 - val_acc: 0.9872\n",
      "Epoch 1514/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 0.0698 - val_acc: 0.9895\n",
      "Epoch 1515/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0902 - val_acc: 0.9851\n",
      "Epoch 1516/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0847 - val_acc: 0.9857\n",
      "Epoch 1517/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0824 - val_acc: 0.9851\n",
      "Epoch 1518/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0069 - acc: 0.9986 - val_loss: 0.0816 - val_acc: 0.9851\n",
      "Epoch 1519/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0072 - acc: 0.9985 - val_loss: 0.0884 - val_acc: 0.9854\n",
      "Epoch 1520/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0086 - acc: 0.9982 - val_loss: 0.0956 - val_acc: 0.9854\n",
      "Epoch 1521/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0081 - acc: 0.9985 - val_loss: 0.0798 - val_acc: 0.9857\n",
      "Epoch 1522/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0751 - val_acc: 0.9869\n",
      "Epoch 1523/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0712 - val_acc: 0.9877\n",
      "Epoch 1524/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0732 - val_acc: 0.9875\n",
      "Epoch 1525/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0740 - val_acc: 0.9880\n",
      "Epoch 1526/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 0.0846 - val_acc: 0.9875\n",
      "Epoch 1527/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9982 - val_loss: 0.0729 - val_acc: 0.9889\n",
      "Epoch 1528/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0071 - acc: 0.9982 - val_loss: 0.0629 - val_acc: 0.9918\n",
      "Epoch 1529/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.0762 - val_acc: 0.9892\n",
      "Epoch 1530/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0060 - acc: 0.9987 - val_loss: 0.0728 - val_acc: 0.9877\n",
      "Epoch 1531/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0753 - val_acc: 0.9880\n",
      "Epoch 1532/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0024 - acc: 0.9990 - val_loss: 0.0816 - val_acc: 0.9880\n",
      "Epoch 1533/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0760 - val_acc: 0.9892\n",
      "Epoch 1534/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 0.0708 - val_acc: 0.9892\n",
      "Epoch 1535/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0080 - acc: 0.9983 - val_loss: 0.0753 - val_acc: 0.9872\n",
      "Epoch 1536/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0644 - val_acc: 0.9886\n",
      "Epoch 1537/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0075 - acc: 0.9984 - val_loss: 0.0623 - val_acc: 0.9886\n",
      "Epoch 1538/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0125 - acc: 0.9976 - val_loss: 0.0709 - val_acc: 0.9886\n",
      "Epoch 1539/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0085 - acc: 0.9984 - val_loss: 0.0798 - val_acc: 0.9857\n",
      "Epoch 1540/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0112 - acc: 0.9979 - val_loss: 0.0846 - val_acc: 0.9883\n",
      "Epoch 1541/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0855 - val_acc: 0.9869\n",
      "Epoch 1542/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.0790 - val_acc: 0.9883\n",
      "Epoch 1543/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0841 - val_acc: 0.9869\n",
      "Epoch 1544/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0071 - acc: 0.9984 - val_loss: 0.0807 - val_acc: 0.9869\n",
      "Epoch 1545/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.0840 - val_acc: 0.9866\n",
      "Epoch 1546/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0059 - acc: 0.9986 - val_loss: 0.0781 - val_acc: 0.9883\n",
      "Epoch 1547/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0712 - val_acc: 0.9901\n",
      "Epoch 1548/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0074 - acc: 0.9985 - val_loss: 0.0686 - val_acc: 0.9904\n",
      "Epoch 1549/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0829 - val_acc: 0.9869\n",
      "Epoch 1550/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0066 - acc: 0.9983 - val_loss: 0.0696 - val_acc: 0.9877\n",
      "Epoch 1551/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0094 - acc: 0.9982 - val_loss: 0.0802 - val_acc: 0.9863\n",
      "Epoch 1552/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.0614 - val_acc: 0.9895\n",
      "Epoch 1553/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0072 - acc: 0.9979 - val_loss: 0.0646 - val_acc: 0.9901\n",
      "Epoch 1554/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0618 - val_acc: 0.9901\n",
      "Epoch 1555/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.0723 - val_acc: 0.9892\n",
      "Epoch 1556/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0747 - val_acc: 0.9875\n",
      "Epoch 1557/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.0728 - val_acc: 0.9883\n",
      "Epoch 1558/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0774 - val_acc: 0.9889\n",
      "Epoch 1559/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.0751 - val_acc: 0.9886\n",
      "Epoch 1560/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0870 - val_acc: 0.9875\n",
      "Epoch 1561/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.0865 - val_acc: 0.9875\n",
      "Epoch 1562/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.0757 - val_acc: 0.9889\n",
      "Epoch 1563/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0738 - acc: 0.9857 - val_loss: 0.1131 - val_acc: 0.9796\n",
      "Epoch 1564/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0260 - acc: 0.9946 - val_loss: 0.0772 - val_acc: 0.9875\n",
      "Epoch 1565/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0229 - acc: 0.9948 - val_loss: 0.0900 - val_acc: 0.9834\n",
      "Epoch 1566/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0156 - acc: 0.9963 - val_loss: 0.1071 - val_acc: 0.9804\n",
      "Epoch 1567/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0163 - acc: 0.9957 - val_loss: 0.0962 - val_acc: 0.9840\n",
      "Epoch 1568/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0098 - acc: 0.9979 - val_loss: 0.0774 - val_acc: 0.9869\n",
      "Epoch 1569/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0093 - acc: 0.9980 - val_loss: 0.0786 - val_acc: 0.9863\n",
      "Epoch 1570/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0080 - acc: 0.9977 - val_loss: 0.0881 - val_acc: 0.9869\n",
      "Epoch 1571/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0075 - acc: 0.9976 - val_loss: 0.0767 - val_acc: 0.9869\n",
      "Epoch 1572/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0080 - acc: 0.9976 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 1573/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0081 - acc: 0.9981 - val_loss: 0.0634 - val_acc: 0.9889\n",
      "Epoch 1574/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0120 - acc: 0.9971 - val_loss: 0.0748 - val_acc: 0.9886\n",
      "Epoch 1575/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0080 - acc: 0.9977 - val_loss: 0.0702 - val_acc: 0.9901\n",
      "Epoch 1576/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0092 - acc: 0.9975 - val_loss: 0.0814 - val_acc: 0.9872\n",
      "Epoch 1577/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0079 - acc: 0.9978 - val_loss: 0.0748 - val_acc: 0.9872\n",
      "Epoch 1578/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 0.0767 - val_acc: 0.9872\n",
      "Epoch 1579/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0767 - val_acc: 0.9869\n",
      "Epoch 1580/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0817 - val_acc: 0.9875\n",
      "Epoch 1581/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0099 - acc: 0.9977 - val_loss: 0.0764 - val_acc: 0.9880\n",
      "Epoch 1582/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.0659 - val_acc: 0.9895\n",
      "Epoch 1583/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0638 - val_acc: 0.9889\n",
      "Epoch 1584/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0708 - val_acc: 0.9883\n",
      "Epoch 1585/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.0665 - val_acc: 0.9889\n",
      "Epoch 1586/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0704 - val_acc: 0.9889\n",
      "Epoch 1587/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0690 - val_acc: 0.9910\n",
      "Epoch 1588/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0090 - acc: 0.9980 - val_loss: 0.0749 - val_acc: 0.9907\n",
      "Epoch 1589/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.0797 - val_acc: 0.9863\n",
      "Epoch 1590/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0809 - val_acc: 0.9866\n",
      "Epoch 1591/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0119 - acc: 0.9973 - val_loss: 0.0927 - val_acc: 0.9866\n",
      "Epoch 1592/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0122 - acc: 0.9975 - val_loss: 0.0838 - val_acc: 0.9889\n",
      "Epoch 1593/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.0793 - val_acc: 0.9883\n",
      "Epoch 1594/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0047 - acc: 0.9989 - val_loss: 0.0791 - val_acc: 0.9875\n",
      "Epoch 1595/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0051 - acc: 0.9987 - val_loss: 0.0790 - val_acc: 0.9883\n",
      "Epoch 1596/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0868 - val_acc: 0.9877\n",
      "Epoch 1597/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0806 - val_acc: 0.9883\n",
      "Epoch 1598/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0767 - val_acc: 0.9866\n",
      "Epoch 1599/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0072 - acc: 0.9982 - val_loss: 0.0787 - val_acc: 0.9869\n",
      "Epoch 1600/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0682 - val_acc: 0.9892\n",
      "Epoch 1601/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0050 - acc: 0.9991 - val_loss: 0.0610 - val_acc: 0.9898\n",
      "Epoch 1602/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0646 - val_acc: 0.9898\n",
      "Epoch 1603/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0754 - val_acc: 0.9875\n",
      "Epoch 1604/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0735 - val_acc: 0.9904\n",
      "Epoch 1605/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.0913 - val_acc: 0.9872\n",
      "Epoch 1606/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0144 - acc: 0.9970 - val_loss: 0.0985 - val_acc: 0.9834\n",
      "Epoch 1607/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0134 - acc: 0.9974 - val_loss: 0.0897 - val_acc: 0.9845\n",
      "Epoch 1608/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0191 - acc: 0.9963 - val_loss: 0.1186 - val_acc: 0.9825\n",
      "Epoch 1609/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0278 - acc: 0.9946 - val_loss: 0.0970 - val_acc: 0.9851\n",
      "Epoch 1610/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0138 - acc: 0.9970 - val_loss: 0.0993 - val_acc: 0.9866\n",
      "Epoch 1611/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0990 - val_acc: 0.9831\n",
      "Epoch 1612/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0091 - acc: 0.9974 - val_loss: 0.1057 - val_acc: 0.9854\n",
      "Epoch 1613/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0948 - val_acc: 0.9845\n",
      "Epoch 1614/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0090 - acc: 0.9977 - val_loss: 0.0847 - val_acc: 0.9863\n",
      "Epoch 1615/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.0741 - val_acc: 0.9877\n",
      "Epoch 1616/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0086 - acc: 0.9978 - val_loss: 0.0892 - val_acc: 0.9863\n",
      "Epoch 1617/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0057 - acc: 0.9986 - val_loss: 0.1030 - val_acc: 0.9860\n",
      "Epoch 1618/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0058 - acc: 0.9985 - val_loss: 0.0907 - val_acc: 0.9877\n",
      "Epoch 1619/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0133 - acc: 0.9971 - val_loss: 0.0900 - val_acc: 0.9854\n",
      "Epoch 1620/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0105 - acc: 0.9976 - val_loss: 0.0766 - val_acc: 0.9875\n",
      "Epoch 1621/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0217 - acc: 0.9957 - val_loss: 0.0928 - val_acc: 0.9854\n",
      "Epoch 1622/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0175 - acc: 0.9961 - val_loss: 0.0849 - val_acc: 0.9866\n",
      "Epoch 1623/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0101 - acc: 0.9974 - val_loss: 0.0865 - val_acc: 0.9880\n",
      "Epoch 1624/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0122 - acc: 0.9972 - val_loss: 0.0953 - val_acc: 0.9834\n",
      "Epoch 1625/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0244 - acc: 0.9940 - val_loss: 0.0871 - val_acc: 0.9863\n",
      "Epoch 1626/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0152 - acc: 0.9965 - val_loss: 0.0765 - val_acc: 0.9863\n",
      "Epoch 1627/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0103 - acc: 0.9976 - val_loss: 0.0982 - val_acc: 0.9854\n",
      "Epoch 1628/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0106 - acc: 0.9982 - val_loss: 0.0902 - val_acc: 0.9866\n",
      "Epoch 1629/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0089 - acc: 0.9981 - val_loss: 0.0937 - val_acc: 0.9863\n",
      "Epoch 1630/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0092 - acc: 0.9981 - val_loss: 0.0945 - val_acc: 0.9857\n",
      "Epoch 1631/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0082 - acc: 0.9980 - val_loss: 0.0776 - val_acc: 0.9877\n",
      "Epoch 1632/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0090 - acc: 0.9977 - val_loss: 0.0825 - val_acc: 0.9866\n",
      "Epoch 1633/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0056 - acc: 0.9979 - val_loss: 0.0844 - val_acc: 0.9898\n",
      "Epoch 1634/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0129 - acc: 0.9976 - val_loss: 0.0761 - val_acc: 0.9895\n",
      "Epoch 1635/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0135 - acc: 0.9972 - val_loss: 0.1060 - val_acc: 0.9854\n",
      "Epoch 1636/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0082 - acc: 0.9976 - val_loss: 0.0893 - val_acc: 0.9875\n",
      "Epoch 1637/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0106 - acc: 0.9976 - val_loss: 0.1006 - val_acc: 0.9860\n",
      "Epoch 1638/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0095 - acc: 0.9984 - val_loss: 0.0941 - val_acc: 0.9848\n",
      "Epoch 1639/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.0844 - val_acc: 0.9860\n",
      "Epoch 1640/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9973 - val_loss: 0.1041 - val_acc: 0.9869\n",
      "Epoch 1641/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0083 - acc: 0.9984 - val_loss: 0.0789 - val_acc: 0.9872\n",
      "Epoch 1642/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0090 - acc: 0.9977 - val_loss: 0.0849 - val_acc: 0.9857\n",
      "Epoch 1643/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0772 - val_acc: 0.9877\n",
      "Epoch 1644/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0707 - val_acc: 0.9869\n",
      "Epoch 1645/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0865 - val_acc: 0.9875\n",
      "Epoch 1646/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0041 - acc: 0.9985 - val_loss: 0.0757 - val_acc: 0.9898\n",
      "Epoch 1647/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0103 - acc: 0.9977 - val_loss: 0.0718 - val_acc: 0.9872\n",
      "Epoch 1648/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0133 - acc: 0.9968 - val_loss: 0.0837 - val_acc: 0.9875\n",
      "Epoch 1649/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0169 - acc: 0.9964 - val_loss: 0.0928 - val_acc: 0.9857\n",
      "Epoch 1650/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0104 - acc: 0.9975 - val_loss: 0.0756 - val_acc: 0.9895\n",
      "Epoch 1651/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0134 - acc: 0.9971 - val_loss: 0.0933 - val_acc: 0.9863\n",
      "Epoch 1652/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0113 - acc: 0.9978 - val_loss: 0.0751 - val_acc: 0.9877\n",
      "Epoch 1653/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0176 - acc: 0.9960 - val_loss: 0.0742 - val_acc: 0.9875\n",
      "Epoch 1654/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0680 - val_acc: 0.9895\n",
      "Epoch 1655/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 0.0544 - val_acc: 0.9901\n",
      "Epoch 1656/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0087 - acc: 0.9981 - val_loss: 0.0622 - val_acc: 0.9877\n",
      "Epoch 1657/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0605 - val_acc: 0.9898\n",
      "Epoch 1658/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0703 - val_acc: 0.9889\n",
      "Epoch 1659/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0076 - acc: 0.9980 - val_loss: 0.0744 - val_acc: 0.9892\n",
      "Epoch 1660/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0732 - val_acc: 0.9886\n",
      "Epoch 1661/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0886 - val_acc: 0.9845\n",
      "Epoch 1662/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.0731 - val_acc: 0.9883\n",
      "Epoch 1663/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0627 - val_acc: 0.9892\n",
      "Epoch 1664/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0108 - acc: 0.9977 - val_loss: 0.0651 - val_acc: 0.9860\n",
      "Epoch 1665/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0811 - val_acc: 0.9877\n",
      "Epoch 1666/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9979 - val_loss: 0.0782 - val_acc: 0.9883\n",
      "Epoch 1667/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0071 - acc: 0.9982 - val_loss: 0.0908 - val_acc: 0.9869\n",
      "Epoch 1668/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0134 - acc: 0.9971 - val_loss: 0.0856 - val_acc: 0.9877\n",
      "Epoch 1669/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0207 - acc: 0.9966 - val_loss: 0.1041 - val_acc: 0.9828\n",
      "Epoch 1670/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0200 - acc: 0.9959 - val_loss: 0.0910 - val_acc: 0.9860\n",
      "Epoch 1671/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0127 - acc: 0.9973 - val_loss: 0.0811 - val_acc: 0.9857\n",
      "Epoch 1672/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0113 - acc: 0.9975 - val_loss: 0.0915 - val_acc: 0.9857\n",
      "Epoch 1673/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0928 - val_acc: 0.9857\n",
      "Epoch 1674/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0080 - acc: 0.9979 - val_loss: 0.0824 - val_acc: 0.9837\n",
      "Epoch 1675/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0803 - val_acc: 0.9863\n",
      "Epoch 1676/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0939 - val_acc: 0.9866\n",
      "Epoch 1677/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0831 - val_acc: 0.9877\n",
      "Epoch 1678/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0835 - val_acc: 0.9877\n",
      "Epoch 1679/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0877 - val_acc: 0.9883\n",
      "Epoch 1680/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0759 - val_acc: 0.9892\n",
      "Epoch 1681/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0684 - val_acc: 0.9886\n",
      "Epoch 1682/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0106 - acc: 0.9973 - val_loss: 0.0762 - val_acc: 0.9869\n",
      "Epoch 1683/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0881 - val_acc: 0.9880\n",
      "Epoch 1684/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0162 - acc: 0.9965 - val_loss: 0.0900 - val_acc: 0.9851\n",
      "Epoch 1685/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0117 - acc: 0.9970 - val_loss: 0.0819 - val_acc: 0.9877\n",
      "Epoch 1686/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0754 - val_acc: 0.9895\n",
      "Epoch 1687/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0094 - acc: 0.9971 - val_loss: 0.0686 - val_acc: 0.9886\n",
      "Epoch 1688/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0163 - acc: 0.9969 - val_loss: 0.0750 - val_acc: 0.9863\n",
      "Epoch 1689/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0136 - acc: 0.9970 - val_loss: 0.0697 - val_acc: 0.9877\n",
      "Epoch 1690/2500\n",
      "53/53 [==============================] - 14s 263ms/step - loss: 0.0134 - acc: 0.9966 - val_loss: 0.0751 - val_acc: 0.9875\n",
      "Epoch 1691/2500\n",
      "53/53 [==============================] - 14s 266ms/step - loss: 0.0118 - acc: 0.9965 - val_loss: 0.0698 - val_acc: 0.9892\n",
      "Epoch 1692/2500\n",
      "53/53 [==============================] - 14s 267ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0830 - val_acc: 0.9863\n",
      "Epoch 1693/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0821 - val_acc: 0.9863\n",
      "Epoch 1694/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0102 - acc: 0.9979 - val_loss: 0.0922 - val_acc: 0.9851\n",
      "Epoch 1695/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0109 - acc: 0.9975 - val_loss: 0.0787 - val_acc: 0.9877\n",
      "Epoch 1696/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0101 - acc: 0.9976 - val_loss: 0.0919 - val_acc: 0.9869\n",
      "Epoch 1697/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0116 - acc: 0.9965 - val_loss: 0.0774 - val_acc: 0.9875\n",
      "Epoch 1698/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0114 - acc: 0.9971 - val_loss: 0.0678 - val_acc: 0.9886\n",
      "Epoch 1699/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0114 - acc: 0.9973 - val_loss: 0.0926 - val_acc: 0.9869\n",
      "Epoch 1700/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0108 - acc: 0.9976 - val_loss: 0.0730 - val_acc: 0.9892\n",
      "Epoch 1701/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0105 - acc: 0.9973 - val_loss: 0.0699 - val_acc: 0.9877\n",
      "Epoch 1702/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0099 - acc: 0.9975 - val_loss: 0.0739 - val_acc: 0.9889\n",
      "Epoch 1703/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0108 - acc: 0.9977 - val_loss: 0.0707 - val_acc: 0.9886\n",
      "Epoch 1704/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0091 - acc: 0.9979 - val_loss: 0.0701 - val_acc: 0.9892\n",
      "Epoch 1705/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0078 - acc: 0.9979 - val_loss: 0.0811 - val_acc: 0.9877\n",
      "Epoch 1706/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0775 - val_acc: 0.9889\n",
      "Epoch 1707/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0055 - acc: 0.9980 - val_loss: 0.0735 - val_acc: 0.9880\n",
      "Epoch 1708/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.0729 - val_acc: 0.9883\n",
      "Epoch 1709/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0107 - acc: 0.9975 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 1710/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0626 - val_acc: 0.9895\n",
      "Epoch 1711/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0709 - val_acc: 0.9892\n",
      "Epoch 1712/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0082 - acc: 0.9976 - val_loss: 0.0882 - val_acc: 0.9863\n",
      "Epoch 1713/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0117 - acc: 0.9970 - val_loss: 0.0720 - val_acc: 0.9872\n",
      "Epoch 1714/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0085 - acc: 0.9979 - val_loss: 0.0737 - val_acc: 0.9869\n",
      "Epoch 1715/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0087 - acc: 0.9979 - val_loss: 0.0843 - val_acc: 0.9877\n",
      "Epoch 1716/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0092 - acc: 0.9977 - val_loss: 0.0945 - val_acc: 0.9866\n",
      "Epoch 1717/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0108 - acc: 0.9976 - val_loss: 0.0817 - val_acc: 0.9869\n",
      "Epoch 1718/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0733 - val_acc: 0.9883\n",
      "Epoch 1719/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0131 - acc: 0.9974 - val_loss: 0.0805 - val_acc: 0.9875\n",
      "Epoch 1720/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0081 - acc: 0.9977 - val_loss: 0.0891 - val_acc: 0.9860\n",
      "Epoch 1721/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0056 - acc: 0.9980 - val_loss: 0.0799 - val_acc: 0.9895\n",
      "Epoch 1722/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0071 - acc: 0.9982 - val_loss: 0.0830 - val_acc: 0.9880\n",
      "Epoch 1723/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0144 - acc: 0.9969 - val_loss: 0.0672 - val_acc: 0.9886\n",
      "Epoch 1724/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.0723 - val_acc: 0.9880\n",
      "Epoch 1725/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0054 - acc: 0.9982 - val_loss: 0.0825 - val_acc: 0.9875\n",
      "Epoch 1726/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0084 - acc: 0.9983 - val_loss: 0.0816 - val_acc: 0.9851\n",
      "Epoch 1727/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0910 - val_acc: 0.9872\n",
      "Epoch 1728/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.0830 - val_acc: 0.9886\n",
      "Epoch 1729/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0096 - acc: 0.9976 - val_loss: 0.0971 - val_acc: 0.9854\n",
      "Epoch 1730/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0102 - acc: 0.9981 - val_loss: 0.1001 - val_acc: 0.9851\n",
      "Epoch 1731/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0154 - acc: 0.9960 - val_loss: 0.0791 - val_acc: 0.9872\n",
      "Epoch 1732/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0136 - acc: 0.9968 - val_loss: 0.0711 - val_acc: 0.9866\n",
      "Epoch 1733/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0066 - acc: 0.9984 - val_loss: 0.0805 - val_acc: 0.9883\n",
      "Epoch 1734/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0744 - val_acc: 0.9872\n",
      "Epoch 1735/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.0929 - val_acc: 0.9863\n",
      "Epoch 1736/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0245 - acc: 0.9964 - val_loss: 0.0932 - val_acc: 0.9848\n",
      "Epoch 1737/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0138 - acc: 0.9970 - val_loss: 0.0794 - val_acc: 0.9869\n",
      "Epoch 1738/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0045 - acc: 0.9989 - val_loss: 0.0988 - val_acc: 0.9869\n",
      "Epoch 1739/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0086 - acc: 0.9982 - val_loss: 0.0936 - val_acc: 0.9848\n",
      "Epoch 1740/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0084 - acc: 0.9982 - val_loss: 0.0911 - val_acc: 0.9869\n",
      "Epoch 1741/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.0789 - val_acc: 0.9889\n",
      "Epoch 1742/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0829 - val_acc: 0.9886\n",
      "Epoch 1743/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0814 - val_acc: 0.9886\n",
      "Epoch 1744/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0106 - acc: 0.9973 - val_loss: 0.1059 - val_acc: 0.9834\n",
      "Epoch 1745/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0119 - acc: 0.9971 - val_loss: 0.1048 - val_acc: 0.9848\n",
      "Epoch 1746/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0133 - acc: 0.9971 - val_loss: 0.1036 - val_acc: 0.9845\n",
      "Epoch 1747/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0128 - acc: 0.9968 - val_loss: 0.0707 - val_acc: 0.9866\n",
      "Epoch 1748/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0801 - val_acc: 0.9857\n",
      "Epoch 1749/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0764 - val_acc: 0.9895\n",
      "Epoch 1750/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0066 - acc: 0.9985 - val_loss: 0.0811 - val_acc: 0.9898\n",
      "Epoch 1751/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0135 - acc: 0.9971 - val_loss: 0.0680 - val_acc: 0.9883\n",
      "Epoch 1752/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0100 - acc: 0.9976 - val_loss: 0.0730 - val_acc: 0.9860\n",
      "Epoch 1753/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0135 - acc: 0.9971 - val_loss: 0.0766 - val_acc: 0.9866\n",
      "Epoch 1754/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0123 - acc: 0.9973 - val_loss: 0.0878 - val_acc: 0.9866\n",
      "Epoch 1755/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0136 - acc: 0.9971 - val_loss: 0.0653 - val_acc: 0.9904\n",
      "Epoch 1756/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0739 - val_acc: 0.9892\n",
      "Epoch 1757/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0080 - acc: 0.9978 - val_loss: 0.0781 - val_acc: 0.9872\n",
      "Epoch 1758/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0112 - acc: 0.9973 - val_loss: 0.0813 - val_acc: 0.9854\n",
      "Epoch 1759/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0715 - val_acc: 0.9880\n",
      "Epoch 1760/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0095 - acc: 0.9976 - val_loss: 0.0684 - val_acc: 0.9886\n",
      "Epoch 1761/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0098 - acc: 0.9977 - val_loss: 0.0794 - val_acc: 0.9875\n",
      "Epoch 1762/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0085 - acc: 0.9982 - val_loss: 0.0749 - val_acc: 0.9869\n",
      "Epoch 1763/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0786 - val_acc: 0.9866\n",
      "Epoch 1764/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0749 - val_acc: 0.9886\n",
      "Epoch 1765/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 0.0750 - val_acc: 0.9883\n",
      "Epoch 1766/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.0630 - val_acc: 0.9886\n",
      "Epoch 1767/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0840 - val_acc: 0.9892\n",
      "Epoch 1768/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.0804 - val_acc: 0.9880\n",
      "Epoch 1769/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0101 - acc: 0.9975 - val_loss: 0.0892 - val_acc: 0.9863\n",
      "Epoch 1770/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0858 - val_acc: 0.9875\n",
      "Epoch 1771/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0919 - val_acc: 0.9866\n",
      "Epoch 1772/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0066 - acc: 0.9985 - val_loss: 0.0757 - val_acc: 0.9872\n",
      "Epoch 1773/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0082 - acc: 0.9983 - val_loss: 0.0816 - val_acc: 0.9845\n",
      "Epoch 1774/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0105 - acc: 0.9978 - val_loss: 0.0791 - val_acc: 0.9842\n",
      "Epoch 1775/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0047 - acc: 0.9990 - val_loss: 0.0791 - val_acc: 0.9851\n",
      "Epoch 1776/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0125 - acc: 0.9977 - val_loss: 0.0871 - val_acc: 0.9854\n",
      "Epoch 1777/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0092 - acc: 0.9980 - val_loss: 0.0797 - val_acc: 0.9863\n",
      "Epoch 1778/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0071 - acc: 0.9984 - val_loss: 0.0773 - val_acc: 0.9863\n",
      "Epoch 1779/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 0.0701 - val_acc: 0.9875\n",
      "Epoch 1780/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0693 - val_acc: 0.9889\n",
      "Epoch 1781/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0135 - acc: 0.9972 - val_loss: 0.0920 - val_acc: 0.9842\n",
      "Epoch 1782/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0118 - acc: 0.9979 - val_loss: 0.0822 - val_acc: 0.9875\n",
      "Epoch 1783/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.0746 - val_acc: 0.9869\n",
      "Epoch 1784/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0104 - acc: 0.9981 - val_loss: 0.0639 - val_acc: 0.9898\n",
      "Epoch 1785/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0092 - acc: 0.9978 - val_loss: 0.0695 - val_acc: 0.9869\n",
      "Epoch 1786/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0753 - val_acc: 0.9869\n",
      "Epoch 1787/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0112 - acc: 0.9975 - val_loss: 0.0647 - val_acc: 0.9854\n",
      "Epoch 1788/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0651 - val_acc: 0.9857\n",
      "Epoch 1789/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.0760 - val_acc: 0.9880\n",
      "Epoch 1790/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.0893 - val_acc: 0.9851\n",
      "Epoch 1791/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0098 - acc: 0.9979 - val_loss: 0.0833 - val_acc: 0.9857\n",
      "Epoch 1792/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0104 - acc: 0.9977 - val_loss: 0.0773 - val_acc: 0.9872\n",
      "Epoch 1793/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0070 - acc: 0.9984 - val_loss: 0.0842 - val_acc: 0.9880\n",
      "Epoch 1794/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0098 - acc: 0.9976 - val_loss: 0.0870 - val_acc: 0.9883\n",
      "Epoch 1795/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0152 - acc: 0.9968 - val_loss: 0.1005 - val_acc: 0.9842\n",
      "Epoch 1796/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0157 - acc: 0.9970 - val_loss: 0.0920 - val_acc: 0.9857\n",
      "Epoch 1797/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0119 - acc: 0.9968 - val_loss: 0.1029 - val_acc: 0.9851\n",
      "Epoch 1798/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0111 - acc: 0.9972 - val_loss: 0.0737 - val_acc: 0.9866\n",
      "Epoch 1799/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0902 - val_acc: 0.9851\n",
      "Epoch 1800/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0194 - acc: 0.9968 - val_loss: 0.0835 - val_acc: 0.9880\n",
      "Epoch 1801/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0082 - acc: 0.9976 - val_loss: 0.0747 - val_acc: 0.9869\n",
      "Epoch 1802/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.0853 - val_acc: 0.9869\n",
      "Epoch 1803/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0088 - acc: 0.9976 - val_loss: 0.0898 - val_acc: 0.9851\n",
      "Epoch 1804/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.0854 - val_acc: 0.9866\n",
      "Epoch 1805/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0846 - val_acc: 0.9869\n",
      "Epoch 1806/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0877 - val_acc: 0.9877\n",
      "Epoch 1807/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0766 - val_acc: 0.9883\n",
      "Epoch 1808/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0049 - acc: 0.9990 - val_loss: 0.0791 - val_acc: 0.9866\n",
      "Epoch 1809/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0083 - acc: 0.9982 - val_loss: 0.0923 - val_acc: 0.9869\n",
      "Epoch 1810/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0080 - acc: 0.9980 - val_loss: 0.1252 - val_acc: 0.9857\n",
      "Epoch 1811/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0133 - acc: 0.9970 - val_loss: 0.0943 - val_acc: 0.9851\n",
      "Epoch 1812/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0091 - acc: 0.9977 - val_loss: 0.0894 - val_acc: 0.9860\n",
      "Epoch 1813/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.0770 - val_acc: 0.9866\n",
      "Epoch 1814/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0868 - val_acc: 0.9875\n",
      "Epoch 1815/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0096 - acc: 0.9977 - val_loss: 0.0969 - val_acc: 0.9848\n",
      "Epoch 1816/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0152 - acc: 0.9973 - val_loss: 0.0886 - val_acc: 0.9872\n",
      "Epoch 1817/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0078 - acc: 0.9981 - val_loss: 0.0817 - val_acc: 0.9869\n",
      "Epoch 1818/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0922 - val_acc: 0.9857\n",
      "Epoch 1819/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0782 - val_acc: 0.9883\n",
      "Epoch 1820/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0078 - acc: 0.9981 - val_loss: 0.0785 - val_acc: 0.9907\n",
      "Epoch 1821/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0108 - acc: 0.9977 - val_loss: 0.0743 - val_acc: 0.9889\n",
      "Epoch 1822/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0094 - acc: 0.9977 - val_loss: 0.0679 - val_acc: 0.9880\n",
      "Epoch 1823/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0052 - acc: 0.9990 - val_loss: 0.0780 - val_acc: 0.9877\n",
      "Epoch 1824/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0065 - acc: 0.9986 - val_loss: 0.0921 - val_acc: 0.9866\n",
      "Epoch 1825/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0130 - acc: 0.9982 - val_loss: 0.1006 - val_acc: 0.9848\n",
      "Epoch 1826/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0106 - acc: 0.9978 - val_loss: 0.1000 - val_acc: 0.9860\n",
      "Epoch 1827/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0093 - acc: 0.9980 - val_loss: 0.0917 - val_acc: 0.9875\n",
      "Epoch 1828/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0111 - acc: 0.9980 - val_loss: 0.0849 - val_acc: 0.9860\n",
      "Epoch 1829/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0103 - acc: 0.9976 - val_loss: 0.1026 - val_acc: 0.9837\n",
      "Epoch 1830/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0125 - acc: 0.9977 - val_loss: 0.0838 - val_acc: 0.9869\n",
      "Epoch 1831/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0158 - acc: 0.9967 - val_loss: 0.0864 - val_acc: 0.9877\n",
      "Epoch 1832/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0972 - val_acc: 0.9886\n",
      "Epoch 1833/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.0943 - val_acc: 0.9875\n",
      "Epoch 1834/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0185 - acc: 0.9966 - val_loss: 0.0855 - val_acc: 0.9848\n",
      "Epoch 1835/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0116 - acc: 0.9975 - val_loss: 0.0760 - val_acc: 0.9872\n",
      "Epoch 1836/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0063 - acc: 0.9985 - val_loss: 0.0811 - val_acc: 0.9863\n",
      "Epoch 1837/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0092 - acc: 0.9978 - val_loss: 0.0778 - val_acc: 0.9869\n",
      "Epoch 1838/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0135 - acc: 0.9974 - val_loss: 0.0899 - val_acc: 0.9837\n",
      "Epoch 1839/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0105 - acc: 0.9982 - val_loss: 0.0654 - val_acc: 0.9883\n",
      "Epoch 1840/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9975 - val_loss: 0.0686 - val_acc: 0.9863\n",
      "Epoch 1841/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 0.0725 - val_acc: 0.9886\n",
      "Epoch 1842/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0122 - acc: 0.9973 - val_loss: 0.0742 - val_acc: 0.9872\n",
      "Epoch 1843/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0083 - acc: 0.9973 - val_loss: 0.0806 - val_acc: 0.9869\n",
      "Epoch 1844/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 268ms/step - loss: 0.0072 - acc: 0.9976 - val_loss: 0.0847 - val_acc: 0.9869\n",
      "Epoch 1845/2500\n",
      "53/53 [==============================] - 14s 264ms/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0998 - val_acc: 0.9860\n",
      "Epoch 1846/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.1069 - val_acc: 0.9869\n",
      "Epoch 1847/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0100 - acc: 0.9975 - val_loss: 0.0939 - val_acc: 0.9869\n",
      "Epoch 1848/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0929 - val_acc: 0.9877\n",
      "Epoch 1849/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9982 - val_loss: 0.1075 - val_acc: 0.9863\n",
      "Epoch 1850/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9976 - val_loss: 0.0945 - val_acc: 0.9875\n",
      "Epoch 1851/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0160 - acc: 0.9968 - val_loss: 0.0852 - val_acc: 0.9845\n",
      "Epoch 1852/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0114 - acc: 0.9976 - val_loss: 0.0817 - val_acc: 0.9869\n",
      "Epoch 1853/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0087 - acc: 0.9979 - val_loss: 0.0992 - val_acc: 0.9834\n",
      "Epoch 1854/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0099 - acc: 0.9976 - val_loss: 0.0998 - val_acc: 0.9860\n",
      "Epoch 1855/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.1059 - val_acc: 0.9857\n",
      "Epoch 1856/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0107 - acc: 0.9975 - val_loss: 0.1170 - val_acc: 0.9842\n",
      "Epoch 1857/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0130 - acc: 0.9974 - val_loss: 0.0733 - val_acc: 0.9875\n",
      "Epoch 1858/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0945 - val_acc: 0.9872\n",
      "Epoch 1859/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0078 - acc: 0.9982 - val_loss: 0.1003 - val_acc: 0.9872\n",
      "Epoch 1860/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.1050 - val_acc: 0.9869\n",
      "Epoch 1861/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0103 - acc: 0.9971 - val_loss: 0.0939 - val_acc: 0.9869\n",
      "Epoch 1862/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9976 - val_loss: 0.1046 - val_acc: 0.9854\n",
      "Epoch 1863/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0184 - acc: 0.9971 - val_loss: 0.0958 - val_acc: 0.9863\n",
      "Epoch 1864/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0138 - acc: 0.9974 - val_loss: 0.0984 - val_acc: 0.9857\n",
      "Epoch 1865/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0074 - acc: 0.9982 - val_loss: 0.0999 - val_acc: 0.9857\n",
      "Epoch 1866/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0117 - acc: 0.9972 - val_loss: 0.0861 - val_acc: 0.9883\n",
      "Epoch 1867/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.0785 - val_acc: 0.9886\n",
      "Epoch 1868/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0100 - acc: 0.9975 - val_loss: 0.0960 - val_acc: 0.9857\n",
      "Epoch 1869/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0093 - acc: 0.9976 - val_loss: 0.0942 - val_acc: 0.9889\n",
      "Epoch 1870/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0124 - acc: 0.9976 - val_loss: 0.0926 - val_acc: 0.9860\n",
      "Epoch 1871/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0848 - val_acc: 0.9886\n",
      "Epoch 1872/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0116 - acc: 0.9973 - val_loss: 0.0972 - val_acc: 0.9840\n",
      "Epoch 1873/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0695 - val_acc: 0.9889\n",
      "Epoch 1874/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0081 - acc: 0.9981 - val_loss: 0.0882 - val_acc: 0.9872\n",
      "Epoch 1875/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0068 - acc: 0.9984 - val_loss: 0.0912 - val_acc: 0.9854\n",
      "Epoch 1876/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0112 - acc: 0.9977 - val_loss: 0.0869 - val_acc: 0.9883\n",
      "Epoch 1877/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0092 - acc: 0.9979 - val_loss: 0.0890 - val_acc: 0.9863\n",
      "Epoch 1878/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0886 - val_acc: 0.9883\n",
      "Epoch 1879/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0143 - acc: 0.9976 - val_loss: 0.0831 - val_acc: 0.9880\n",
      "Epoch 1880/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0815 - val_acc: 0.9895\n",
      "Epoch 1881/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9973 - val_loss: 0.0806 - val_acc: 0.9860\n",
      "Epoch 1882/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0759 - val_acc: 0.9877\n",
      "Epoch 1883/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0083 - acc: 0.9983 - val_loss: 0.0784 - val_acc: 0.9875\n",
      "Epoch 1884/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0723 - val_acc: 0.9866\n",
      "Epoch 1885/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.0905 - val_acc: 0.9854\n",
      "Epoch 1886/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0993 - val_acc: 0.9872\n",
      "Epoch 1887/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0841 - val_acc: 0.9872\n",
      "Epoch 1888/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9986 - val_loss: 0.0728 - val_acc: 0.9866\n",
      "Epoch 1889/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9980 - val_loss: 0.0937 - val_acc: 0.9866\n",
      "Epoch 1890/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0920 - val_acc: 0.9837\n",
      "Epoch 1891/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0889 - val_acc: 0.9872\n",
      "Epoch 1892/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0962 - val_acc: 0.9872\n",
      "Epoch 1893/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0151 - acc: 0.9974 - val_loss: 0.1144 - val_acc: 0.9834\n",
      "Epoch 1894/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.1054 - val_acc: 0.9834\n",
      "Epoch 1895/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0149 - acc: 0.9973 - val_loss: 0.0884 - val_acc: 0.9880\n",
      "Epoch 1896/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0116 - acc: 0.9978 - val_loss: 0.0967 - val_acc: 0.9875\n",
      "Epoch 1897/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0124 - acc: 0.9973 - val_loss: 0.0915 - val_acc: 0.9857\n",
      "Epoch 1898/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0141 - acc: 0.9971 - val_loss: 0.0949 - val_acc: 0.9869\n",
      "Epoch 1899/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0119 - acc: 0.9975 - val_loss: 0.0923 - val_acc: 0.9866\n",
      "Epoch 1900/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0145 - acc: 0.9963 - val_loss: 0.0962 - val_acc: 0.9848\n",
      "Epoch 1901/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0125 - acc: 0.9973 - val_loss: 0.0945 - val_acc: 0.9877\n",
      "Epoch 1902/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0079 - acc: 0.9979 - val_loss: 0.0858 - val_acc: 0.9886\n",
      "Epoch 1903/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0754 - val_acc: 0.9875\n",
      "Epoch 1904/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0801 - val_acc: 0.9875\n",
      "Epoch 1905/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0095 - acc: 0.9980 - val_loss: 0.0760 - val_acc: 0.9866\n",
      "Epoch 1906/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0100 - acc: 0.9982 - val_loss: 0.0734 - val_acc: 0.9883\n",
      "Epoch 1907/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0117 - acc: 0.9971 - val_loss: 0.0759 - val_acc: 0.9854\n",
      "Epoch 1908/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0088 - acc: 0.9982 - val_loss: 0.0688 - val_acc: 0.9883\n",
      "Epoch 1909/2500\n",
      "53/53 [==============================] - 14s 256ms/step - loss: 0.0054 - acc: 0.9988 - val_loss: 0.0730 - val_acc: 0.9886\n",
      "Epoch 1910/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0739 - val_acc: 0.9898\n",
      "Epoch 1911/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.0778 - val_acc: 0.9910\n",
      "Epoch 1912/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0784 - val_acc: 0.9883\n",
      "Epoch 1913/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0062 - acc: 0.9984 - val_loss: 0.0814 - val_acc: 0.9877\n",
      "Epoch 1914/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0062 - acc: 0.9984 - val_loss: 0.0843 - val_acc: 0.9895\n",
      "Epoch 1915/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0060 - acc: 0.9986 - val_loss: 0.0826 - val_acc: 0.9875\n",
      "Epoch 1916/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0882 - val_acc: 0.9877\n",
      "Epoch 1917/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0754 - val_acc: 0.9892\n",
      "Epoch 1918/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0068 - acc: 0.9985 - val_loss: 0.0853 - val_acc: 0.9886\n",
      "Epoch 1919/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0074 - acc: 0.9980 - val_loss: 0.0829 - val_acc: 0.9883\n",
      "Epoch 1920/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0098 - acc: 0.9983 - val_loss: 0.0820 - val_acc: 0.9857\n",
      "Epoch 1921/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9981 - val_loss: 0.0913 - val_acc: 0.9857\n",
      "Epoch 1922/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0076 - acc: 0.9982 - val_loss: 0.0811 - val_acc: 0.9883\n",
      "Epoch 1923/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.0787 - val_acc: 0.9892\n",
      "Epoch 1924/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0201 - acc: 0.9960 - val_loss: 0.1025 - val_acc: 0.9851\n",
      "Epoch 1925/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0143 - acc: 0.9964 - val_loss: 0.0964 - val_acc: 0.9840\n",
      "Epoch 1926/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.1079 - val_acc: 0.9866\n",
      "Epoch 1927/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0072 - acc: 0.9987 - val_loss: 0.0924 - val_acc: 0.9875\n",
      "Epoch 1928/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0102 - acc: 0.9979 - val_loss: 0.0994 - val_acc: 0.9851\n",
      "Epoch 1929/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1020 - acc: 0.9843 - val_loss: 0.3195 - val_acc: 0.9402\n",
      "Epoch 1930/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1928 - acc: 0.9704 - val_loss: 0.2265 - val_acc: 0.9732\n",
      "Epoch 1931/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1177 - acc: 0.9881 - val_loss: 0.2088 - val_acc: 0.9746\n",
      "Epoch 1932/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1002 - acc: 0.9904 - val_loss: 0.1945 - val_acc: 0.9793\n",
      "Epoch 1933/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0910 - acc: 0.9911 - val_loss: 0.2004 - val_acc: 0.9784\n",
      "Epoch 1934/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0950 - acc: 0.9916 - val_loss: 0.1946 - val_acc: 0.9784\n",
      "Epoch 1935/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0905 - acc: 0.9928 - val_loss: 0.1913 - val_acc: 0.9787\n",
      "Epoch 1936/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0814 - acc: 0.9932 - val_loss: 0.1817 - val_acc: 0.9790\n",
      "Epoch 1937/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0809 - acc: 0.9933 - val_loss: 0.1858 - val_acc: 0.9790\n",
      "Epoch 1938/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0851 - acc: 0.9928 - val_loss: 0.1684 - val_acc: 0.9807\n",
      "Epoch 1939/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0871 - acc: 0.9926 - val_loss: 0.1632 - val_acc: 0.9822\n",
      "Epoch 1940/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0819 - acc: 0.9928 - val_loss: 0.1693 - val_acc: 0.9802\n",
      "Epoch 1941/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0764 - acc: 0.9932 - val_loss: 0.1672 - val_acc: 0.9802\n",
      "Epoch 1942/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0761 - acc: 0.9938 - val_loss: 0.1793 - val_acc: 0.9816\n",
      "Epoch 1943/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0834 - acc: 0.9929 - val_loss: 0.1644 - val_acc: 0.9825\n",
      "Epoch 1944/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0806 - acc: 0.9932 - val_loss: 0.2149 - val_acc: 0.9749\n",
      "Epoch 1945/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0782 - acc: 0.9940 - val_loss: 0.1523 - val_acc: 0.9834\n",
      "Epoch 1946/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0778 - acc: 0.9935 - val_loss: 0.1610 - val_acc: 0.9825\n",
      "Epoch 1947/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0787 - acc: 0.9942 - val_loss: 0.1764 - val_acc: 0.9822\n",
      "Epoch 1948/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0804 - acc: 0.9935 - val_loss: 0.1644 - val_acc: 0.9834\n",
      "Epoch 1949/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0861 - acc: 0.9933 - val_loss: 0.1715 - val_acc: 0.9813\n",
      "Epoch 1950/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0793 - acc: 0.9939 - val_loss: 0.1632 - val_acc: 0.9822\n",
      "Epoch 1951/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0782 - acc: 0.9940 - val_loss: 0.1525 - val_acc: 0.9819\n",
      "Epoch 1952/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0780 - acc: 0.9941 - val_loss: 0.1537 - val_acc: 0.9822\n",
      "Epoch 1953/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0758 - acc: 0.9944 - val_loss: 0.1621 - val_acc: 0.9807\n",
      "Epoch 1954/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0830 - acc: 0.9940 - val_loss: 0.1504 - val_acc: 0.9834\n",
      "Epoch 1955/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0817 - acc: 0.9944 - val_loss: 0.1998 - val_acc: 0.9737\n",
      "Epoch 1956/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1134 - acc: 0.9875 - val_loss: 0.1716 - val_acc: 0.9769\n",
      "Epoch 1957/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0899 - acc: 0.9919 - val_loss: 0.1491 - val_acc: 0.9831\n",
      "Epoch 1958/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0816 - acc: 0.9934 - val_loss: 0.1478 - val_acc: 0.9837\n",
      "Epoch 1959/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0869 - acc: 0.9933 - val_loss: 0.1510 - val_acc: 0.9842\n",
      "Epoch 1960/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0961 - acc: 0.9893 - val_loss: 0.2217 - val_acc: 0.9618\n",
      "Epoch 1961/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1137 - acc: 0.9754 - val_loss: 0.1357 - val_acc: 0.9746\n",
      "Epoch 1962/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0529 - acc: 0.9876 - val_loss: 0.1170 - val_acc: 0.9796\n",
      "Epoch 1963/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0484 - acc: 0.9892 - val_loss: 0.1071 - val_acc: 0.9802\n",
      "Epoch 1964/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0291 - acc: 0.9929 - val_loss: 0.0991 - val_acc: 0.9813\n",
      "Epoch 1965/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0262 - acc: 0.9937 - val_loss: 0.1159 - val_acc: 0.9810\n",
      "Epoch 1966/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0289 - acc: 0.9945 - val_loss: 0.1052 - val_acc: 0.9813\n",
      "Epoch 1967/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0182 - acc: 0.9962 - val_loss: 0.1072 - val_acc: 0.9813\n",
      "Epoch 1968/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0221 - acc: 0.9953 - val_loss: 0.1034 - val_acc: 0.9819\n",
      "Epoch 1969/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0127 - acc: 0.9968 - val_loss: 0.1013 - val_acc: 0.9828\n",
      "Epoch 1970/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0159 - acc: 0.9954 - val_loss: 0.0962 - val_acc: 0.9840\n",
      "Epoch 1971/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0158 - acc: 0.9962 - val_loss: 0.0958 - val_acc: 0.9845\n",
      "Epoch 1972/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0141 - acc: 0.9965 - val_loss: 0.0972 - val_acc: 0.9857\n",
      "Epoch 1973/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0130 - acc: 0.9971 - val_loss: 0.0923 - val_acc: 0.9845\n",
      "Epoch 1974/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0223 - acc: 0.9960 - val_loss: 0.1017 - val_acc: 0.9828\n",
      "Epoch 1975/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0189 - acc: 0.9969 - val_loss: 0.1007 - val_acc: 0.9804\n",
      "Epoch 1976/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0900 - val_acc: 0.9848\n",
      "Epoch 1977/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0166 - acc: 0.9967 - val_loss: 0.0849 - val_acc: 0.9863\n",
      "Epoch 1978/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0889 - val_acc: 0.9877\n",
      "Epoch 1979/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0150 - acc: 0.9970 - val_loss: 0.0950 - val_acc: 0.9866\n",
      "Epoch 1980/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0090 - acc: 0.9983 - val_loss: 0.1017 - val_acc: 0.9869\n",
      "Epoch 1981/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0078 - acc: 0.9982 - val_loss: 0.1029 - val_acc: 0.9863\n",
      "Epoch 1982/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0136 - acc: 0.9966 - val_loss: 0.1152 - val_acc: 0.9816\n",
      "Epoch 1983/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0251 - acc: 0.9946 - val_loss: 0.1177 - val_acc: 0.9807\n",
      "Epoch 1984/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0153 - acc: 0.9963 - val_loss: 0.1211 - val_acc: 0.9828\n",
      "Epoch 1985/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0172 - acc: 0.9964 - val_loss: 0.1177 - val_acc: 0.9840\n",
      "Epoch 1986/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0079 - acc: 0.9979 - val_loss: 0.1184 - val_acc: 0.9854\n",
      "Epoch 1987/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0152 - acc: 0.9965 - val_loss: 0.1017 - val_acc: 0.9845\n",
      "Epoch 1988/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0154 - acc: 0.9965 - val_loss: 0.1010 - val_acc: 0.9848\n",
      "Epoch 1989/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0101 - acc: 0.9976 - val_loss: 0.1008 - val_acc: 0.9840\n",
      "Epoch 1990/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0144 - acc: 0.9974 - val_loss: 0.1001 - val_acc: 0.9854\n",
      "Epoch 1991/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0111 - acc: 0.9975 - val_loss: 0.1003 - val_acc: 0.9860\n",
      "Epoch 1992/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0081 - acc: 0.9981 - val_loss: 0.0984 - val_acc: 0.9854\n",
      "Epoch 1993/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0972 - val_acc: 0.9854\n",
      "Epoch 1994/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0079 - acc: 0.9985 - val_loss: 0.0877 - val_acc: 0.9872\n",
      "Epoch 1995/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0082 - acc: 0.9975 - val_loss: 0.0937 - val_acc: 0.9860\n",
      "Epoch 1996/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0897 - val_acc: 0.9863\n",
      "Epoch 1997/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0116 - acc: 0.9976 - val_loss: 0.0865 - val_acc: 0.9857\n",
      "Epoch 1998/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.1048 - val_acc: 0.9845\n",
      "Epoch 1999/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0058 - acc: 0.9986 - val_loss: 0.0889 - val_acc: 0.9869\n",
      "Epoch 2000/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0081 - acc: 0.9980 - val_loss: 0.0924 - val_acc: 0.9880\n",
      "Epoch 2001/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0084 - acc: 0.9980 - val_loss: 0.0871 - val_acc: 0.9880\n",
      "Epoch 2002/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0135 - acc: 0.9980 - val_loss: 0.0811 - val_acc: 0.9866\n",
      "Epoch 2003/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.0854 - val_acc: 0.9866\n",
      "Epoch 2004/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.0822 - val_acc: 0.9872\n",
      "Epoch 2005/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0064 - acc: 0.9987 - val_loss: 0.0798 - val_acc: 0.9886\n",
      "Epoch 2006/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0095 - acc: 0.9978 - val_loss: 0.0844 - val_acc: 0.9880\n",
      "Epoch 2007/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0742 - val_acc: 0.9892\n",
      "Epoch 2008/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0067 - acc: 0.9986 - val_loss: 0.0706 - val_acc: 0.9912\n",
      "Epoch 2009/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0660 - val_acc: 0.9895\n",
      "Epoch 2010/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0065 - acc: 0.9985 - val_loss: 0.0680 - val_acc: 0.9889\n",
      "Epoch 2011/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0703 - val_acc: 0.9880\n",
      "Epoch 2012/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0755 - val_acc: 0.9880\n",
      "Epoch 2013/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0745 - val_acc: 0.9875\n",
      "Epoch 2014/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0054 - acc: 0.9989 - val_loss: 0.0777 - val_acc: 0.9866\n",
      "Epoch 2015/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0753 - val_acc: 0.9880\n",
      "Epoch 2016/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0074 - acc: 0.9982 - val_loss: 0.0745 - val_acc: 0.9889\n",
      "Epoch 2017/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0040 - acc: 0.9986 - val_loss: 0.0780 - val_acc: 0.9889\n",
      "Epoch 2018/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0107 - acc: 0.9976 - val_loss: 0.0805 - val_acc: 0.9880\n",
      "Epoch 2019/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0794 - val_acc: 0.9883\n",
      "Epoch 2020/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0796 - val_acc: 0.9880\n",
      "Epoch 2021/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.0842 - val_acc: 0.9880\n",
      "Epoch 2022/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0039 - acc: 0.9990 - val_loss: 0.0824 - val_acc: 0.9877\n",
      "Epoch 2023/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0070 - acc: 0.9985 - val_loss: 0.0814 - val_acc: 0.9875\n",
      "Epoch 2024/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.0906 - val_acc: 0.9869\n",
      "Epoch 2025/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0923 - val_acc: 0.9863\n",
      "Epoch 2026/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0890 - val_acc: 0.9877\n",
      "Epoch 2027/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0096 - acc: 0.9981 - val_loss: 0.0885 - val_acc: 0.9869\n",
      "Epoch 2028/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0874 - val_acc: 0.9872\n",
      "Epoch 2029/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0881 - val_acc: 0.9869\n",
      "Epoch 2030/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0071 - acc: 0.9987 - val_loss: 0.0817 - val_acc: 0.9883\n",
      "Epoch 2031/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0090 - acc: 0.9979 - val_loss: 0.0896 - val_acc: 0.9863\n",
      "Epoch 2032/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0056 - acc: 0.9987 - val_loss: 0.0897 - val_acc: 0.9857\n",
      "Epoch 2033/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0135 - acc: 0.9971 - val_loss: 0.1117 - val_acc: 0.9828\n",
      "Epoch 2034/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0147 - acc: 0.9968 - val_loss: 0.1038 - val_acc: 0.9831\n",
      "Epoch 2035/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0185 - acc: 0.9961 - val_loss: 0.1050 - val_acc: 0.9854\n",
      "Epoch 2036/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0108 - acc: 0.9975 - val_loss: 0.0915 - val_acc: 0.9860\n",
      "Epoch 2037/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9980 - val_loss: 0.0836 - val_acc: 0.9860\n",
      "Epoch 2038/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0169 - acc: 0.9970 - val_loss: 0.0907 - val_acc: 0.9872\n",
      "Epoch 2039/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0174 - acc: 0.9967 - val_loss: 0.0841 - val_acc: 0.9866\n",
      "Epoch 2040/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0872 - val_acc: 0.9866\n",
      "Epoch 2041/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0841 - val_acc: 0.9866\n",
      "Epoch 2042/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0118 - acc: 0.9985 - val_loss: 0.0847 - val_acc: 0.9860\n",
      "Epoch 2043/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0186 - acc: 0.9973 - val_loss: 0.0900 - val_acc: 0.9842\n",
      "Epoch 2044/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0056 - acc: 0.9987 - val_loss: 0.0830 - val_acc: 0.9854\n",
      "Epoch 2045/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0082 - acc: 0.9985 - val_loss: 0.0887 - val_acc: 0.9866\n",
      "Epoch 2046/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.0897 - val_acc: 0.9883\n",
      "Epoch 2047/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0099 - acc: 0.9982 - val_loss: 0.0929 - val_acc: 0.9848\n",
      "Epoch 2048/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0073 - acc: 0.9985 - val_loss: 0.1025 - val_acc: 0.9845\n",
      "Epoch 2049/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0089 - acc: 0.9982 - val_loss: 0.0960 - val_acc: 0.9854\n",
      "Epoch 2050/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0113 - acc: 0.9980 - val_loss: 0.0890 - val_acc: 0.9866\n",
      "Epoch 2051/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0070 - acc: 0.9988 - val_loss: 0.0946 - val_acc: 0.9866\n",
      "Epoch 2052/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0099 - acc: 0.9981 - val_loss: 0.1046 - val_acc: 0.9848\n",
      "Epoch 2053/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0123 - acc: 0.9980 - val_loss: 0.0879 - val_acc: 0.9877\n",
      "Epoch 2054/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0049 - acc: 0.9979 - val_loss: 0.0901 - val_acc: 0.9872\n",
      "Epoch 2055/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 0.0953 - val_acc: 0.9883\n",
      "Epoch 2056/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0933 - val_acc: 0.9866\n",
      "Epoch 2057/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.0917 - val_acc: 0.9875\n",
      "Epoch 2058/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0963 - val_acc: 0.9872\n",
      "Epoch 2059/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0065 - acc: 0.9984 - val_loss: 0.0860 - val_acc: 0.9883\n",
      "Epoch 2060/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0968 - val_acc: 0.9863\n",
      "Epoch 2061/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0117 - acc: 0.9980 - val_loss: 0.0839 - val_acc: 0.9877\n",
      "Epoch 2062/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0098 - acc: 0.9981 - val_loss: 0.0868 - val_acc: 0.9877\n",
      "Epoch 2063/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0071 - acc: 0.9982 - val_loss: 0.0901 - val_acc: 0.9880\n",
      "Epoch 2064/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0039 - acc: 0.9986 - val_loss: 0.0885 - val_acc: 0.9877\n",
      "Epoch 2065/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0068 - acc: 0.9986 - val_loss: 0.0919 - val_acc: 0.9872\n",
      "Epoch 2066/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0106 - acc: 0.9981 - val_loss: 0.0882 - val_acc: 0.9857\n",
      "Epoch 2067/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0117 - acc: 0.9974 - val_loss: 0.0881 - val_acc: 0.9883\n",
      "Epoch 2068/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0105 - acc: 0.9979 - val_loss: 0.0925 - val_acc: 0.9851\n",
      "Epoch 2069/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0121 - acc: 0.9979 - val_loss: 0.0879 - val_acc: 0.9851\n",
      "Epoch 2070/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0076 - acc: 0.9983 - val_loss: 0.0872 - val_acc: 0.9872\n",
      "Epoch 2071/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0077 - acc: 0.9985 - val_loss: 0.0970 - val_acc: 0.9869\n",
      "Epoch 2072/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0061 - acc: 0.9986 - val_loss: 0.0851 - val_acc: 0.9875\n",
      "Epoch 2073/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0776 - val_acc: 0.9901\n",
      "Epoch 2074/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0059 - acc: 0.9987 - val_loss: 0.0798 - val_acc: 0.9892\n",
      "Epoch 2075/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0061 - acc: 0.9988 - val_loss: 0.0853 - val_acc: 0.9889\n",
      "Epoch 2076/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0094 - acc: 0.9977 - val_loss: 0.0895 - val_acc: 0.9875\n",
      "Epoch 2077/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.0922 - val_acc: 0.9866\n",
      "Epoch 2078/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0101 - acc: 0.9979 - val_loss: 0.0999 - val_acc: 0.9883\n",
      "Epoch 2079/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0104 - acc: 0.9984 - val_loss: 0.0911 - val_acc: 0.9883\n",
      "Epoch 2080/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0080 - acc: 0.9981 - val_loss: 0.0845 - val_acc: 0.9883\n",
      "Epoch 2081/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0109 - acc: 0.9977 - val_loss: 0.0920 - val_acc: 0.9875\n",
      "Epoch 2082/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0107 - acc: 0.9982 - val_loss: 0.0873 - val_acc: 0.9872\n",
      "Epoch 2083/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0992 - val_acc: 0.9860\n",
      "Epoch 2084/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.1004 - val_acc: 0.9877\n",
      "Epoch 2085/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0940 - val_acc: 0.9886\n",
      "Epoch 2086/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0845 - val_acc: 0.9883\n",
      "Epoch 2087/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0932 - val_acc: 0.9875\n",
      "Epoch 2088/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0881 - val_acc: 0.9892\n",
      "Epoch 2089/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9986 - val_loss: 0.0950 - val_acc: 0.9866\n",
      "Epoch 2090/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0100 - acc: 0.9980 - val_loss: 0.1075 - val_acc: 0.9869\n",
      "Epoch 2091/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0087 - acc: 0.9979 - val_loss: 0.1051 - val_acc: 0.9866\n",
      "Epoch 2092/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0081 - acc: 0.9986 - val_loss: 0.1032 - val_acc: 0.9869\n",
      "Epoch 2093/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0091 - acc: 0.9974 - val_loss: 0.1060 - val_acc: 0.9854\n",
      "Epoch 2094/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0104 - acc: 0.9980 - val_loss: 0.1145 - val_acc: 0.9851\n",
      "Epoch 2095/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0111 - acc: 0.9980 - val_loss: 0.1129 - val_acc: 0.9866\n",
      "Epoch 2096/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0109 - acc: 0.9978 - val_loss: 0.1088 - val_acc: 0.9866\n",
      "Epoch 2097/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0087 - acc: 0.9985 - val_loss: 0.1023 - val_acc: 0.9866\n",
      "Epoch 2098/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.1091 - val_acc: 0.9866\n",
      "Epoch 2099/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0100 - acc: 0.9982 - val_loss: 0.1037 - val_acc: 0.9851\n",
      "Epoch 2100/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0064 - acc: 0.9986 - val_loss: 0.1077 - val_acc: 0.9860\n",
      "Epoch 2101/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0080 - acc: 0.9986 - val_loss: 0.1174 - val_acc: 0.9866\n",
      "Epoch 2102/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0100 - acc: 0.9982 - val_loss: 0.1258 - val_acc: 0.9851\n",
      "Epoch 2103/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0122 - acc: 0.9975 - val_loss: 0.0840 - val_acc: 0.9889\n",
      "Epoch 2104/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0848 - val_acc: 0.9889\n",
      "Epoch 2105/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0086 - acc: 0.9987 - val_loss: 0.0798 - val_acc: 0.9886\n",
      "Epoch 2106/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0064 - acc: 0.9986 - val_loss: 0.0996 - val_acc: 0.9872\n",
      "Epoch 2107/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.0930 - val_acc: 0.9875\n",
      "Epoch 2108/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0088 - acc: 0.9982 - val_loss: 0.1028 - val_acc: 0.9869\n",
      "Epoch 2109/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0811 - val_acc: 0.9869\n",
      "Epoch 2110/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0107 - acc: 0.9979 - val_loss: 0.0786 - val_acc: 0.9877\n",
      "Epoch 2111/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0115 - acc: 0.9976 - val_loss: 0.0879 - val_acc: 0.9840\n",
      "Epoch 2112/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0081 - acc: 0.9973 - val_loss: 0.0819 - val_acc: 0.9880\n",
      "Epoch 2113/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0109 - acc: 0.9979 - val_loss: 0.0880 - val_acc: 0.9877\n",
      "Epoch 2114/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.0778 - val_acc: 0.9889\n",
      "Epoch 2115/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0088 - acc: 0.9983 - val_loss: 0.0803 - val_acc: 0.9883\n",
      "Epoch 2116/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0120 - acc: 0.9976 - val_loss: 0.0934 - val_acc: 0.9866\n",
      "Epoch 2117/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0808 - val_acc: 0.9880\n",
      "Epoch 2118/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0134 - acc: 0.9980 - val_loss: 0.0889 - val_acc: 0.9875\n",
      "Epoch 2119/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0109 - acc: 0.9977 - val_loss: 0.0861 - val_acc: 0.9854\n",
      "Epoch 2120/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0118 - acc: 0.9976 - val_loss: 0.0732 - val_acc: 0.9860\n",
      "Epoch 2121/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0836 - val_acc: 0.9851\n",
      "Epoch 2122/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0080 - acc: 0.9984 - val_loss: 0.0783 - val_acc: 0.9883\n",
      "Epoch 2123/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0780 - val_acc: 0.9857\n",
      "Epoch 2124/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0098 - acc: 0.9976 - val_loss: 0.0737 - val_acc: 0.9883\n",
      "Epoch 2125/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1021 - acc: 0.9775 - val_loss: 0.1807 - val_acc: 0.9659\n",
      "Epoch 2126/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0781 - acc: 0.9841 - val_loss: 0.1309 - val_acc: 0.9732\n",
      "Epoch 2127/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0368 - acc: 0.9920 - val_loss: 0.1238 - val_acc: 0.9813\n",
      "Epoch 2128/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0310 - acc: 0.9927 - val_loss: 0.1145 - val_acc: 0.9822\n",
      "Epoch 2129/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0245 - acc: 0.9946 - val_loss: 0.1048 - val_acc: 0.9842\n",
      "Epoch 2130/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0200 - acc: 0.9945 - val_loss: 0.1039 - val_acc: 0.9825\n",
      "Epoch 2131/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0144 - acc: 0.9965 - val_loss: 0.0981 - val_acc: 0.9848\n",
      "Epoch 2132/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0182 - acc: 0.9960 - val_loss: 0.0950 - val_acc: 0.9845\n",
      "Epoch 2133/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0125 - acc: 0.9973 - val_loss: 0.0877 - val_acc: 0.9854\n",
      "Epoch 2134/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0141 - acc: 0.9963 - val_loss: 0.0903 - val_acc: 0.9842\n",
      "Epoch 2135/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0095 - acc: 0.9976 - val_loss: 0.0923 - val_acc: 0.9866\n",
      "Epoch 2136/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0092 - acc: 0.9978 - val_loss: 0.0863 - val_acc: 0.9866\n",
      "Epoch 2137/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0173 - acc: 0.9965 - val_loss: 0.1089 - val_acc: 0.9851\n",
      "Epoch 2138/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0366 - acc: 0.9925 - val_loss: 0.1415 - val_acc: 0.9769\n",
      "Epoch 2139/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0354 - acc: 0.9910 - val_loss: 0.1093 - val_acc: 0.9840\n",
      "Epoch 2140/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0178 - acc: 0.9950 - val_loss: 0.1067 - val_acc: 0.9840\n",
      "Epoch 2141/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0158 - acc: 0.9965 - val_loss: 0.1086 - val_acc: 0.9860\n",
      "Epoch 2142/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0122 - acc: 0.9970 - val_loss: 0.1060 - val_acc: 0.9851\n",
      "Epoch 2143/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0094 - acc: 0.9979 - val_loss: 0.1012 - val_acc: 0.9860\n",
      "Epoch 2144/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0093 - acc: 0.9977 - val_loss: 0.1076 - val_acc: 0.9834\n",
      "Epoch 2145/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0088 - acc: 0.9974 - val_loss: 0.1095 - val_acc: 0.9848\n",
      "Epoch 2146/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0101 - acc: 0.9974 - val_loss: 0.1060 - val_acc: 0.9845\n",
      "Epoch 2147/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0084 - acc: 0.9979 - val_loss: 0.1018 - val_acc: 0.9863\n",
      "Epoch 2148/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0062 - acc: 0.9978 - val_loss: 0.0952 - val_acc: 0.9866\n",
      "Epoch 2149/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0083 - acc: 0.9979 - val_loss: 0.0881 - val_acc: 0.9869\n",
      "Epoch 2150/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0787 - val_acc: 0.9895\n",
      "Epoch 2151/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0094 - acc: 0.9981 - val_loss: 0.0829 - val_acc: 0.9904\n",
      "Epoch 2152/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0901 - val_acc: 0.9889\n",
      "Epoch 2153/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0896 - val_acc: 0.9877\n",
      "Epoch 2154/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0094 - acc: 0.9985 - val_loss: 0.0971 - val_acc: 0.9863\n",
      "Epoch 2155/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0923 - val_acc: 0.9877\n",
      "Epoch 2156/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.0875 - val_acc: 0.9883\n",
      "Epoch 2157/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0814 - val_acc: 0.9889\n",
      "Epoch 2158/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0959 - val_acc: 0.9860\n",
      "Epoch 2159/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.0920 - val_acc: 0.9875\n",
      "Epoch 2160/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.0728 - val_acc: 0.9880\n",
      "Epoch 2161/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0779 - val_acc: 0.9875\n",
      "Epoch 2162/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0797 - val_acc: 0.9875\n",
      "Epoch 2163/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0074 - acc: 0.9980 - val_loss: 0.0874 - val_acc: 0.9851\n",
      "Epoch 2164/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0056 - acc: 0.9985 - val_loss: 0.0809 - val_acc: 0.9854\n",
      "Epoch 2165/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0080 - acc: 0.9979 - val_loss: 0.0804 - val_acc: 0.9872\n",
      "Epoch 2166/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0891 - val_acc: 0.9875\n",
      "Epoch 2167/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0920 - val_acc: 0.9866\n",
      "Epoch 2168/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0101 - acc: 0.9981 - val_loss: 0.0976 - val_acc: 0.9869\n",
      "Epoch 2169/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0094 - acc: 0.9984 - val_loss: 0.0983 - val_acc: 0.9875\n",
      "Epoch 2170/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0911 - val_acc: 0.9875\n",
      "Epoch 2171/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0079 - acc: 0.9984 - val_loss: 0.0947 - val_acc: 0.9863\n",
      "Epoch 2172/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0053 - acc: 0.9989 - val_loss: 0.0848 - val_acc: 0.9872\n",
      "Epoch 2173/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0774 - val_acc: 0.9875\n",
      "Epoch 2174/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0084 - acc: 0.9982 - val_loss: 0.0813 - val_acc: 0.9869\n",
      "Epoch 2175/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0021 - acc: 0.9992 - val_loss: 0.0760 - val_acc: 0.9886\n",
      "Epoch 2176/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0057 - acc: 0.9989 - val_loss: 0.0863 - val_acc: 0.9875\n",
      "Epoch 2177/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0784 - val_acc: 0.9883\n",
      "Epoch 2178/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0770 - val_acc: 0.9872\n",
      "Epoch 2179/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0822 - val_acc: 0.9869\n",
      "Epoch 2180/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0057 - acc: 0.9982 - val_loss: 0.0813 - val_acc: 0.9883\n",
      "Epoch 2181/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0070 - acc: 0.9984 - val_loss: 0.0789 - val_acc: 0.9901\n",
      "Epoch 2182/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0962 - val_acc: 0.9854\n",
      "Epoch 2183/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0947 - val_acc: 0.9875\n",
      "Epoch 2184/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0843 - val_acc: 0.9880\n",
      "Epoch 2185/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0897 - val_acc: 0.9883\n",
      "Epoch 2186/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0809 - val_acc: 0.9886\n",
      "Epoch 2187/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0072 - acc: 0.9990 - val_loss: 0.0796 - val_acc: 0.9877\n",
      "Epoch 2188/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0857 - val_acc: 0.9886\n",
      "Epoch 2189/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0892 - val_acc: 0.9880\n",
      "Epoch 2190/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0051 - acc: 0.9987 - val_loss: 0.0851 - val_acc: 0.9886\n",
      "Epoch 2191/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0039 - acc: 0.9990 - val_loss: 0.0825 - val_acc: 0.9901\n",
      "Epoch 2192/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0058 - acc: 0.9986 - val_loss: 0.0802 - val_acc: 0.9907\n",
      "Epoch 2193/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.0859 - val_acc: 0.9880\n",
      "Epoch 2194/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.0904 - val_acc: 0.9875\n",
      "Epoch 2195/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0058 - acc: 0.9987 - val_loss: 0.0888 - val_acc: 0.9886\n",
      "Epoch 2196/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0835 - val_acc: 0.9898\n",
      "Epoch 2197/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0829 - val_acc: 0.9886\n",
      "Epoch 2198/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0040 - acc: 0.9991 - val_loss: 0.0945 - val_acc: 0.9869\n",
      "Epoch 2199/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0048 - acc: 0.9992 - val_loss: 0.0891 - val_acc: 0.9892\n",
      "Epoch 2200/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0914 - val_acc: 0.9892\n",
      "Epoch 2201/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.1063 - val_acc: 0.9863\n",
      "Epoch 2202/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0111 - acc: 0.9980 - val_loss: 0.0924 - val_acc: 0.9883\n",
      "Epoch 2203/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0083 - acc: 0.9980 - val_loss: 0.0962 - val_acc: 0.9883\n",
      "Epoch 2204/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0115 - acc: 0.9978 - val_loss: 0.1125 - val_acc: 0.9857\n",
      "Epoch 2205/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0105 - acc: 0.9979 - val_loss: 0.0999 - val_acc: 0.9866\n",
      "Epoch 2206/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0963 - val_acc: 0.9875\n",
      "Epoch 2207/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0068 - acc: 0.9985 - val_loss: 0.0928 - val_acc: 0.9883\n",
      "Epoch 2208/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0053 - acc: 0.9989 - val_loss: 0.0903 - val_acc: 0.9889\n",
      "Epoch 2209/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0053 - acc: 0.9990 - val_loss: 0.0756 - val_acc: 0.9898\n",
      "Epoch 2210/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0066 - acc: 0.9984 - val_loss: 0.0708 - val_acc: 0.9901\n",
      "Epoch 2211/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0815 - val_acc: 0.9886\n",
      "Epoch 2212/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0118 - acc: 0.9981 - val_loss: 0.0904 - val_acc: 0.9872\n",
      "Epoch 2213/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0152 - acc: 0.9971 - val_loss: 0.0942 - val_acc: 0.9877\n",
      "Epoch 2214/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0100 - acc: 0.9973 - val_loss: 0.0917 - val_acc: 0.9866\n",
      "Epoch 2215/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0135 - acc: 0.9969 - val_loss: 0.0882 - val_acc: 0.9877\n",
      "Epoch 2216/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0113 - acc: 0.9979 - val_loss: 0.1166 - val_acc: 0.9840\n",
      "Epoch 2217/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.1121 - val_acc: 0.9845\n",
      "Epoch 2218/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0060 - acc: 0.9988 - val_loss: 0.0921 - val_acc: 0.9880\n",
      "Epoch 2219/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.0775 - val_acc: 0.9886\n",
      "Epoch 2220/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0061 - acc: 0.9989 - val_loss: 0.0908 - val_acc: 0.9869\n",
      "Epoch 2221/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0060 - acc: 0.9985 - val_loss: 0.0950 - val_acc: 0.9866\n",
      "Epoch 2222/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0122 - acc: 0.9966 - val_loss: 0.1044 - val_acc: 0.9842\n",
      "Epoch 2223/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0110 - acc: 0.9977 - val_loss: 0.0933 - val_acc: 0.9845\n",
      "Epoch 2224/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0075 - acc: 0.9981 - val_loss: 0.0815 - val_acc: 0.9877\n",
      "Epoch 2225/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0100 - acc: 0.9980 - val_loss: 0.0929 - val_acc: 0.9854\n",
      "Epoch 2226/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0109 - acc: 0.9977 - val_loss: 0.0806 - val_acc: 0.9883\n",
      "Epoch 2227/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0798 - val_acc: 0.9872\n",
      "Epoch 2228/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0199 - acc: 0.9966 - val_loss: 0.0826 - val_acc: 0.9875\n",
      "Epoch 2229/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0780 - val_acc: 0.9892\n",
      "Epoch 2230/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0099 - acc: 0.9979 - val_loss: 0.0928 - val_acc: 0.9860\n",
      "Epoch 2231/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0858 - val_acc: 0.9886\n",
      "Epoch 2232/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0095 - acc: 0.9980 - val_loss: 0.0744 - val_acc: 0.9892\n",
      "Epoch 2233/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0101 - acc: 0.9979 - val_loss: 0.0914 - val_acc: 0.9866\n",
      "Epoch 2234/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.0835 - val_acc: 0.9880\n",
      "Epoch 2235/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0881 - val_acc: 0.9880\n",
      "Epoch 2236/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0077 - acc: 0.9985 - val_loss: 0.0949 - val_acc: 0.9854\n",
      "Epoch 2237/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0113 - acc: 0.9977 - val_loss: 0.0920 - val_acc: 0.9883\n",
      "Epoch 2238/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0078 - acc: 0.9979 - val_loss: 0.1028 - val_acc: 0.9857\n",
      "Epoch 2239/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0101 - acc: 0.9980 - val_loss: 0.1010 - val_acc: 0.9872\n",
      "Epoch 2240/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.1005 - val_acc: 0.9875\n",
      "Epoch 2241/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9981 - val_loss: 0.0861 - val_acc: 0.9872\n",
      "Epoch 2242/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0045 - acc: 0.9989 - val_loss: 0.0834 - val_acc: 0.9863\n",
      "Epoch 2243/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0071 - acc: 0.9984 - val_loss: 0.0867 - val_acc: 0.9872\n",
      "Epoch 2244/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0092 - acc: 0.9979 - val_loss: 0.0951 - val_acc: 0.9860\n",
      "Epoch 2245/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0099 - acc: 0.9986 - val_loss: 0.0884 - val_acc: 0.9875\n",
      "Epoch 2246/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.0900 - val_acc: 0.9883\n",
      "Epoch 2247/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0906 - val_acc: 0.9877\n",
      "Epoch 2248/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0068 - acc: 0.9985 - val_loss: 0.0915 - val_acc: 0.9877\n",
      "Epoch 2249/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0122 - acc: 0.9979 - val_loss: 0.0860 - val_acc: 0.9877\n",
      "Epoch 2250/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0970 - val_acc: 0.9886\n",
      "Epoch 2251/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0031 - acc: 0.9987 - val_loss: 0.0946 - val_acc: 0.9877\n",
      "Epoch 2252/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9988 - val_loss: 0.0849 - val_acc: 0.9880\n",
      "Epoch 2253/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0067 - acc: 0.9986 - val_loss: 0.0811 - val_acc: 0.9895\n",
      "Epoch 2254/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0116 - acc: 0.9983 - val_loss: 0.0957 - val_acc: 0.9883\n",
      "Epoch 2255/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0060 - acc: 0.9987 - val_loss: 0.0998 - val_acc: 0.9854\n",
      "Epoch 2256/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0113 - acc: 0.9978 - val_loss: 0.0912 - val_acc: 0.9857\n",
      "Epoch 2257/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0919 - val_acc: 0.9866\n",
      "Epoch 2258/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.1023 - val_acc: 0.9877\n",
      "Epoch 2259/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0879 - val_acc: 0.9892\n",
      "Epoch 2260/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.1068 - val_acc: 0.9883\n",
      "Epoch 2261/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0094 - acc: 0.9979 - val_loss: 0.1044 - val_acc: 0.9880\n",
      "Epoch 2262/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0123 - acc: 0.9978 - val_loss: 0.1034 - val_acc: 0.9880\n",
      "Epoch 2263/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0239 - acc: 0.9969 - val_loss: 0.1251 - val_acc: 0.9848\n",
      "Epoch 2264/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0647 - acc: 0.9938 - val_loss: 0.2534 - val_acc: 0.9752\n",
      "Epoch 2265/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1100 - acc: 0.9910 - val_loss: 0.2509 - val_acc: 0.9761\n",
      "Epoch 2266/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1075 - acc: 0.9921 - val_loss: 0.2417 - val_acc: 0.9767\n",
      "Epoch 2267/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1072 - acc: 0.9922 - val_loss: 0.2362 - val_acc: 0.9793\n",
      "Epoch 2268/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.1127 - acc: 0.9915 - val_loss: 0.2623 - val_acc: 0.9746\n",
      "Epoch 2269/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.1173 - acc: 0.9920 - val_loss: 0.2341 - val_acc: 0.9790\n",
      "Epoch 2270/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1150 - acc: 0.9911 - val_loss: 0.2496 - val_acc: 0.9764\n",
      "Epoch 2271/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1045 - acc: 0.9923 - val_loss: 0.2476 - val_acc: 0.9781\n",
      "Epoch 2272/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1778 - acc: 0.9803 - val_loss: 0.2750 - val_acc: 0.9644\n",
      "Epoch 2273/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0972 - acc: 0.9827 - val_loss: 0.1579 - val_acc: 0.9761\n",
      "Epoch 2274/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0747 - acc: 0.9883 - val_loss: 0.1287 - val_acc: 0.9790\n",
      "Epoch 2275/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0330 - acc: 0.9928 - val_loss: 0.1209 - val_acc: 0.9810\n",
      "Epoch 2276/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0247 - acc: 0.9943 - val_loss: 0.1170 - val_acc: 0.9819\n",
      "Epoch 2277/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0174 - acc: 0.9960 - val_loss: 0.1208 - val_acc: 0.9837\n",
      "Epoch 2278/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0092 - acc: 0.9976 - val_loss: 0.1160 - val_acc: 0.9842\n",
      "Epoch 2279/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0114 - acc: 0.9972 - val_loss: 0.1128 - val_acc: 0.9845\n",
      "Epoch 2280/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0245 - acc: 0.9946 - val_loss: 0.1234 - val_acc: 0.9819\n",
      "Epoch 2281/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0257 - acc: 0.9946 - val_loss: 0.1084 - val_acc: 0.9845\n",
      "Epoch 2282/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0146 - acc: 0.9970 - val_loss: 0.1063 - val_acc: 0.9851\n",
      "Epoch 2283/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0143 - acc: 0.9968 - val_loss: 0.1145 - val_acc: 0.9840\n",
      "Epoch 2284/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0145 - acc: 0.9966 - val_loss: 0.1152 - val_acc: 0.9845\n",
      "Epoch 2285/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0078 - acc: 0.9976 - val_loss: 0.1093 - val_acc: 0.9851\n",
      "Epoch 2286/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.1091 - val_acc: 0.9857\n",
      "Epoch 2287/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.1101 - val_acc: 0.9866\n",
      "Epoch 2288/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0090 - acc: 0.9984 - val_loss: 0.1111 - val_acc: 0.9857\n",
      "Epoch 2289/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0077 - acc: 0.9981 - val_loss: 0.1135 - val_acc: 0.9831\n",
      "Epoch 2290/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0078 - acc: 0.9983 - val_loss: 0.1079 - val_acc: 0.9842\n",
      "Epoch 2291/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0102 - acc: 0.9979 - val_loss: 0.1013 - val_acc: 0.9863\n",
      "Epoch 2292/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.1127 - val_acc: 0.9851\n",
      "Epoch 2293/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0088 - acc: 0.9982 - val_loss: 0.1098 - val_acc: 0.9848\n",
      "Epoch 2294/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.1020 - val_acc: 0.9854\n",
      "Epoch 2295/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.1010 - val_acc: 0.9863\n",
      "Epoch 2296/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0080 - acc: 0.9985 - val_loss: 0.0938 - val_acc: 0.9877\n",
      "Epoch 2297/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0073 - acc: 0.9985 - val_loss: 0.0936 - val_acc: 0.9875\n",
      "Epoch 2298/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0959 - val_acc: 0.9877\n",
      "Epoch 2299/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.0881 - val_acc: 0.9863\n",
      "Epoch 2300/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0068 - acc: 0.9986 - val_loss: 0.0885 - val_acc: 0.9860\n",
      "Epoch 2301/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0072 - acc: 0.9987 - val_loss: 0.0913 - val_acc: 0.9866\n",
      "Epoch 2302/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0050 - acc: 0.9989 - val_loss: 0.1046 - val_acc: 0.9866\n",
      "Epoch 2303/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0109 - acc: 0.9986 - val_loss: 0.1121 - val_acc: 0.9866\n",
      "Epoch 2304/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0910 - val_acc: 0.9877\n",
      "Epoch 2305/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0068 - acc: 0.9985 - val_loss: 0.0869 - val_acc: 0.9886\n",
      "Epoch 2306/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0047 - acc: 0.9989 - val_loss: 0.1031 - val_acc: 0.9869\n",
      "Epoch 2307/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.1103 - val_acc: 0.9866\n",
      "Epoch 2308/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.1149 - val_acc: 0.9860\n",
      "Epoch 2309/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.1033 - val_acc: 0.9875\n",
      "Epoch 2310/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.1041 - val_acc: 0.9872\n",
      "Epoch 2311/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0028 - acc: 0.9994 - val_loss: 0.1027 - val_acc: 0.9869\n",
      "Epoch 2312/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.0046 - acc: 0.9992 - val_loss: 0.1031 - val_acc: 0.9866\n",
      "Epoch 2313/2500\n",
      "53/53 [==============================] - 14s 272ms/step - loss: 0.0071 - acc: 0.9985 - val_loss: 0.0966 - val_acc: 0.9863\n",
      "Epoch 2314/2500\n",
      "53/53 [==============================] - 14s 267ms/step - loss: 0.0083 - acc: 0.9988 - val_loss: 0.0944 - val_acc: 0.9869\n",
      "Epoch 2315/2500\n",
      "53/53 [==============================] - 14s 271ms/step - loss: 0.0042 - acc: 0.9984 - val_loss: 0.0918 - val_acc: 0.9866\n",
      "Epoch 2316/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 269ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0884 - val_acc: 0.9877\n",
      "Epoch 2317/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0950 - val_acc: 0.9854\n",
      "Epoch 2318/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0905 - val_acc: 0.9860\n",
      "Epoch 2319/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0066 - acc: 0.9989 - val_loss: 0.0845 - val_acc: 0.9880\n",
      "Epoch 2320/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0846 - val_acc: 0.9880\n",
      "Epoch 2321/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0059 - acc: 0.9989 - val_loss: 0.1040 - val_acc: 0.9877\n",
      "Epoch 2322/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.1054 - val_acc: 0.9851\n",
      "Epoch 2323/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0949 - val_acc: 0.9875\n",
      "Epoch 2324/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.1072 - val_acc: 0.9851\n",
      "Epoch 2325/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0060 - acc: 0.9988 - val_loss: 0.0925 - val_acc: 0.9886\n",
      "Epoch 2326/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0054 - acc: 0.9988 - val_loss: 0.0894 - val_acc: 0.9886\n",
      "Epoch 2327/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.0913 - val_acc: 0.9875\n",
      "Epoch 2328/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0082 - acc: 0.9985 - val_loss: 0.0892 - val_acc: 0.9863\n",
      "Epoch 2329/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.1144 - val_acc: 0.9866\n",
      "Epoch 2330/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.1320 - val_acc: 0.9851\n",
      "Epoch 2331/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0090 - acc: 0.9983 - val_loss: 0.1307 - val_acc: 0.9863\n",
      "Epoch 2332/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0093 - acc: 0.9980 - val_loss: 0.1127 - val_acc: 0.9869\n",
      "Epoch 2333/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0070 - acc: 0.9987 - val_loss: 0.1050 - val_acc: 0.9869\n",
      "Epoch 2334/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0085 - acc: 0.9983 - val_loss: 0.1087 - val_acc: 0.9875\n",
      "Epoch 2335/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0078 - acc: 0.9981 - val_loss: 0.1091 - val_acc: 0.9860\n",
      "Epoch 2336/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.1028 - val_acc: 0.9875\n",
      "Epoch 2337/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0106 - acc: 0.9980 - val_loss: 0.0983 - val_acc: 0.9857\n",
      "Epoch 2338/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0051 - acc: 0.9987 - val_loss: 0.0886 - val_acc: 0.9880\n",
      "Epoch 2339/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0133 - acc: 0.9978 - val_loss: 0.1005 - val_acc: 0.9863\n",
      "Epoch 2340/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.1042 - val_acc: 0.9869\n",
      "Epoch 2341/2500\n",
      "53/53 [==============================] - 14s 263ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0968 - val_acc: 0.9880\n",
      "Epoch 2342/2500\n",
      "53/53 [==============================] - 14s 262ms/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.1064 - val_acc: 0.9866\n",
      "Epoch 2343/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.1075 - val_acc: 0.9877\n",
      "Epoch 2344/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0981 - val_acc: 0.9848\n",
      "Epoch 2345/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0961 - val_acc: 0.9863\n",
      "Epoch 2346/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0083 - acc: 0.9983 - val_loss: 0.1156 - val_acc: 0.9845\n",
      "Epoch 2347/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0085 - acc: 0.9982 - val_loss: 0.1246 - val_acc: 0.9872\n",
      "Epoch 2348/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.1000 - val_acc: 0.9875\n",
      "Epoch 2349/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0160 - acc: 0.9974 - val_loss: 0.1095 - val_acc: 0.9842\n",
      "Epoch 2350/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0131 - acc: 0.9976 - val_loss: 0.1088 - val_acc: 0.9863\n",
      "Epoch 2351/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0054 - acc: 0.9990 - val_loss: 0.1132 - val_acc: 0.9857\n",
      "Epoch 2352/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0067 - acc: 0.9987 - val_loss: 0.0945 - val_acc: 0.9886\n",
      "Epoch 2353/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0100 - acc: 0.9986 - val_loss: 0.0977 - val_acc: 0.9889\n",
      "Epoch 2354/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0081 - acc: 0.9983 - val_loss: 0.0949 - val_acc: 0.9886\n",
      "Epoch 2355/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0122 - acc: 0.9981 - val_loss: 0.0966 - val_acc: 0.9866\n",
      "Epoch 2356/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0101 - acc: 0.9978 - val_loss: 0.1005 - val_acc: 0.9877\n",
      "Epoch 2357/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.1183 - val_acc: 0.9854\n",
      "Epoch 2358/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.1023 - val_acc: 0.9872\n",
      "Epoch 2359/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.1053 - val_acc: 0.9860\n",
      "Epoch 2360/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0093 - acc: 0.9978 - val_loss: 0.0957 - val_acc: 0.9842\n",
      "Epoch 2361/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0085 - acc: 0.9980 - val_loss: 0.1071 - val_acc: 0.9875\n",
      "Epoch 2362/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0104 - acc: 0.9977 - val_loss: 0.1096 - val_acc: 0.9840\n",
      "Epoch 2363/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0057 - acc: 0.9988 - val_loss: 0.1036 - val_acc: 0.9869\n",
      "Epoch 2364/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.1032 - val_acc: 0.9880\n",
      "Epoch 2365/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0042 - acc: 0.9992 - val_loss: 0.0958 - val_acc: 0.9892\n",
      "Epoch 2366/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0035 - acc: 0.9993 - val_loss: 0.1031 - val_acc: 0.9869\n",
      "Epoch 2367/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.1042 - val_acc: 0.9886\n",
      "Epoch 2368/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.1016 - val_acc: 0.9889\n",
      "Epoch 2369/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0944 - val_acc: 0.9877\n",
      "Epoch 2370/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.0965 - val_acc: 0.9863\n",
      "Epoch 2371/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0101 - acc: 0.9979 - val_loss: 0.1021 - val_acc: 0.9866\n",
      "Epoch 2372/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0079 - acc: 0.9987 - val_loss: 0.0975 - val_acc: 0.9863\n",
      "Epoch 2373/2500\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 0.0239 - acc: 0.9956 - val_loss: 0.0934 - val_acc: 0.9840\n",
      "Epoch 2374/2500\n",
      "53/53 [==============================] - 14s 261ms/step - loss: 0.0162 - acc: 0.9966 - val_loss: 0.0975 - val_acc: 0.9851\n",
      "Epoch 2375/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0120 - acc: 0.9973 - val_loss: 0.0993 - val_acc: 0.9863\n",
      "Epoch 2376/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0084 - acc: 0.9979 - val_loss: 0.1213 - val_acc: 0.9837\n",
      "Epoch 2377/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.1047 - val_acc: 0.9883\n",
      "Epoch 2378/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.1128 - val_acc: 0.9872\n",
      "Epoch 2379/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0148 - acc: 0.9971 - val_loss: 0.1131 - val_acc: 0.9845\n",
      "Epoch 2380/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0078 - acc: 0.9981 - val_loss: 0.1012 - val_acc: 0.9880\n",
      "Epoch 2381/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0092 - acc: 0.9981 - val_loss: 0.1099 - val_acc: 0.9866\n",
      "Epoch 2382/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0114 - acc: 0.9979 - val_loss: 0.1095 - val_acc: 0.9828\n",
      "Epoch 2383/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0060 - acc: 0.9987 - val_loss: 0.1100 - val_acc: 0.9842\n",
      "Epoch 2384/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0099 - acc: 0.9982 - val_loss: 0.1334 - val_acc: 0.9825\n",
      "Epoch 2385/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0105 - acc: 0.9980 - val_loss: 0.1169 - val_acc: 0.9851\n",
      "Epoch 2386/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0826 - val_acc: 0.9875\n",
      "Epoch 2387/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0069 - acc: 0.9985 - val_loss: 0.1064 - val_acc: 0.9851\n",
      "Epoch 2388/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0101 - acc: 0.9982 - val_loss: 0.1058 - val_acc: 0.9857\n",
      "Epoch 2389/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.1006 - val_acc: 0.9845\n",
      "Epoch 2390/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0085 - acc: 0.9984 - val_loss: 0.0970 - val_acc: 0.9857\n",
      "Epoch 2391/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0079 - acc: 0.9986 - val_loss: 0.0862 - val_acc: 0.9851\n",
      "Epoch 2392/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0923 - val_acc: 0.9860\n",
      "Epoch 2393/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0047 - acc: 0.9989 - val_loss: 0.0838 - val_acc: 0.9857\n",
      "Epoch 2394/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0113 - acc: 0.9980 - val_loss: 0.0777 - val_acc: 0.9889\n",
      "Epoch 2395/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0065 - acc: 0.9986 - val_loss: 0.0838 - val_acc: 0.9889\n",
      "Epoch 2396/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0051 - acc: 0.9988 - val_loss: 0.0859 - val_acc: 0.9877\n",
      "Epoch 2397/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.1326 - val_acc: 0.9840\n",
      "Epoch 2398/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.2919 - acc: 0.9585 - val_loss: 0.4054 - val_acc: 0.9463\n",
      "Epoch 2399/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.2848 - acc: 0.9662 - val_loss: 0.3603 - val_acc: 0.9577\n",
      "Epoch 2400/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.2441 - acc: 0.9756 - val_loss: 0.3470 - val_acc: 0.9618\n",
      "Epoch 2401/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.2158 - acc: 0.9805 - val_loss: 0.3504 - val_acc: 0.9632\n",
      "Epoch 2402/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.2366 - acc: 0.9595 - val_loss: 0.2405 - val_acc: 0.9583\n",
      "Epoch 2403/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1603 - acc: 0.9701 - val_loss: 0.1891 - val_acc: 0.9679\n",
      "Epoch 2404/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.1222 - acc: 0.9781 - val_loss: 0.1955 - val_acc: 0.9676\n",
      "Epoch 2405/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.1097 - acc: 0.9815 - val_loss: 0.1654 - val_acc: 0.9734\n",
      "Epoch 2406/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0812 - acc: 0.9851 - val_loss: 0.1556 - val_acc: 0.9752\n",
      "Epoch 2407/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0735 - acc: 0.9878 - val_loss: 0.1390 - val_acc: 0.9775\n",
      "Epoch 2408/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0547 - acc: 0.9893 - val_loss: 0.1374 - val_acc: 0.9764\n",
      "Epoch 2409/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0532 - acc: 0.9901 - val_loss: 0.1390 - val_acc: 0.9764\n",
      "Epoch 2410/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0466 - acc: 0.9895 - val_loss: 0.1417 - val_acc: 0.9734\n",
      "Epoch 2411/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0384 - acc: 0.9929 - val_loss: 0.1425 - val_acc: 0.9764\n",
      "Epoch 2412/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0422 - acc: 0.9924 - val_loss: 0.1393 - val_acc: 0.9787\n",
      "Epoch 2413/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0440 - acc: 0.9920 - val_loss: 0.1335 - val_acc: 0.9787\n",
      "Epoch 2414/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0496 - acc: 0.9926 - val_loss: 0.1328 - val_acc: 0.9778\n",
      "Epoch 2415/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0409 - acc: 0.9921 - val_loss: 0.1369 - val_acc: 0.9784\n",
      "Epoch 2416/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0427 - acc: 0.9933 - val_loss: 0.1418 - val_acc: 0.9775\n",
      "Epoch 2417/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0520 - acc: 0.9926 - val_loss: 0.1663 - val_acc: 0.9761\n",
      "Epoch 2418/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0658 - acc: 0.9914 - val_loss: 0.1610 - val_acc: 0.9767\n",
      "Epoch 2419/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0659 - acc: 0.9917 - val_loss: 0.1618 - val_acc: 0.9769\n",
      "Epoch 2420/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0657 - acc: 0.9915 - val_loss: 0.1472 - val_acc: 0.9781\n",
      "Epoch 2421/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0618 - acc: 0.9935 - val_loss: 0.1485 - val_acc: 0.9784\n",
      "Epoch 2422/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0513 - acc: 0.9930 - val_loss: 0.1446 - val_acc: 0.9781\n",
      "Epoch 2423/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0527 - acc: 0.9937 - val_loss: 0.1500 - val_acc: 0.9781\n",
      "Epoch 2424/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0470 - acc: 0.9940 - val_loss: 0.1490 - val_acc: 0.9775\n",
      "Epoch 2425/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0517 - acc: 0.9936 - val_loss: 0.1515 - val_acc: 0.9781\n",
      "Epoch 2426/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0612 - acc: 0.9934 - val_loss: 0.1558 - val_acc: 0.9790\n",
      "Epoch 2427/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0689 - acc: 0.9931 - val_loss: 0.1435 - val_acc: 0.9793\n",
      "Epoch 2428/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0690 - acc: 0.9916 - val_loss: 0.1606 - val_acc: 0.9796\n",
      "Epoch 2429/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0726 - acc: 0.9904 - val_loss: 0.1380 - val_acc: 0.9828\n",
      "Epoch 2430/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0571 - acc: 0.9924 - val_loss: 0.1607 - val_acc: 0.9767\n",
      "Epoch 2431/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0477 - acc: 0.9929 - val_loss: 0.1300 - val_acc: 0.9822\n",
      "Epoch 2432/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0514 - acc: 0.9936 - val_loss: 0.1240 - val_acc: 0.9828\n",
      "Epoch 2433/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0417 - acc: 0.9946 - val_loss: 0.1205 - val_acc: 0.9828\n",
      "Epoch 2434/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0299 - acc: 0.9959 - val_loss: 0.1160 - val_acc: 0.9816\n",
      "Epoch 2435/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0321 - acc: 0.9952 - val_loss: 0.1180 - val_acc: 0.9807\n",
      "Epoch 2436/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0283 - acc: 0.9958 - val_loss: 0.1118 - val_acc: 0.9828\n",
      "Epoch 2437/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0216 - acc: 0.9959 - val_loss: 0.1163 - val_acc: 0.9834\n",
      "Epoch 2438/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0204 - acc: 0.9970 - val_loss: 0.1184 - val_acc: 0.9816\n",
      "Epoch 2439/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0181 - acc: 0.9971 - val_loss: 0.1129 - val_acc: 0.9837\n",
      "Epoch 2440/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0178 - acc: 0.9971 - val_loss: 0.1050 - val_acc: 0.9819\n",
      "Epoch 2441/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0102 - acc: 0.9980 - val_loss: 0.1050 - val_acc: 0.9831\n",
      "Epoch 2442/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0103 - acc: 0.9974 - val_loss: 0.0953 - val_acc: 0.9848\n",
      "Epoch 2443/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0097 - acc: 0.9975 - val_loss: 0.1003 - val_acc: 0.9845\n",
      "Epoch 2444/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0127 - acc: 0.9976 - val_loss: 0.0947 - val_acc: 0.9854\n",
      "Epoch 2445/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0065 - acc: 0.9984 - val_loss: 0.0979 - val_acc: 0.9842\n",
      "Epoch 2446/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0168 - acc: 0.9973 - val_loss: 0.0891 - val_acc: 0.9851\n",
      "Epoch 2447/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0116 - acc: 0.9976 - val_loss: 0.0883 - val_acc: 0.9863\n",
      "Epoch 2448/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0112 - acc: 0.9975 - val_loss: 0.0936 - val_acc: 0.9845\n",
      "Epoch 2449/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0093 - acc: 0.9978 - val_loss: 0.0938 - val_acc: 0.9851\n",
      "Epoch 2450/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0118 - acc: 0.9975 - val_loss: 0.0967 - val_acc: 0.9842\n",
      "Epoch 2451/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0118 - acc: 0.9975 - val_loss: 0.0939 - val_acc: 0.9834\n",
      "Epoch 2452/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0070 - acc: 0.9984 - val_loss: 0.0991 - val_acc: 0.9822\n",
      "Epoch 2453/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0130 - acc: 0.9982 - val_loss: 0.0938 - val_acc: 0.9831\n",
      "Epoch 2454/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0085 - acc: 0.9979 - val_loss: 0.0890 - val_acc: 0.9845\n",
      "Epoch 2455/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0143 - acc: 0.9971 - val_loss: 0.0886 - val_acc: 0.9866\n",
      "Epoch 2456/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0113 - acc: 0.9975 - val_loss: 0.0924 - val_acc: 0.9866\n",
      "Epoch 2457/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0090 - acc: 0.9979 - val_loss: 0.0896 - val_acc: 0.9854\n",
      "Epoch 2458/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0135 - acc: 0.9971 - val_loss: 0.0878 - val_acc: 0.9851\n",
      "Epoch 2459/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0800 - val_acc: 0.9857\n",
      "Epoch 2460/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0802 - val_acc: 0.9869\n",
      "Epoch 2461/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0931 - val_acc: 0.9848\n",
      "Epoch 2462/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0820 - val_acc: 0.9869\n",
      "Epoch 2463/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0121 - acc: 0.9982 - val_loss: 0.0751 - val_acc: 0.9860\n",
      "Epoch 2464/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.0764 - val_acc: 0.9857\n",
      "Epoch 2465/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0038 - acc: 0.9982 - val_loss: 0.0783 - val_acc: 0.9866\n",
      "Epoch 2466/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0087 - acc: 0.9982 - val_loss: 0.0823 - val_acc: 0.9863\n",
      "Epoch 2467/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0951 - val_acc: 0.9831\n",
      "Epoch 2468/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0928 - val_acc: 0.9831\n",
      "Epoch 2469/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0863 - val_acc: 0.9842\n",
      "Epoch 2470/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0885 - val_acc: 0.9851\n",
      "Epoch 2471/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.0831 - val_acc: 0.9872\n",
      "Epoch 2472/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0914 - val_acc: 0.9872\n",
      "Epoch 2473/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0091 - acc: 0.9978 - val_loss: 0.0952 - val_acc: 0.9866\n",
      "Epoch 2474/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0046 - acc: 0.9989 - val_loss: 0.0845 - val_acc: 0.9877\n",
      "Epoch 2475/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0071 - acc: 0.9985 - val_loss: 0.0838 - val_acc: 0.9880\n",
      "Epoch 2476/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0064 - acc: 0.9985 - val_loss: 0.0875 - val_acc: 0.9863\n",
      "Epoch 2477/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0800 - val_acc: 0.9877\n",
      "Epoch 2478/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0833 - val_acc: 0.9901\n",
      "Epoch 2479/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0782 - val_acc: 0.9889\n",
      "Epoch 2480/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0805 - val_acc: 0.9883\n",
      "Epoch 2481/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0858 - val_acc: 0.9875\n",
      "Epoch 2482/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0904 - val_acc: 0.9866\n",
      "Epoch 2483/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0989 - val_acc: 0.9875\n",
      "Epoch 2484/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0083 - acc: 0.9982 - val_loss: 0.1153 - val_acc: 0.9857\n",
      "Epoch 2485/2500\n",
      "53/53 [==============================] - 14s 259ms/step - loss: 0.0076 - acc: 0.9987 - val_loss: 0.0798 - val_acc: 0.9877\n",
      "Epoch 2486/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.0814 - val_acc: 0.9869\n",
      "Epoch 2487/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0047 - acc: 0.9990 - val_loss: 0.0784 - val_acc: 0.9872\n",
      "Epoch 2488/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0721 - val_acc: 0.9892\n",
      "Epoch 2489/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.0843 - val_acc: 0.9877\n",
      "Epoch 2490/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0888 - val_acc: 0.9869\n",
      "Epoch 2491/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0907 - val_acc: 0.9866\n",
      "Epoch 2492/2500\n",
      "53/53 [==============================] - 14s 258ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.0854 - val_acc: 0.9883\n",
      "Epoch 2493/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0042 - acc: 0.9991 - val_loss: 0.0855 - val_acc: 0.9880\n",
      "Epoch 2494/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0906 - val_acc: 0.9883\n",
      "Epoch 2495/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0927 - val_acc: 0.9883\n",
      "Epoch 2496/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.1038 - val_acc: 0.9877\n",
      "Epoch 2497/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0041 - acc: 0.9994 - val_loss: 0.1049 - val_acc: 0.9872\n",
      "Epoch 2498/2500\n",
      "53/53 [==============================] - 14s 256ms/step - loss: 0.0025 - acc: 0.9990 - val_loss: 0.0946 - val_acc: 0.9869\n",
      "Epoch 2499/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0046 - acc: 0.9989 - val_loss: 0.0896 - val_acc: 0.9889\n",
      "Epoch 2500/2500\n",
      "53/53 [==============================] - 14s 257ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.0898 - val_acc: 0.9869\n",
      "9.495681988199552\n"
     ]
    }
   ],
   "source": [
    "# https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n",
    "# https://keras.io/models/sequential/\n",
    "batch_size=256\n",
    "epochs = 2500\n",
    "ini = tm.time()\n",
    "\n",
    "history =inception_transfer.fit_generator(\n",
    "    generator=data_generator.flow(x=X_train,\n",
    "                                  y=y_train,\n",
    "                                  batch_size=batch_size),\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle = True, \n",
    "    verbose = 1,\n",
    "    validation_data=(X_test, y_test))\n",
    "end = tm.time()\n",
    "\n",
    "elapsed = end - ini\n",
    "print(elapsed/3600)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model categorical accuracy')\n",
    "plt.ylabel('categorical accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
